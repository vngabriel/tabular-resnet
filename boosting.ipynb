{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Projeto AM - Leandro\n",
    "## XGBoost, CatBoost, and LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from data.data import DataProcessor\n",
    "from evaluation.evaluation import ResultsManager\n",
    "from experiments.experiment_boosting import BoostingExperiment\n",
    "from experiments.experiment_boosting_gpu import BoostingExperimentGPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## Configuração dos Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = \"./data/openml_cache\"\n",
    "\n",
    "SEED = 123\n",
    "N_TRIALS = 50  # Optuna trials\n",
    "CV_FOLDS = 10  # Cross-validation folds\n",
    "\n",
    "# Modelos a serem testados\n",
    "MODELS = [\"xgboost\", \"catboost\", \"lightgbm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f920ad",
   "metadata": {},
   "source": [
    "## Função para agregar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77537207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_results(results_dir: str, model_name: str, output_filename: str = None):\n",
    "    \"\"\"\n",
    "    Agrega todos os resultados individuais em um único CSV\n",
    "\n",
    "    Args:\n",
    "        results_dir: Diretório com os resultados (ex: \"./results/catboost_gpu\")\n",
    "        model_name: Nome do modelo (ex: \"catboost\")\n",
    "        output_filename: Nome do arquivo de saída (opcional, default: {model_name}_metrics.csv)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame com todos os resultados agregados\n",
    "    \"\"\"\n",
    "    results_path = Path(results_dir)\n",
    "    individual_dir = results_path / \"individual_results\"\n",
    "\n",
    "    # Verificar se diretório existe\n",
    "    if not individual_dir.exists():\n",
    "        print(f\"❌ Diretório não encontrado: {individual_dir}\")\n",
    "        return None\n",
    "\n",
    "    # Encontrar todos os arquivos de resultado\n",
    "    result_files = list(individual_dir.glob(\"*_result.csv\"))\n",
    "\n",
    "    if not result_files:\n",
    "        print(f\"❌ Nenhum arquivo de resultado encontrado em: {individual_dir}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"✓ Encontrados {len(result_files)} arquivos de resultado\")\n",
    "    print(f\"  Diretório: {individual_dir}\\n\")\n",
    "\n",
    "    # Ler todos os resultados\n",
    "    all_results = []\n",
    "\n",
    "    for result_file in result_files:\n",
    "        try:\n",
    "            df = pd.read_csv(result_file)\n",
    "            all_results.append(df)\n",
    "            dataset_name = result_file.stem.replace(\"_result\", \"\")\n",
    "            print(f\"  ✓ {dataset_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Erro ao ler {result_file.name}: {e}\")\n",
    "\n",
    "    if not all_results:\n",
    "        print(\"\\n❌ Nenhum resultado foi carregado com sucesso\")\n",
    "        return None\n",
    "\n",
    "    # Concatenar todos os resultados\n",
    "    df_all = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "    # Ordenar por dataset\n",
    "    df_all = df_all.sort_values(\"dataset\").reset_index(drop=True)\n",
    "\n",
    "    # Selecionar colunas importantes para o CSV de métricas\n",
    "    metric_columns = [\n",
    "        \"dataset\",\n",
    "        \"model\",\n",
    "        \"accuracy\",\n",
    "        \"auc_ovo\",\n",
    "        \"gmean\",\n",
    "        \"cross_entropy\",\n",
    "    ]\n",
    "\n",
    "    # Adicionar colunas opcionais se existirem\n",
    "    optional_columns = [\n",
    "        \"n_samples_train\",\n",
    "        \"n_samples_test\",\n",
    "        \"n_features\",\n",
    "        \"n_classes\",\n",
    "        \"tuning_time\",\n",
    "        \"training_time\",\n",
    "        \"prediction_time\",\n",
    "        \"total_time\",\n",
    "    ]\n",
    "\n",
    "    for col in optional_columns:\n",
    "        if col in df_all.columns:\n",
    "            metric_columns.append(col)\n",
    "\n",
    "    # Filtrar apenas as colunas que existem\n",
    "    metric_columns = [col for col in metric_columns if col in df_all.columns]\n",
    "\n",
    "    df_metrics = df_all[metric_columns].copy()\n",
    "\n",
    "    # Definir nome do arquivo de saída\n",
    "    if output_filename is None:\n",
    "        output_filename = f\"{model_name}_metrics.csv\"\n",
    "\n",
    "    output_path = results_path / output_filename\n",
    "\n",
    "    # Salvar CSV\n",
    "    df_metrics.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"RESULTADOS AGREGADOS\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(f\"✓ Total de datasets: {len(df_metrics)}\")\n",
    "    print(f\"✓ Arquivo salvo: {output_path}\")\n",
    "    print(f\"✓ Colunas: {list(df_metrics.columns)}\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "    # Mostrar estatísticas\n",
    "    print(\"Estatísticas das Métricas:\")\n",
    "    print(df_metrics[[\"accuracy\", \"auc_ovo\", \"gmean\", \"cross_entropy\"]].describe())\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"DATASETS PROCESSADOS (ordenados alfabeticamente):\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    for idx, dataset in enumerate(df_metrics[\"dataset\"].sort_values(), 1):\n",
    "        print(f\"{idx:3d}. {dataset}\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "function_def",
   "metadata": {},
   "source": [
    "## Função Principal de Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c997914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments_for_model(\n",
    "    model_name: str,\n",
    "    use_gpu: bool = False,\n",
    "    gpu_id: int = 0,\n",
    "    n_trials: int = N_TRIALS,\n",
    "    cv_folds: int = CV_FOLDS,\n",
    "    seed: int = SEED,\n",
    "    cache_dir: str = \"./data/openml_cache\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Executa experimentos para um modelo específico em todos os datasets\n",
    "\n",
    "    Args:\n",
    "        model_name: Nome do modelo ('xgboost', 'catboost', ou 'lightgbm')\n",
    "        use_gpu: Se True, usa BoostingExperimentGPU. Se False, usa BoostingExperiment\n",
    "        gpu_id: ID da GPU a ser usada (0, 1, 2, ...)\n",
    "        n_trials: Número de trials do Optuna (padrão: 50)\n",
    "        cv_folds: Número de folds de validação cruzada (padrão: 10)\n",
    "        seed: Seed\n",
    "        cache_dir: Diretório com datasets processados\n",
    "    \"\"\"\n",
    "    # Configurar diretório de resultados\n",
    "    if use_gpu:\n",
    "        RESULTS_DIR = f\"./results/{model_name}_gpu\"\n",
    "    else:\n",
    "        RESULTS_DIR = f\"./results/{model_name}\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{model_name.upper()} - EXPERIMENT PIPELINE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Mode: {'GPU' if use_gpu else 'CPU'}\")\n",
    "    if use_gpu:\n",
    "        print(f\"GPU ID: {gpu_id}\")\n",
    "    print(f\"Seed: {seed}\")\n",
    "    print(f\"Optuna trials: {n_trials}\")\n",
    "    print(f\"CV folds: {cv_folds}\")\n",
    "    print(f\"Results directory: {RESULTS_DIR}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Initialize data processor and results manager\n",
    "    processor = DataProcessor(seed=seed, cache_dir=cache_dir)\n",
    "    results_manager = ResultsManager(save_dir=RESULTS_DIR, model_name=model_name)\n",
    "\n",
    "    # Find all processed PKL files\n",
    "    pkl_files = list(Path(cache_dir).glob(\"*_dataset.pkl\"))\n",
    "\n",
    "    if not pkl_files:\n",
    "        print(\"\\nNo processed datasets found!\")\n",
    "        print(f\"Looking in: {cache_dir}\")\n",
    "        print(\"\\nPlease run data.py first to download and process datasets.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n✓ Found {len(pkl_files)} processed datasets\\n\")\n",
    "\n",
    "    # Check GPU availability if requested\n",
    "    if use_gpu:\n",
    "        try:\n",
    "            import torch\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                print(f\"✓ GPU available: {torch.cuda.get_device_name(gpu_id)}\")\n",
    "                print(\n",
    "                    f\"  Memory: {torch.cuda.get_device_properties(gpu_id).total_memory / 1e9:.2f} GB\\n\"\n",
    "                )\n",
    "            else:\n",
    "                print(\"Warning: GPU requested but not available, using CPU\\n\")\n",
    "                use_gpu = False\n",
    "        except ImportError:\n",
    "            print(\"PyTorch not installed, cannot check GPU\")\n",
    "\n",
    "    # Run experiments on all datasets\n",
    "    failed_datasets = []\n",
    "\n",
    "    for idx, pkl_file in enumerate(pkl_files[18:], 1):\n",
    "        # Extract dataset name\n",
    "        dataset_name = pkl_file.stem.replace(\"_dataset\", \"\")\n",
    "\n",
    "        print(f\"\\n{'#' * 80}\")\n",
    "        print(f\"DATASET {idx}/{len(pkl_files)}: {dataset_name}\")\n",
    "        print(f\"{'#' * 80}\")\n",
    "\n",
    "        try:\n",
    "            # Load processed dataset (numpy arrays)\n",
    "            X_train, y_train, X_test, y_test = processor.load_or_process_dataset(\n",
    "                name=dataset_name\n",
    "            )\n",
    "\n",
    "            # Get number of classes\n",
    "            n_classes = len(set(y_train))\n",
    "\n",
    "            # Create experiment (GPU ou CPU)\n",
    "            if use_gpu:\n",
    "                # Usar versão GPU\n",
    "                experiment = BoostingExperimentGPU(\n",
    "                    dataset_name=dataset_name,\n",
    "                    X_train=X_train,\n",
    "                    y_train=y_train,\n",
    "                    X_test=X_test,\n",
    "                    y_test=y_test,\n",
    "                    n_classes=n_classes,\n",
    "                    model_type=model_name,\n",
    "                    n_trials=n_trials,\n",
    "                    cv_folds=cv_folds,\n",
    "                    seed=seed,\n",
    "                    use_gpu=True,\n",
    "                    gpu_id=gpu_id,\n",
    "                )\n",
    "            else:\n",
    "                # Usar versão CPU\n",
    "                experiment = BoostingExperiment(\n",
    "                    dataset_name=dataset_name,\n",
    "                    X_train=X_train,\n",
    "                    y_train=y_train,\n",
    "                    X_test=X_test,\n",
    "                    y_test=y_test,\n",
    "                    n_classes=n_classes,\n",
    "                    model_type=model_name,\n",
    "                    n_trials=n_trials,\n",
    "                    cv_folds=cv_folds,\n",
    "                    seed=seed,\n",
    "                    catboost_bootstrap_type=\"Bayesian\",\n",
    "                )\n",
    "\n",
    "            # Run complete experiment\n",
    "            results = experiment.run_complete_experiment()\n",
    "\n",
    "            # Extract metrics and info for saving\n",
    "            metrics = {\n",
    "                \"accuracy\": results[\"accuracy\"],\n",
    "                \"auc_ovo\": results[\"auc_ovo\"],\n",
    "                \"gmean\": results[\"gmean\"],\n",
    "                \"cross_entropy\": results[\"cross_entropy\"],\n",
    "            }\n",
    "\n",
    "            dataset_info = {\n",
    "                \"n_samples_train\": results[\"n_samples_train\"],\n",
    "                \"n_samples_test\": results[\"n_samples_test\"],\n",
    "                \"n_features\": results[\"n_features\"],\n",
    "                \"n_classes\": results[\"n_classes\"],\n",
    "            }\n",
    "\n",
    "            timings = {\n",
    "                \"tuning_time\": results[\"tuning_time\"],\n",
    "                \"training_time\": results[\"training_time\"],\n",
    "                \"prediction_time\": results[\"prediction_time\"],\n",
    "                \"total_time\": results[\"total_time\"],\n",
    "            }\n",
    "\n",
    "            # Adicionar info de GPU se disponível\n",
    "            if use_gpu and \"gpu_enabled\" in results:\n",
    "                timings[\"gpu_enabled\"] = results[\"gpu_enabled\"]\n",
    "\n",
    "            # Save results\n",
    "            results_manager.save_dataset_result(\n",
    "                dataset_name=dataset_name,\n",
    "                metrics=metrics,\n",
    "                dataset_info=dataset_info,\n",
    "                timings=timings,\n",
    "                hyperparameters=results[\"best_params\"],\n",
    "            )\n",
    "\n",
    "            print(f\"\\n✓ Completed {dataset_name} ({idx}/{len(pkl_files)})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ Failed: {dataset_name}\")\n",
    "            print(f\"   Error: {e}\")\n",
    "            failed_datasets.append((dataset_name, e))\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "    # ========================================================================\n",
    "    # Save final results\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SAVING FINAL RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Save metrics CSV (for hypothesis testing)\n",
    "    results_manager.save_metrics_csv()\n",
    "\n",
    "    # Print final summary\n",
    "    results_manager.print_summary()\n",
    "\n",
    "    # Print failed datasets if any\n",
    "    if failed_datasets:\n",
    "        print(f\"\\nFailed datasets ({len(failed_datasets)}):\")\n",
    "        for dataset, error in failed_datasets:\n",
    "            print(f\"  - {dataset}: {error}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"EXPERIMENT COMPLETE FOR {model_name.upper()}!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"✓ Total datasets: {len(pkl_files)}\")\n",
    "    print(f\"✓ Successful: {len(results_manager.all_results)}\")\n",
    "    print(f\"✓ Failed: {len(failed_datasets)}\")\n",
    "    print(f\"\\n✓ Metrics CSV saved: {RESULTS_DIR}/{model_name}_metrics.csv\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xgboost_section",
   "metadata": {},
   "source": [
    "## Experimentos com XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_xgboost",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments_for_model(\"xgboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30310e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Encontrados 30 arquivos de resultado\n",
      "  Diretório: results\\xgboost\\individual_results\n",
      "\n",
      "  ✓ analcatdata_authorship\n",
      "  ✓ analcatdata_dmft\n",
      "  ✓ balance-scale\n",
      "  ✓ banknote-authentication\n",
      "  ✓ blood-transfusion-service-center\n",
      "  ✓ breast-w\n",
      "  ✓ car\n",
      "  ✓ climate-model-simulation-crashes\n",
      "  ✓ cmc\n",
      "  ✓ cnae-9\n",
      "  ✓ credit-approval\n",
      "  ✓ credit-g\n",
      "  ✓ cylinder-bands\n",
      "  ✓ diabetes\n",
      "  ✓ dresses-sales\n",
      "  ✓ eucalyptus\n",
      "  ✓ ilpd\n",
      "  ✓ kc2\n",
      "  ✓ mfeat-factors\n",
      "  ✓ MiceProtein\n",
      "  ✓ pc1\n",
      "  ✓ pc3\n",
      "  ✓ pc4\n",
      "  ✓ qsar-biodeg\n",
      "  ✓ semeion\n",
      "  ✓ steel-plates-fault\n",
      "  ✓ tic-tac-toe\n",
      "  ✓ vehicle\n",
      "  ✓ vowel\n",
      "  ✓ wdbc\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS AGREGADOS\n",
      "================================================================================\n",
      "✓ Total de datasets: 30\n",
      "✓ Arquivo salvo: results\\xgboost\\xgboost_metrics.csv\n",
      "✓ Colunas: ['dataset', 'model', 'accuracy', 'auc_ovo', 'gmean', 'cross_entropy', 'n_samples_train', 'n_samples_test', 'n_features', 'n_classes', 'tuning_time', 'training_time', 'prediction_time', 'total_time']\n",
      "================================================================================\n",
      "\n",
      "Estatísticas das Métricas:\n",
      "        accuracy    auc_ovo      gmean  cross_entropy\n",
      "count  30.000000  30.000000  30.000000      30.000000\n",
      "mean    0.827895   0.883850   0.734336       0.408210\n",
      "std     0.169569   0.127676   0.206982       0.340109\n",
      "min     0.236181   0.551220   0.231849       0.030669\n",
      "25%     0.754935   0.805616   0.600548       0.182740\n",
      "50%     0.890411   0.920841   0.715342       0.356142\n",
      "75%     0.936596   0.995384   0.926170       0.522091\n",
      "max     0.996528   0.999976   0.995084       1.698971\n",
      "\n",
      "================================================================================\n",
      "DATASETS PROCESSADOS (ordenados alfabeticamente):\n",
      "================================================================================\n",
      "  1. MiceProtein\n",
      "  2. analcatdata_authorship\n",
      "  3. analcatdata_dmft\n",
      "  4. balance-scale\n",
      "  5. banknote-authentication\n",
      "  6. blood-transfusion-service-center\n",
      "  7. breast-w\n",
      "  8. car\n",
      "  9. climate-model-simulation-crashes\n",
      " 10. cmc\n",
      " 11. cnae-9\n",
      " 12. credit-approval\n",
      " 13. credit-g\n",
      " 14. cylinder-bands\n",
      " 15. diabetes\n",
      " 16. dresses-sales\n",
      " 17. eucalyptus\n",
      " 18. ilpd\n",
      " 19. kc2\n",
      " 20. mfeat-factors\n",
      " 21. pc1\n",
      " 22. pc3\n",
      " 23. pc4\n",
      " 24. qsar-biodeg\n",
      " 25. semeion\n",
      " 26. steel-plates-fault\n",
      " 27. tic-tac-toe\n",
      " 28. vehicle\n",
      " 29. vowel\n",
      " 30. wdbc\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc_ovo</th>\n",
       "      <th>gmean</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>n_samples_train</th>\n",
       "      <th>n_samples_test</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>tuning_time</th>\n",
       "      <th>training_time</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MiceProtein</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.999671</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.180083</td>\n",
       "      <td>756</td>\n",
       "      <td>324</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>1157.593033</td>\n",
       "      <td>3.263902</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>1160.865796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>analcatdata_authorship</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.980237</td>\n",
       "      <td>0.997829</td>\n",
       "      <td>0.959238</td>\n",
       "      <td>0.069780</td>\n",
       "      <td>588</td>\n",
       "      <td>253</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>1.469057</td>\n",
       "      <td>0.137714</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>1.609781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>analcatdata_dmft</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.236181</td>\n",
       "      <td>0.551220</td>\n",
       "      <td>0.231849</td>\n",
       "      <td>1.698971</td>\n",
       "      <td>462</td>\n",
       "      <td>199</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>175.707135</td>\n",
       "      <td>0.207949</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>175.922066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balance-scale</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.909574</td>\n",
       "      <td>0.960476</td>\n",
       "      <td>0.628629</td>\n",
       "      <td>0.217733</td>\n",
       "      <td>437</td>\n",
       "      <td>188</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>121.686057</td>\n",
       "      <td>0.272283</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>121.962329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.995084</td>\n",
       "      <td>0.030669</td>\n",
       "      <td>960</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>64.321503</td>\n",
       "      <td>0.103219</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>64.426717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blood-transfusion-service-center</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.804444</td>\n",
       "      <td>0.746968</td>\n",
       "      <td>0.627332</td>\n",
       "      <td>0.486186</td>\n",
       "      <td>523</td>\n",
       "      <td>225</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>49.850096</td>\n",
       "      <td>0.072315</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>49.926400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>breast-w</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.938095</td>\n",
       "      <td>0.979217</td>\n",
       "      <td>0.936275</td>\n",
       "      <td>0.160601</td>\n",
       "      <td>489</td>\n",
       "      <td>210</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>54.327947</td>\n",
       "      <td>0.092259</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>54.422201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>car</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.967245</td>\n",
       "      <td>0.996231</td>\n",
       "      <td>0.904439</td>\n",
       "      <td>0.101350</td>\n",
       "      <td>1209</td>\n",
       "      <td>519</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>176.548280</td>\n",
       "      <td>0.253339</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>176.809598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>climate-model-simulation-crashes</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.884170</td>\n",
       "      <td>0.530899</td>\n",
       "      <td>0.229605</td>\n",
       "      <td>378</td>\n",
       "      <td>162</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>42.255156</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>42.351899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cmc</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.711147</td>\n",
       "      <td>0.495561</td>\n",
       "      <td>0.953966</td>\n",
       "      <td>1031</td>\n",
       "      <td>442</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>150.862976</td>\n",
       "      <td>0.385980</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>151.252947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cnae-9</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.995660</td>\n",
       "      <td>0.931083</td>\n",
       "      <td>0.259820</td>\n",
       "      <td>756</td>\n",
       "      <td>324</td>\n",
       "      <td>856</td>\n",
       "      <td>9</td>\n",
       "      <td>665.796918</td>\n",
       "      <td>0.506645</td>\n",
       "      <td>0.013602</td>\n",
       "      <td>666.317165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>credit-approval</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.874396</td>\n",
       "      <td>0.917202</td>\n",
       "      <td>0.874983</td>\n",
       "      <td>0.384895</td>\n",
       "      <td>483</td>\n",
       "      <td>207</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>74.108584</td>\n",
       "      <td>0.101237</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>74.211816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>credit-g</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.761534</td>\n",
       "      <td>0.665555</td>\n",
       "      <td>0.615725</td>\n",
       "      <td>700</td>\n",
       "      <td>300</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>69.744749</td>\n",
       "      <td>0.112206</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>69.858950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cylinder-bands</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.746914</td>\n",
       "      <td>0.832760</td>\n",
       "      <td>0.716339</td>\n",
       "      <td>0.496541</td>\n",
       "      <td>378</td>\n",
       "      <td>162</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>85.471758</td>\n",
       "      <td>0.089268</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>85.563021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.827572</td>\n",
       "      <td>0.714345</td>\n",
       "      <td>0.484669</td>\n",
       "      <td>537</td>\n",
       "      <td>231</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>85.527027</td>\n",
       "      <td>0.161075</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>85.691094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dresses-sales</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.555738</td>\n",
       "      <td>0.495188</td>\n",
       "      <td>0.790888</td>\n",
       "      <td>350</td>\n",
       "      <td>150</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>80.000122</td>\n",
       "      <td>0.238868</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>80.241983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eucalyptus</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.656109</td>\n",
       "      <td>0.896045</td>\n",
       "      <td>0.591620</td>\n",
       "      <td>0.815812</td>\n",
       "      <td>515</td>\n",
       "      <td>221</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>240.519258</td>\n",
       "      <td>0.195981</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>240.718231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ilpd</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.708571</td>\n",
       "      <td>0.765440</td>\n",
       "      <td>0.576888</td>\n",
       "      <td>0.622456</td>\n",
       "      <td>408</td>\n",
       "      <td>175</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>58.470544</td>\n",
       "      <td>0.109215</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>58.581754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kc2</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.821656</td>\n",
       "      <td>0.787625</td>\n",
       "      <td>0.672309</td>\n",
       "      <td>0.425620</td>\n",
       "      <td>365</td>\n",
       "      <td>157</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>59.085383</td>\n",
       "      <td>0.086768</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>59.174146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mfeat-factors</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.998074</td>\n",
       "      <td>0.957432</td>\n",
       "      <td>0.143545</td>\n",
       "      <td>1400</td>\n",
       "      <td>600</td>\n",
       "      <td>216</td>\n",
       "      <td>10</td>\n",
       "      <td>1716.482015</td>\n",
       "      <td>4.033216</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>1720.526201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pc1</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.930931</td>\n",
       "      <td>0.861571</td>\n",
       "      <td>0.414330</td>\n",
       "      <td>0.190712</td>\n",
       "      <td>776</td>\n",
       "      <td>333</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>52.959945</td>\n",
       "      <td>0.073803</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>53.035743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pc3</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.878465</td>\n",
       "      <td>0.798298</td>\n",
       "      <td>0.399921</td>\n",
       "      <td>0.344292</td>\n",
       "      <td>1094</td>\n",
       "      <td>469</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>91.507332</td>\n",
       "      <td>0.376992</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>91.888314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pc4</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.908676</td>\n",
       "      <td>0.927665</td>\n",
       "      <td>0.688478</td>\n",
       "      <td>0.231236</td>\n",
       "      <td>1020</td>\n",
       "      <td>438</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>60.014045</td>\n",
       "      <td>0.140624</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>60.156664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qsar-biodeg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.839117</td>\n",
       "      <td>0.893413</td>\n",
       "      <td>0.807839</td>\n",
       "      <td>0.387634</td>\n",
       "      <td>738</td>\n",
       "      <td>317</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>87.314304</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>87.443957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>semeion</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.914226</td>\n",
       "      <td>0.995579</td>\n",
       "      <td>0.911432</td>\n",
       "      <td>0.268401</td>\n",
       "      <td>1115</td>\n",
       "      <td>478</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>540.193124</td>\n",
       "      <td>1.012293</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>541.214393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>steel-plates-fault</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.787307</td>\n",
       "      <td>0.966780</td>\n",
       "      <td>0.786807</td>\n",
       "      <td>0.568251</td>\n",
       "      <td>1358</td>\n",
       "      <td>583</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>408.214044</td>\n",
       "      <td>0.997331</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>409.222346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tic-tac-toe</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.996528</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.066747</td>\n",
       "      <td>670</td>\n",
       "      <td>288</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>63.020505</td>\n",
       "      <td>0.213429</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>63.238921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>vehicle</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.728346</td>\n",
       "      <td>0.924480</td>\n",
       "      <td>0.689410</td>\n",
       "      <td>0.530607</td>\n",
       "      <td>592</td>\n",
       "      <td>254</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>163.015154</td>\n",
       "      <td>0.405914</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>163.426056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vowel</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.902357</td>\n",
       "      <td>0.994800</td>\n",
       "      <td>0.899189</td>\n",
       "      <td>0.367991</td>\n",
       "      <td>693</td>\n",
       "      <td>297</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>686.903587</td>\n",
       "      <td>1.688485</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>688.602046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>wdbc</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>0.960979</td>\n",
       "      <td>0.121513</td>\n",
       "      <td>398</td>\n",
       "      <td>171</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>61.603296</td>\n",
       "      <td>0.148601</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>61.752894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dataset    model  accuracy   auc_ovo     gmean  \\\n",
       "0                        MiceProtein  xgboost  0.972222  0.999671  0.971667   \n",
       "1             analcatdata_authorship  xgboost  0.980237  0.997829  0.959238   \n",
       "2                   analcatdata_dmft  xgboost  0.236181  0.551220  0.231849   \n",
       "3                      balance-scale  xgboost  0.909574  0.960476  0.628629   \n",
       "4            banknote-authentication  xgboost  0.995146  0.999976  0.995084   \n",
       "5   blood-transfusion-service-center  xgboost  0.804444  0.746968  0.627332   \n",
       "6                           breast-w  xgboost  0.938095  0.979217  0.936275   \n",
       "7                                car  xgboost  0.967245  0.996231  0.904439   \n",
       "8   climate-model-simulation-crashes  xgboost  0.925926  0.884170  0.530899   \n",
       "9                                cmc  xgboost  0.518100  0.711147  0.495561   \n",
       "10                            cnae-9  xgboost  0.932099  0.995660  0.931083   \n",
       "11                   credit-approval  xgboost  0.874396  0.917202  0.874983   \n",
       "12                          credit-g  xgboost  0.760000  0.761534  0.665555   \n",
       "13                    cylinder-bands  xgboost  0.746914  0.832760  0.716339   \n",
       "14                          diabetes  xgboost  0.753247  0.827572  0.714345   \n",
       "15                     dresses-sales  xgboost  0.533333  0.555738  0.495188   \n",
       "16                        eucalyptus  xgboost  0.656109  0.896045  0.591620   \n",
       "17                              ilpd  xgboost  0.708571  0.765440  0.576888   \n",
       "18                               kc2  xgboost  0.821656  0.787625  0.672309   \n",
       "19                     mfeat-factors  xgboost  0.958333  0.998074  0.957432   \n",
       "20                               pc1  xgboost  0.930931  0.861571  0.414330   \n",
       "21                               pc3  xgboost  0.878465  0.798298  0.399921   \n",
       "22                               pc4  xgboost  0.908676  0.927665  0.688478   \n",
       "23                       qsar-biodeg  xgboost  0.839117  0.893413  0.807839   \n",
       "24                           semeion  xgboost  0.914226  0.995579  0.911432   \n",
       "25                steel-plates-fault  xgboost  0.787307  0.966780  0.786807   \n",
       "26                       tic-tac-toe  xgboost  0.996528  0.999894  0.994987   \n",
       "27                           vehicle  xgboost  0.728346  0.924480  0.689410   \n",
       "28                             vowel  xgboost  0.902357  0.994800  0.899189   \n",
       "29                              wdbc  xgboost  0.959064  0.988464  0.960979   \n",
       "\n",
       "    cross_entropy  n_samples_train  n_samples_test  n_features  n_classes  \\\n",
       "0        0.180083              756             324          77          8   \n",
       "1        0.069780              588             253          70          4   \n",
       "2        1.698971              462             199           7          5   \n",
       "3        0.217733              437             188           4          3   \n",
       "4        0.030669              960             412           4          2   \n",
       "5        0.486186              523             225           4          2   \n",
       "6        0.160601              489             210           9          2   \n",
       "7        0.101350             1209             519          21          4   \n",
       "8        0.229605              378             162          18          2   \n",
       "9        0.953966             1031             442           9          3   \n",
       "10       0.259820              756             324         856          9   \n",
       "11       0.384895              483             207          46          2   \n",
       "12       0.615725              700             300          61          2   \n",
       "13       0.496541              378             162         119          2   \n",
       "14       0.484669              537             231           8          2   \n",
       "15       0.790888              350             150         141          2   \n",
       "16       0.815812              515             221          91          5   \n",
       "17       0.622456              408             175          11          2   \n",
       "18       0.425620              365             157          21          2   \n",
       "19       0.143545             1400             600         216         10   \n",
       "20       0.190712              776             333          21          2   \n",
       "21       0.344292             1094             469          37          2   \n",
       "22       0.231236             1020             438          37          2   \n",
       "23       0.387634              738             317          41          2   \n",
       "24       0.268401             1115             478         256         10   \n",
       "25       0.568251             1358             583          27          7   \n",
       "26       0.066747              670             288          27          2   \n",
       "27       0.530607              592             254          18          4   \n",
       "28       0.367991              693             297          27         11   \n",
       "29       0.121513              398             171          30          2   \n",
       "\n",
       "    tuning_time  training_time  prediction_time   total_time  \n",
       "0   1157.593033       3.263902         0.008860  1160.865796  \n",
       "1      1.469057       0.137714         0.003011     1.609781  \n",
       "2    175.707135       0.207949         0.006982   175.922066  \n",
       "3    121.686057       0.272283         0.003989   121.962329  \n",
       "4     64.321503       0.103219         0.001995    64.426717  \n",
       "5     49.850096       0.072315         0.003990    49.926400  \n",
       "6     54.327947       0.092259         0.001995    54.422201  \n",
       "7    176.548280       0.253339         0.007979   176.809598  \n",
       "8     42.255156       0.095745         0.000997    42.351899  \n",
       "9    150.862976       0.385980         0.003990   151.252947  \n",
       "10   665.796918       0.506645         0.013602   666.317165  \n",
       "11    74.108584       0.101237         0.001995    74.211816  \n",
       "12    69.744749       0.112206         0.001996    69.858950  \n",
       "13    85.471758       0.089268         0.001995    85.563021  \n",
       "14    85.527027       0.161075         0.002992    85.691094  \n",
       "15    80.000122       0.238868         0.002993    80.241983  \n",
       "16   240.519258       0.195981         0.002993   240.718231  \n",
       "17    58.470544       0.109215         0.001995    58.581754  \n",
       "18    59.085383       0.086768         0.001994    59.174146  \n",
       "19  1716.482015       4.033216         0.010971  1720.526201  \n",
       "20    52.959945       0.073803         0.001995    53.035743  \n",
       "21    91.507332       0.376992         0.003990    91.888314  \n",
       "22    60.014045       0.140624         0.001995    60.156664  \n",
       "23    87.314304       0.127659         0.001994    87.443957  \n",
       "24   540.193124       1.012293         0.008976   541.214393  \n",
       "25   408.214044       0.997331         0.010971   409.222346  \n",
       "26    63.020505       0.213429         0.004987    63.238921  \n",
       "27   163.015154       0.405914         0.004988   163.426056  \n",
       "28   686.903587       1.688485         0.009974   688.602046  \n",
       "29    61.603296       0.148601         0.000998    61.752894  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_results(results_dir=\"./results/xgboost\", model_name=\"xgboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catboost_section",
   "metadata": {},
   "source": [
    "## Experimentos com CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "run_catboost",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 00:47:03,371] A new study created in memory with name: no-name-0a7dfa76-5156-46d4-8b90-84759eb30d1c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CATBOOST - EXPERIMENT PIPELINE\n",
      "================================================================================\n",
      "Model: catboost\n",
      "Mode: GPU\n",
      "GPU ID: 0\n",
      "Seed: 123\n",
      "Optuna trials: 50\n",
      "CV folds: 10\n",
      "Results directory: ./results/catboost_gpu\n",
      "================================================================================\n",
      "\n",
      "✓ Found 30 processed datasets\n",
      "\n",
      "✓ GPU available: NVIDIA GeForce RTX 3060\n",
      "  Memory: 12.88 GB\n",
      "\n",
      "\n",
      "################################################################################\n",
      "DATASET 1/30: analcatdata_authorship\n",
      "################################################################################\n",
      "Loading processed dataset from cache: analcatdata_authorship\n",
      "Dataset: analcatdata_authorship\n",
      "  Train: (588, 70), Test: (253, 70)\n",
      "  Features: 70, Classes: 4\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: analcatdata_authorship\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 1342.31s\n",
      "  Best CV G-Mean: 0.9873\n",
      "  Best parameters:\n",
      "    iterations: 94\n",
      "    depth: 3\n",
      "    learning_rate: 0.28977739923128126\n",
      "    l2_leaf_reg: 1.0725502906361868\n",
      "    bagging_temperature: 0.04648413599350565\n",
      "    min_data_in_leaf: 49\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.81s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR analcatdata_authorship\n",
      "================================================================================\n",
      "Accuracy:        0.9763\n",
      "AUC OVO:         0.9919\n",
      "G-Mean:          0.9587\n",
      "Cross-Entropy:   0.0759\n",
      "================================================================================\n",
      "Tuning Time:     1342.31s\n",
      "Training Time:   0.81s\n",
      "Total Time:      1343.11s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for analcatdata_authorship\n",
      "\n",
      "✓ Completed analcatdata_authorship (1/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 2/30: analcatdata_dmft\n",
      "################################################################################\n",
      "Loading processed dataset from cache: analcatdata_dmft\n",
      "Dataset: analcatdata_dmft\n",
      "  Train: (462, 7), Test: (199, 7)\n",
      "  Features: 7, Classes: 5\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: analcatdata_dmft\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 612.77s\n",
      "  Best CV G-Mean: 0.1926\n",
      "  Best parameters:\n",
      "    iterations: 61\n",
      "    depth: 8\n",
      "    learning_rate: 0.018834480380386723\n",
      "    l2_leaf_reg: 5.333346830049678\n",
      "    bagging_temperature: 0.10189499224697596\n",
      "    min_data_in_leaf: 10\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.94s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR analcatdata_dmft\n",
      "================================================================================\n",
      "Accuracy:        0.2211\n",
      "AUC OVO:         0.5393\n",
      "G-Mean:          0.2029\n",
      "Cross-Entropy:   1.6052\n",
      "================================================================================\n",
      "Tuning Time:     612.77s\n",
      "Training Time:   0.94s\n",
      "Total Time:      613.71s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for analcatdata_dmft\n",
      "\n",
      "✓ Completed analcatdata_dmft (2/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 3/30: balance-scale\n",
      "################################################################################\n",
      "Loading processed dataset from cache: balance-scale\n",
      "Dataset: balance-scale\n",
      "  Train: (437, 4), Test: (188, 4)\n",
      "  Features: 4, Classes: 3\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: balance-scale\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 897.55s\n",
      "  Best CV G-Mean: 0.2837\n",
      "  Best parameters:\n",
      "    iterations: 457\n",
      "    depth: 5\n",
      "    learning_rate: 0.23196088905161624\n",
      "    l2_leaf_reg: 4.746476812108133\n",
      "    bagging_temperature: 0.10592114071261152\n",
      "    min_data_in_leaf: 21\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.59s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR balance-scale\n",
      "================================================================================\n",
      "Accuracy:        0.9043\n",
      "AUC OVO:         0.9463\n",
      "G-Mean:          0.5010\n",
      "Cross-Entropy:   0.2628\n",
      "================================================================================\n",
      "Tuning Time:     897.55s\n",
      "Training Time:   1.59s\n",
      "Total Time:      899.14s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for balance-scale\n",
      "\n",
      "✓ Completed balance-scale (3/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 4/30: banknote-authentication\n",
      "################################################################################\n",
      "Loading processed dataset from cache: banknote-authentication\n",
      "Dataset: banknote-authentication\n",
      "  Train: (960, 4), Test: (412, 4)\n",
      "  Features: 4, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: banknote-authentication\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 1328.16s\n",
      "  Best CV G-Mean: 0.9981\n",
      "  Best parameters:\n",
      "    iterations: 414\n",
      "    depth: 8\n",
      "    learning_rate: 0.23844861963607764\n",
      "    l2_leaf_reg: 1.9292208459463318\n",
      "    bagging_temperature: 0.3334255467623599\n",
      "    min_data_in_leaf: 19\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 4.39s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR banknote-authentication\n",
      "================================================================================\n",
      "Accuracy:        0.9976\n",
      "AUC OVO:         1.0000\n",
      "G-Mean:          0.9973\n",
      "Cross-Entropy:   0.0091\n",
      "================================================================================\n",
      "Tuning Time:     1328.16s\n",
      "Training Time:   4.39s\n",
      "Total Time:      1332.56s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for banknote-authentication\n",
      "\n",
      "✓ Completed banknote-authentication (4/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 5/30: blood-transfusion-service-center\n",
      "################################################################################\n",
      "Loading processed dataset from cache: blood-transfusion-service-center\n",
      "Dataset: blood-transfusion-service-center\n",
      "  Train: (523, 4), Test: (225, 4)\n",
      "  Features: 4, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: blood-transfusion-service-center\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 620.63s\n",
      "  Best CV G-Mean: 0.5159\n",
      "  Best parameters:\n",
      "    iterations: 62\n",
      "    depth: 9\n",
      "    learning_rate: 0.2958374071333366\n",
      "    l2_leaf_reg: 8.012058853354654\n",
      "    bagging_temperature: 0.921425151122152\n",
      "    min_data_in_leaf: 4\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.80s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR blood-transfusion-service-center\n",
      "================================================================================\n",
      "Accuracy:        0.7911\n",
      "AUC OVO:         0.7444\n",
      "G-Mean:          0.5850\n",
      "Cross-Entropy:   0.4814\n",
      "================================================================================\n",
      "Tuning Time:     620.63s\n",
      "Training Time:   0.80s\n",
      "Total Time:      621.43s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for blood-transfusion-service-center\n",
      "\n",
      "✓ Completed blood-transfusion-service-center (5/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 6/30: breast-w\n",
      "################################################################################\n",
      "Loading processed dataset from cache: breast-w\n",
      "Dataset: breast-w\n",
      "  Train: (489, 9), Test: (210, 9)\n",
      "  Features: 9, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: breast-w\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 765.20s\n",
      "  Best CV G-Mean: 0.9800\n",
      "  Best parameters:\n",
      "    iterations: 364\n",
      "    depth: 5\n",
      "    learning_rate: 0.021631523301351215\n",
      "    l2_leaf_reg: 5.961832921746021\n",
      "    bagging_temperature: 0.7194689697855631\n",
      "    min_data_in_leaf: 22\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.65s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR breast-w\n",
      "================================================================================\n",
      "Accuracy:        0.9429\n",
      "AUC OVO:         0.9831\n",
      "G-Mean:          0.9399\n",
      "Cross-Entropy:   0.1414\n",
      "================================================================================\n",
      "Tuning Time:     765.20s\n",
      "Training Time:   1.65s\n",
      "Total Time:      766.85s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for breast-w\n",
      "\n",
      "✓ Completed breast-w (6/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 7/30: car\n",
      "################################################################################\n",
      "Loading processed dataset from cache: car\n",
      "Dataset: car\n",
      "  Train: (1209, 21), Test: (519, 21)\n",
      "  Features: 21, Classes: 4\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: car\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 1985.25s\n",
      "  Best CV G-Mean: 0.9633\n",
      "  Best parameters:\n",
      "    iterations: 373\n",
      "    depth: 3\n",
      "    learning_rate: 0.09473927972610038\n",
      "    l2_leaf_reg: 2.6734490067203267\n",
      "    bagging_temperature: 0.158252688661779\n",
      "    min_data_in_leaf: 34\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.83s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR car\n",
      "================================================================================\n",
      "Accuracy:        0.9807\n",
      "AUC OVO:         0.9998\n",
      "G-Mean:          0.9817\n",
      "Cross-Entropy:   0.0854\n",
      "================================================================================\n",
      "Tuning Time:     1985.25s\n",
      "Training Time:   1.83s\n",
      "Total Time:      1987.09s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for car\n",
      "\n",
      "✓ Completed car (7/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 8/30: climate-model-simulation-crashes\n",
      "################################################################################\n",
      "Loading processed dataset from cache: climate-model-simulation-crashes\n",
      "Dataset: climate-model-simulation-crashes\n",
      "  Train: (378, 18), Test: (162, 18)\n",
      "  Features: 18, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: climate-model-simulation-crashes\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 1009.21s\n",
      "  Best CV G-Mean: 0.6456\n",
      "  Best parameters:\n",
      "    iterations: 233\n",
      "    depth: 9\n",
      "    learning_rate: 0.2057411899326481\n",
      "    l2_leaf_reg: 5.632005019565198\n",
      "    bagging_temperature: 0.6502732236960761\n",
      "    min_data_in_leaf: 7\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.59s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR climate-model-simulation-crashes\n",
      "================================================================================\n",
      "Accuracy:        0.9198\n",
      "AUC OVO:         0.8673\n",
      "G-Mean:          0.4598\n",
      "Cross-Entropy:   0.2169\n",
      "================================================================================\n",
      "Tuning Time:     1009.21s\n",
      "Training Time:   1.59s\n",
      "Total Time:      1010.80s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for climate-model-simulation-crashes\n",
      "\n",
      "✓ Completed climate-model-simulation-crashes (8/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 9/30: cmc\n",
      "################################################################################\n",
      "Loading processed dataset from cache: cmc\n",
      "Dataset: cmc\n",
      "  Train: (1031, 9), Test: (442, 9)\n",
      "  Features: 9, Classes: 3\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: cmc\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 1508.88s\n",
      "  Best CV G-Mean: 0.5648\n",
      "  Best parameters:\n",
      "    iterations: 119\n",
      "    depth: 8\n",
      "    learning_rate: 0.017796196529312927\n",
      "    l2_leaf_reg: 7.364801013359984\n",
      "    bagging_temperature: 0.6221801027067312\n",
      "    min_data_in_leaf: 36\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.67s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR cmc\n",
      "================================================================================\n",
      "Accuracy:        0.5271\n",
      "AUC OVO:         0.7004\n",
      "G-Mean:          0.5124\n",
      "Cross-Entropy:   0.9773\n",
      "================================================================================\n",
      "Tuning Time:     1508.88s\n",
      "Training Time:   1.67s\n",
      "Total Time:      1510.55s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for cmc\n",
      "\n",
      "✓ Completed cmc (9/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 10/30: cnae-9\n",
      "################################################################################\n",
      "Loading processed dataset from cache: cnae-9\n",
      "Dataset: cnae-9\n",
      "  Train: (756, 856), Test: (324, 856)\n",
      "  Features: 856, Classes: 9\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: cnae-9\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 1080.07s\n",
      "  Best CV G-Mean: 0.9080\n",
      "  Best parameters:\n",
      "    iterations: 89\n",
      "    depth: 6\n",
      "    learning_rate: 0.2734435689158948\n",
      "    l2_leaf_reg: 1.0003475480920438\n",
      "    bagging_temperature: 0.017547791934038645\n",
      "    min_data_in_leaf: 5\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.53s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR cnae-9\n",
      "================================================================================\n",
      "Accuracy:        0.9383\n",
      "AUC OVO:         0.9966\n",
      "G-Mean:          0.9372\n",
      "Cross-Entropy:   0.2906\n",
      "================================================================================\n",
      "Tuning Time:     1080.07s\n",
      "Training Time:   1.53s\n",
      "Total Time:      1081.60s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for cnae-9\n",
      "\n",
      "✓ Completed cnae-9 (10/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 11/30: credit-approval\n",
      "################################################################################\n",
      "Loading processed dataset from cache: credit-approval\n",
      "Dataset: credit-approval\n",
      "  Train: (483, 46), Test: (207, 46)\n",
      "  Features: 46, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: credit-approval\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 698.94s\n",
      "  Best CV G-Mean: 0.8721\n",
      "  Best parameters:\n",
      "    iterations: 449\n",
      "    depth: 4\n",
      "    learning_rate: 0.27677327263382834\n",
      "    l2_leaf_reg: 6.4356961131295485\n",
      "    bagging_temperature: 0.8760204694215238\n",
      "    min_data_in_leaf: 24\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.00s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR credit-approval\n",
      "================================================================================\n",
      "Accuracy:        0.8696\n",
      "AUC OVO:         0.9312\n",
      "G-Mean:          0.8672\n",
      "Cross-Entropy:   0.3334\n",
      "================================================================================\n",
      "Tuning Time:     698.94s\n",
      "Training Time:   1.00s\n",
      "Total Time:      699.94s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for credit-approval\n",
      "\n",
      "✓ Completed credit-approval (11/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 12/30: credit-g\n",
      "################################################################################\n",
      "Loading processed dataset from cache: credit-g\n",
      "Dataset: credit-g\n",
      "  Train: (700, 61), Test: (300, 61)\n",
      "  Features: 61, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: credit-g\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 713.76s\n",
      "  Best CV G-Mean: 0.6657\n",
      "  Best parameters:\n",
      "    iterations: 225\n",
      "    depth: 4\n",
      "    learning_rate: 0.29802247237380397\n",
      "    l2_leaf_reg: 3.610878531680354\n",
      "    bagging_temperature: 0.8159775662392736\n",
      "    min_data_in_leaf: 47\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.87s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR credit-g\n",
      "================================================================================\n",
      "Accuracy:        0.7533\n",
      "AUC OVO:         0.7863\n",
      "G-Mean:          0.6274\n",
      "Cross-Entropy:   0.4965\n",
      "================================================================================\n",
      "Tuning Time:     713.76s\n",
      "Training Time:   0.87s\n",
      "Total Time:      714.64s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for credit-g\n",
      "\n",
      "✓ Completed credit-g (12/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 13/30: cylinder-bands\n",
      "################################################################################\n",
      "Loading processed dataset from cache: cylinder-bands\n",
      "Dataset: cylinder-bands\n",
      "  Train: (378, 119), Test: (162, 119)\n",
      "  Features: 119, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: cylinder-bands\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 704.58s\n",
      "  Best CV G-Mean: 0.8184\n",
      "  Best parameters:\n",
      "    iterations: 207\n",
      "    depth: 5\n",
      "    learning_rate: 0.11562628761999123\n",
      "    l2_leaf_reg: 2.861263050468632\n",
      "    bagging_temperature: 0.783166287164034\n",
      "    min_data_in_leaf: 25\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.89s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR cylinder-bands\n",
      "================================================================================\n",
      "Accuracy:        0.7469\n",
      "AUC OVO:         0.8168\n",
      "G-Mean:          0.7244\n",
      "Cross-Entropy:   0.5498\n",
      "================================================================================\n",
      "Tuning Time:     704.58s\n",
      "Training Time:   1.89s\n",
      "Total Time:      706.48s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for cylinder-bands\n",
      "\n",
      "✓ Completed cylinder-bands (13/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 14/30: diabetes\n",
      "################################################################################\n",
      "Loading processed dataset from cache: diabetes\n",
      "Dataset: diabetes\n",
      "  Train: (537, 8), Test: (231, 8)\n",
      "  Features: 8, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: diabetes\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 504.82s\n",
      "  Best CV G-Mean: 0.6965\n",
      "  Best parameters:\n",
      "    iterations: 305\n",
      "    depth: 3\n",
      "    learning_rate: 0.12609833389120095\n",
      "    l2_leaf_reg: 7.941633505739114\n",
      "    bagging_temperature: 0.3249626718181696\n",
      "    min_data_in_leaf: 37\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.19s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR diabetes\n",
      "================================================================================\n",
      "Accuracy:        0.7662\n",
      "AUC OVO:         0.8483\n",
      "G-Mean:          0.7185\n",
      "Cross-Entropy:   0.4587\n",
      "================================================================================\n",
      "Tuning Time:     504.82s\n",
      "Training Time:   1.19s\n",
      "Total Time:      506.02s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for diabetes\n",
      "\n",
      "✓ Completed diabetes (14/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 15/30: dresses-sales\n",
      "################################################################################\n",
      "Loading processed dataset from cache: dresses-sales\n",
      "Dataset: dresses-sales\n",
      "  Train: (350, 141), Test: (150, 141)\n",
      "  Features: 141, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: dresses-sales\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 510.11s\n",
      "  Best CV G-Mean: 0.6265\n",
      "  Best parameters:\n",
      "    iterations: 298\n",
      "    depth: 6\n",
      "    learning_rate: 0.10732115041175552\n",
      "    l2_leaf_reg: 1.3288670464687802\n",
      "    bagging_temperature: 0.015325290080303866\n",
      "    min_data_in_leaf: 30\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.87s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR dresses-sales\n",
      "================================================================================\n",
      "Accuracy:        0.5667\n",
      "AUC OVO:         0.5750\n",
      "G-Mean:          0.4783\n",
      "Cross-Entropy:   0.6724\n",
      "================================================================================\n",
      "Tuning Time:     510.11s\n",
      "Training Time:   0.87s\n",
      "Total Time:      510.98s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for dresses-sales\n",
      "\n",
      "✓ Completed dresses-sales (15/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 16/30: eucalyptus\n",
      "################################################################################\n",
      "Loading processed dataset from cache: eucalyptus\n",
      "Dataset: eucalyptus\n",
      "  Train: (515, 91), Test: (221, 91)\n",
      "  Features: 91, Classes: 5\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: eucalyptus\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 1246.19s\n",
      "  Best CV G-Mean: 0.6437\n",
      "  Best parameters:\n",
      "    iterations: 496\n",
      "    depth: 6\n",
      "    learning_rate: 0.09706960713209668\n",
      "    l2_leaf_reg: 2.308314290070444\n",
      "    bagging_temperature: 0.5624488366318396\n",
      "    min_data_in_leaf: 34\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 3.88s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR eucalyptus\n",
      "================================================================================\n",
      "Accuracy:        0.6606\n",
      "AUC OVO:         0.9112\n",
      "G-Mean:          0.6052\n",
      "Cross-Entropy:   0.7565\n",
      "================================================================================\n",
      "Tuning Time:     1246.19s\n",
      "Training Time:   3.88s\n",
      "Total Time:      1250.07s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for eucalyptus\n",
      "\n",
      "✓ Completed eucalyptus (16/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 17/30: ilpd\n",
      "################################################################################\n",
      "Loading processed dataset from cache: ilpd\n",
      "Dataset: ilpd\n",
      "  Train: (408, 11), Test: (175, 11)\n",
      "  Features: 11, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: ilpd\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 552.86s\n",
      "  Best CV G-Mean: 0.5343\n",
      "  Best parameters:\n",
      "    iterations: 403\n",
      "    depth: 5\n",
      "    learning_rate: 0.2882664399779163\n",
      "    l2_leaf_reg: 3.892572673897133\n",
      "    bagging_temperature: 0.26684501574807207\n",
      "    min_data_in_leaf: 21\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.84s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR ilpd\n",
      "================================================================================\n",
      "Accuracy:        0.7200\n",
      "AUC OVO:         0.7630\n",
      "G-Mean:          0.5307\n",
      "Cross-Entropy:   0.5111\n",
      "================================================================================\n",
      "Tuning Time:     552.86s\n",
      "Training Time:   0.84s\n",
      "Total Time:      553.70s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for ilpd\n",
      "\n",
      "✓ Completed ilpd (17/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 18/30: kc2\n",
      "################################################################################\n",
      "Loading processed dataset from cache: kc2\n",
      "Dataset: kc2\n",
      "  Train: (365, 21), Test: (157, 21)\n",
      "  Features: 21, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: kc2\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 675.80s\n",
      "  Best CV G-Mean: 0.7227\n",
      "  Best parameters:\n",
      "    iterations: 390\n",
      "    depth: 3\n",
      "    learning_rate: 0.2133693238216612\n",
      "    l2_leaf_reg: 4.935590580725092\n",
      "    bagging_temperature: 0.29635490781417917\n",
      "    min_data_in_leaf: 5\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.69s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR kc2\n",
      "================================================================================\n",
      "Accuracy:        0.8025\n",
      "AUC OVO:         0.7512\n",
      "G-Mean:          0.5385\n",
      "Cross-Entropy:   0.4778\n",
      "================================================================================\n",
      "Tuning Time:     675.80s\n",
      "Training Time:   0.69s\n",
      "Total Time:      676.49s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for kc2\n",
      "\n",
      "✓ Completed kc2 (18/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 19/30: mfeat-factors\n",
      "################################################################################\n",
      "Loading processed dataset from cache: mfeat-factors\n",
      "Dataset: mfeat-factors\n",
      "  Train: (1400, 216), Test: (600, 216)\n",
      "  Features: 216, Classes: 10\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: mfeat-factors\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 1293.09s\n",
      "  Best CV G-Mean: 0.9725\n",
      "  Best parameters:\n",
      "    iterations: 191\n",
      "    depth: 5\n",
      "    learning_rate: 0.12881105803931553\n",
      "    l2_leaf_reg: 1.0016137110160783\n",
      "    bagging_temperature: 0.5071849023974168\n",
      "    min_data_in_leaf: 7\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 2.38s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR mfeat-factors\n",
      "================================================================================\n",
      "Accuracy:        0.9617\n",
      "AUC OVO:         0.9984\n",
      "G-Mean:          0.9612\n",
      "Cross-Entropy:   0.1456\n",
      "================================================================================\n",
      "Tuning Time:     1293.09s\n",
      "Training Time:   2.38s\n",
      "Total Time:      1295.47s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for mfeat-factors\n",
      "\n",
      "✓ Completed mfeat-factors (19/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 20/30: MiceProtein\n",
      "################################################################################\n",
      "Loading processed dataset from cache: MiceProtein\n",
      "Dataset: MiceProtein\n",
      "  Train: (756, 77), Test: (324, 77)\n",
      "  Features: 77, Classes: 8\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: MiceProtein\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 3349.17s\n",
      "  Best CV G-Mean: 0.9825\n",
      "  Best parameters:\n",
      "    iterations: 459\n",
      "    depth: 6\n",
      "    learning_rate: 0.07567994667969338\n",
      "    l2_leaf_reg: 1.4567301127319374\n",
      "    bagging_temperature: 0.6744941515637362\n",
      "    min_data_in_leaf: 37\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 4.88s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR MiceProtein\n",
      "================================================================================\n",
      "Accuracy:        0.9815\n",
      "AUC OVO:         0.9999\n",
      "G-Mean:          0.9816\n",
      "Cross-Entropy:   0.0876\n",
      "================================================================================\n",
      "Tuning Time:     3349.17s\n",
      "Training Time:   4.88s\n",
      "Total Time:      3354.05s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for MiceProtein\n",
      "\n",
      "✓ Completed MiceProtein (20/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 21/30: pc1\n",
      "################################################################################\n",
      "Loading processed dataset from cache: pc1\n",
      "Dataset: pc1\n",
      "  Train: (776, 21), Test: (333, 21)\n",
      "  Features: 21, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: pc1\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 583.64s\n",
      "  Best CV G-Mean: 0.5511\n",
      "  Best parameters:\n",
      "    iterations: 315\n",
      "    depth: 4\n",
      "    learning_rate: 0.1526875993381248\n",
      "    l2_leaf_reg: 1.635625500132396\n",
      "    bagging_temperature: 0.059206683497552995\n",
      "    min_data_in_leaf: 48\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.93s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR pc1\n",
      "================================================================================\n",
      "Accuracy:        0.9339\n",
      "AUC OVO:         0.8755\n",
      "G-Mean:          0.4632\n",
      "Cross-Entropy:   0.1877\n",
      "================================================================================\n",
      "Tuning Time:     583.64s\n",
      "Training Time:   0.93s\n",
      "Total Time:      584.57s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for pc1\n",
      "\n",
      "✓ Completed pc1 (21/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 22/30: pc3\n",
      "################################################################################\n",
      "Loading processed dataset from cache: pc3\n",
      "Dataset: pc3\n",
      "  Train: (1094, 37), Test: (469, 37)\n",
      "  Features: 37, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: pc3\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 763.49s\n",
      "  Best CV G-Mean: 0.4633\n",
      "  Best parameters:\n",
      "    iterations: 86\n",
      "    depth: 7\n",
      "    learning_rate: 0.2964485231622305\n",
      "    l2_leaf_reg: 6.3525461229886595\n",
      "    bagging_temperature: 0.452827500519477\n",
      "    min_data_in_leaf: 29\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.16s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR pc3\n",
      "================================================================================\n",
      "Accuracy:        0.8870\n",
      "AUC OVO:         0.8160\n",
      "G-Mean:          0.4019\n",
      "Cross-Entropy:   0.2797\n",
      "================================================================================\n",
      "Tuning Time:     763.49s\n",
      "Training Time:   1.16s\n",
      "Total Time:      764.65s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for pc3\n",
      "\n",
      "✓ Completed pc3 (22/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 23/30: pc4\n",
      "################################################################################\n",
      "Loading processed dataset from cache: pc4\n",
      "Dataset: pc4\n",
      "  Train: (1020, 37), Test: (438, 37)\n",
      "  Features: 37, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: pc4\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 881.77s\n",
      "  Best CV G-Mean: 0.6990\n",
      "  Best parameters:\n",
      "    iterations: 130\n",
      "    depth: 8\n",
      "    learning_rate: 0.1300347209324308\n",
      "    l2_leaf_reg: 8.77429275282635\n",
      "    bagging_temperature: 0.5346367158776689\n",
      "    min_data_in_leaf: 39\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.95s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR pc4\n",
      "================================================================================\n",
      "Accuracy:        0.9041\n",
      "AUC OVO:         0.9334\n",
      "G-Mean:          0.6484\n",
      "Cross-Entropy:   0.2056\n",
      "================================================================================\n",
      "Tuning Time:     881.77s\n",
      "Training Time:   1.95s\n",
      "Total Time:      883.72s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for pc4\n",
      "\n",
      "✓ Completed pc4 (23/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 24/30: qsar-biodeg\n",
      "################################################################################\n",
      "Loading processed dataset from cache: qsar-biodeg\n",
      "Dataset: qsar-biodeg\n",
      "  Train: (738, 41), Test: (317, 41)\n",
      "  Features: 41, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: qsar-biodeg\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 723.47s\n",
      "  Best CV G-Mean: 0.8532\n",
      "  Best parameters:\n",
      "    iterations: 226\n",
      "    depth: 6\n",
      "    learning_rate: 0.295548219701463\n",
      "    l2_leaf_reg: 5.69761633372336\n",
      "    bagging_temperature: 0.7239335011970356\n",
      "    min_data_in_leaf: 3\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.19s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR qsar-biodeg\n",
      "================================================================================\n",
      "Accuracy:        0.8675\n",
      "AUC OVO:         0.9085\n",
      "G-Mean:          0.8237\n",
      "Cross-Entropy:   0.3589\n",
      "================================================================================\n",
      "Tuning Time:     723.47s\n",
      "Training Time:   1.19s\n",
      "Total Time:      724.65s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for qsar-biodeg\n",
      "\n",
      "✓ Completed qsar-biodeg (24/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 25/30: semeion\n",
      "################################################################################\n",
      "Loading processed dataset from cache: semeion\n",
      "Dataset: semeion\n",
      "  Train: (1115, 256), Test: (478, 256)\n",
      "  Features: 256, Classes: 10\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: semeion\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 918.21s\n",
      "  Best CV G-Mean: 0.9310\n",
      "  Best parameters:\n",
      "    iterations: 298\n",
      "    depth: 4\n",
      "    learning_rate: 0.28759507017375047\n",
      "    l2_leaf_reg: 3.016832810722147\n",
      "    bagging_temperature: 0.20501879190616257\n",
      "    min_data_in_leaf: 11\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 2.17s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR semeion\n",
      "================================================================================\n",
      "Accuracy:        0.9435\n",
      "AUC OVO:         0.9978\n",
      "G-Mean:          0.9420\n",
      "Cross-Entropy:   0.2046\n",
      "================================================================================\n",
      "Tuning Time:     918.21s\n",
      "Training Time:   2.17s\n",
      "Total Time:      920.38s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for semeion\n",
      "\n",
      "✓ Completed semeion (25/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 26/30: steel-plates-fault\n",
      "################################################################################\n",
      "Loading processed dataset from cache: steel-plates-fault\n",
      "Dataset: steel-plates-fault\n",
      "  Train: (1358, 27), Test: (583, 27)\n",
      "  Features: 27, Classes: 7\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: steel-plates-fault\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 1854.85s\n",
      "  Best CV G-Mean: 0.7895\n",
      "  Best parameters:\n",
      "    iterations: 335\n",
      "    depth: 7\n",
      "    learning_rate: 0.11103566011368242\n",
      "    l2_leaf_reg: 2.0130779996058923\n",
      "    bagging_temperature: 0.5233286935540856\n",
      "    min_data_in_leaf: 41\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 2.60s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR steel-plates-fault\n",
      "================================================================================\n",
      "Accuracy:        0.7856\n",
      "AUC OVO:         0.9677\n",
      "G-Mean:          0.7749\n",
      "Cross-Entropy:   0.5444\n",
      "================================================================================\n",
      "Tuning Time:     1854.85s\n",
      "Training Time:   2.60s\n",
      "Total Time:      1857.45s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for steel-plates-fault\n",
      "\n",
      "✓ Completed steel-plates-fault (26/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 27/30: tic-tac-toe\n",
      "################################################################################\n",
      "Loading processed dataset from cache: tic-tac-toe\n",
      "Dataset: tic-tac-toe\n",
      "  Train: (670, 27), Test: (288, 27)\n",
      "  Features: 27, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: tic-tac-toe\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 2491.95s\n",
      "  Best CV G-Mean: 0.9957\n",
      "  Best parameters:\n",
      "    iterations: 481\n",
      "    depth: 10\n",
      "    learning_rate: 0.09129828948151858\n",
      "    l2_leaf_reg: 4.6857114825736765\n",
      "    bagging_temperature: 0.9869681814124713\n",
      "    min_data_in_leaf: 41\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 9.42s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR tic-tac-toe\n",
      "================================================================================\n",
      "Accuracy:        0.9826\n",
      "AUC OVO:         0.9999\n",
      "G-Mean:          0.9747\n",
      "Cross-Entropy:   0.0566\n",
      "================================================================================\n",
      "Tuning Time:     2491.95s\n",
      "Training Time:   9.42s\n",
      "Total Time:      2501.37s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for tic-tac-toe\n",
      "\n",
      "✓ Completed tic-tac-toe (27/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 28/30: vehicle\n",
      "################################################################################\n",
      "Loading processed dataset from cache: vehicle\n",
      "Dataset: vehicle\n",
      "  Train: (592, 18), Test: (254, 18)\n",
      "  Features: 18, Classes: 4\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: vehicle\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 1381.85s\n",
      "  Best CV G-Mean: 0.7720\n",
      "  Best parameters:\n",
      "    iterations: 357\n",
      "    depth: 5\n",
      "    learning_rate: 0.17890456326239265\n",
      "    l2_leaf_reg: 6.545107207808757\n",
      "    bagging_temperature: 0.9008216684310931\n",
      "    min_data_in_leaf: 34\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 2.58s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR vehicle\n",
      "================================================================================\n",
      "Accuracy:        0.7283\n",
      "AUC OVO:         0.9250\n",
      "G-Mean:          0.6961\n",
      "Cross-Entropy:   0.5414\n",
      "================================================================================\n",
      "Tuning Time:     1381.85s\n",
      "Training Time:   2.58s\n",
      "Total Time:      1384.43s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for vehicle\n",
      "\n",
      "✓ Completed vehicle (28/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 29/30: vowel\n",
      "################################################################################\n",
      "Loading processed dataset from cache: vowel\n",
      "Dataset: vowel\n",
      "  Train: (693, 27), Test: (297, 27)\n",
      "  Features: 27, Classes: 11\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: vowel\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-11-29 10:30:12,640] Trial 46 failed with parameters: {'iterations': 499, 'depth': 10, 'learning_rate': 0.12908589029057904, 'l2_leaf_reg': 1.8665745998100671, 'bagging_temperature': 0.9089992939961165, 'min_data_in_leaf': 6} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\venv_ml\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\codigo gabriel\\eu\\experiment_boosting_gpu_optimized.py\", line 295, in objective\n",
      "    fold_model = self.train_model(\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\codigo gabriel\\eu\\experiment_boosting_gpu_optimized.py\", line 251, in train_model\n",
      "    model.fit(\n",
      "  File \"c:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\venv_ml\\Lib\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"c:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\venv_ml\\Lib\\site-packages\\catboost\\core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"c:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\venv_ml\\Lib\\site-packages\\catboost\\core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2025-11-29 10:30:12,676] Trial 46 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_experiments_for_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcatboost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 144\u001b[39m, in \u001b[36mrun_experiments_for_model\u001b[39m\u001b[34m(model_name, use_gpu, gpu_id, n_trials, cv_folds, seed, cache_dir)\u001b[39m\n\u001b[32m    129\u001b[39m     experiment = BoostingExperiment(\n\u001b[32m    130\u001b[39m         dataset_name=dataset_name,\n\u001b[32m    131\u001b[39m         X_train=X_train,\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m         catboost_bootstrap_type=\u001b[33m\"\u001b[39m\u001b[33mBayesian\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# Usar Bayesian (mais rápido)\u001b[39;00m\n\u001b[32m    141\u001b[39m     )\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# Run complete experiment\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m results = \u001b[43mexperiment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_complete_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m# Extract metrics and info for saving\u001b[39;00m\n\u001b[32m    147\u001b[39m metrics = {\n\u001b[32m    148\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m: results[\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    149\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mauc_ovo\u001b[39m\u001b[33m\"\u001b[39m: results[\u001b[33m\"\u001b[39m\u001b[33mauc_ovo\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    150\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgmean\u001b[39m\u001b[33m\"\u001b[39m: results[\u001b[33m\"\u001b[39m\u001b[33mgmean\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    151\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcross_entropy\u001b[39m\u001b[33m\"\u001b[39m: results[\u001b[33m\"\u001b[39m\u001b[33mcross_entropy\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    152\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\codigo gabriel\\eu\\experiment_boosting_gpu_optimized.py:454\u001b[39m, in \u001b[36mBoostingExperimentGPU.run_complete_experiment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m*\u001b[38;5;250m \u001b[39m\u001b[32m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# Step 1: Optimize hyperparameters\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimize_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# Step 2: Train final model\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;28mself\u001b[39m.train_final_model()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\codigo gabriel\\eu\\experiment_boosting_gpu_optimized.py:338\u001b[39m, in \u001b[36mBoostingExperimentGPU.optimize_hyperparameters\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;66;03m# Suppress Optuna's verbose output\u001b[39;00m\n\u001b[32m    336\u001b[39m optuna.logging.set_verbosity(optuna.logging.WARNING)\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[38;5;28mself\u001b[39m.tuning_time = time.time() - start_time\n\u001b[32m    341\u001b[39m \u001b[38;5;28mself\u001b[39m.best_params = study.best_params\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\venv_ml\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\venv_ml\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\venv_ml\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\venv_ml\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\venv_ml\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\codigo gabriel\\eu\\experiment_boosting_gpu_optimized.py:295\u001b[39m, in \u001b[36mBoostingExperimentGPU.objective\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m    292\u001b[39m fold_model = \u001b[38;5;28mself\u001b[39m.create_model(params)\n\u001b[32m    294\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m fold_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[38;5;66;03m# Evaluate (using G-Mean as optimization metric)\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == \u001b[33m\"\u001b[39m\u001b[33mxgboost\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\codigo gabriel\\eu\\experiment_boosting_gpu_optimized.py:251\u001b[39m, in \u001b[36mBoostingExperimentGPU.train_model\u001b[39m\u001b[34m(self, model, X_train, y_train, X_val, y_val)\u001b[39m\n\u001b[32m    242\u001b[39m     model.fit(\n\u001b[32m    243\u001b[39m         X_train,\n\u001b[32m    244\u001b[39m         y_train,\n\u001b[32m    245\u001b[39m         eval_set=[(X_val, y_val)],\n\u001b[32m    246\u001b[39m         verbose=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    247\u001b[39m     )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == \u001b[33m\"\u001b[39m\u001b[33mcatboost\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m# CatBoost with early stopping and best model selection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Stop if no improvement for 50 rounds\u001b[39;49;00m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use best model from validation\u001b[39;49;00m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Don't generate plots\u001b[39;49;00m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == \u001b[33m\"\u001b[39m\u001b[33mlightgbm\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    262\u001b[39m     model.fit(\n\u001b[32m    263\u001b[39m         X_train,\n\u001b[32m    264\u001b[39m         y_train,\n\u001b[32m    265\u001b[39m         eval_set=[(X_val, y_val)],\n\u001b[32m    266\u001b[39m         callbacks=[lgb.early_stopping(stopping_rounds=\u001b[32m50\u001b[39m, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m)],\n\u001b[32m    267\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\venv_ml\\Lib\\site-packages\\catboost\\core.py:5245\u001b[39m, in \u001b[36mCatBoostClassifier.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5243\u001b[39m     CatBoostClassifier._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5245\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5246\u001b[39m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5247\u001b[39m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\venv_ml\\Lib\\site-packages\\catboost\\core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\Desktop\\mestrado\\ml\\projeto-leandro\\venv_ml\\Lib\\site-packages\\catboost\\core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "run_experiments_for_model(\"catboost\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c084a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 13:42:13,616] A new study created in memory with name: no-name-88c7fd5e-b9aa-4757-802d-e5b95c3e3c21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CATBOOST - EXPERIMENT PIPELINE\n",
      "================================================================================\n",
      "Model: catboost\n",
      "Mode: GPU\n",
      "GPU ID: 0\n",
      "Seed: 123\n",
      "Optuna trials: 50\n",
      "CV folds: 10\n",
      "Results directory: ./results/catboost_gpu\n",
      "================================================================================\n",
      "\n",
      "✓ Found 30 processed datasets\n",
      "\n",
      "✓ GPU available: NVIDIA GeForce RTX 3060\n",
      "  Memory: 12.88 GB\n",
      "\n",
      "\n",
      "################################################################################\n",
      "DATASET 1/30: vowel\n",
      "################################################################################\n",
      "Loading processed dataset from cache: vowel\n",
      "Dataset: vowel\n",
      "  Train: (693, 27), Test: (297, 27)\n",
      "  Features: 27, Classes: 11\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: vowel\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 4468.93s\n",
      "  Best CV G-Mean: 0.9544\n",
      "  Best parameters:\n",
      "    iterations: 483\n",
      "    depth: 10\n",
      "    learning_rate: 0.26707484379625845\n",
      "    l2_leaf_reg: 1.4213818814607038\n",
      "    bagging_temperature: 0.792649414705147\n",
      "    min_data_in_leaf: 29\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 21.11s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR vowel\n",
      "================================================================================\n",
      "Accuracy:        0.9394\n",
      "AUC OVO:         0.9971\n",
      "G-Mean:          0.9364\n",
      "Cross-Entropy:   0.2157\n",
      "================================================================================\n",
      "Tuning Time:     4468.93s\n",
      "Training Time:   21.11s\n",
      "Total Time:      4490.05s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for vowel\n",
      "\n",
      "✓ Completed vowel (1/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 2/30: wdbc\n",
      "################################################################################\n",
      "Loading processed dataset from cache: wdbc\n",
      "Dataset: wdbc\n",
      "  Train: (398, 30), Test: (171, 30)\n",
      "  Features: 30, Classes: 2\n",
      "  Model: CATBOOST\n",
      "  GPU: Enabled (Device 0)\n",
      "  Bootstrap: Bayesian (fastest)\n",
      "  Early Stopping: Enabled\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: wdbc\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "  GPU: Enabled\n",
      "\n",
      "✓ Optimization complete! Time: 972.87s\n",
      "  Best CV G-Mean: 0.9691\n",
      "  Best parameters:\n",
      "    iterations: 298\n",
      "    depth: 7\n",
      "    learning_rate: 0.10541318837857297\n",
      "    l2_leaf_reg: 2.787860554047956\n",
      "    bagging_temperature: 0.20194036765275342\n",
      "    min_data_in_leaf: 36\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 3.23s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR wdbc\n",
      "================================================================================\n",
      "Accuracy:        0.9591\n",
      "AUC OVO:         0.9937\n",
      "G-Mean:          0.9610\n",
      "Cross-Entropy:   0.1161\n",
      "================================================================================\n",
      "Tuning Time:     972.87s\n",
      "Training Time:   3.23s\n",
      "Total Time:      976.09s\n",
      "GPU Enabled:     True\n",
      "================================================================================\n",
      "✓ Saved results for wdbc\n",
      "\n",
      "✓ Completed wdbc (2/30)\n",
      "\n",
      "================================================================================\n",
      "SAVING FINAL RESULTS\n",
      "================================================================================\n",
      "\n",
      "✓ Saved metrics CSV: results\\catboost_gpu\\catboost_metrics.csv\n",
      "  Total datasets: 2\n",
      "  Columns: ['dataset', 'model', 'accuracy', 'auc_ovo', 'gmean', 'cross_entropy', 'n_samples_train', 'n_samples_test', 'n_features', 'n_classes']\n",
      "\n",
      "Metrics Summary:\n",
      "       accuracy   auc_ovo     gmean  cross_entropy\n",
      "count  2.000000  2.000000  2.000000       2.000000\n",
      "mean   0.949229  0.995395  0.948684       0.165905\n",
      "std    0.013909  0.002368  0.017388       0.070432\n",
      "min    0.939394  0.993721  0.936390       0.116101\n",
      "25%    0.944312  0.994558  0.942537       0.141003\n",
      "50%    0.949229  0.995395  0.948684       0.165905\n",
      "75%    0.954147  0.996232  0.954832       0.190806\n",
      "max    0.959064  0.997069  0.960979       0.215708\n",
      "\n",
      "================================================================================\n",
      "RESULTS SUMMARY - CATBOOST\n",
      "================================================================================\n",
      "Total datasets: 2\n",
      "\n",
      "Metrics Statistics:\n",
      "       accuracy   auc_ovo     gmean  cross_entropy\n",
      "count  2.000000  2.000000  2.000000       2.000000\n",
      "mean   0.949229  0.995395  0.948684       0.165905\n",
      "std    0.013909  0.002368  0.017388       0.070432\n",
      "min    0.939394  0.993721  0.936390       0.116101\n",
      "25%    0.944312  0.994558  0.942537       0.141003\n",
      "50%    0.949229  0.995395  0.948684       0.165905\n",
      "75%    0.954147  0.996232  0.954832       0.190806\n",
      "max    0.959064  0.997069  0.960979       0.215708\n",
      "\n",
      "Top 5 datasets by accuracy:\n",
      "dataset  accuracy  auc_ovo    gmean\n",
      "   wdbc  0.959064 0.993721 0.960979\n",
      "  vowel  0.939394 0.997069 0.936390\n",
      "\n",
      "Bottom 5 datasets by accuracy:\n",
      "dataset  accuracy  auc_ovo    gmean\n",
      "  vowel  0.939394 0.997069 0.936390\n",
      "   wdbc  0.959064 0.993721 0.960979\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT COMPLETE FOR CATBOOST!\n",
      "================================================================================\n",
      "✓ Total datasets: 30\n",
      "✓ Successful: 2\n",
      "✓ Failed: 0\n",
      "\n",
      "✓ Metrics CSV saved: ./results/catboost_gpu/catboost_metrics.csv\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "run_experiments_for_model(\"catboost\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882d64b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Encontrados 30 arquivos de resultado\n",
      "  Diretório: results\\catboost_gpu\\individual_results\n",
      "\n",
      "  ✓ analcatdata_authorship\n",
      "  ✓ analcatdata_dmft\n",
      "  ✓ balance-scale\n",
      "  ✓ banknote-authentication\n",
      "  ✓ blood-transfusion-service-center\n",
      "  ✓ breast-w\n",
      "  ✓ car\n",
      "  ✓ climate-model-simulation-crashes\n",
      "  ✓ cmc\n",
      "  ✓ cnae-9\n",
      "  ✓ credit-approval\n",
      "  ✓ credit-g\n",
      "  ✓ cylinder-bands\n",
      "  ✓ diabetes\n",
      "  ✓ dresses-sales\n",
      "  ✓ eucalyptus\n",
      "  ✓ ilpd\n",
      "  ✓ kc2\n",
      "  ✓ mfeat-factors\n",
      "  ✓ MiceProtein\n",
      "  ✓ pc1\n",
      "  ✓ pc3\n",
      "  ✓ pc4\n",
      "  ✓ qsar-biodeg\n",
      "  ✓ semeion\n",
      "  ✓ steel-plates-fault\n",
      "  ✓ tic-tac-toe\n",
      "  ✓ vehicle\n",
      "  ✓ vowel\n",
      "  ✓ wdbc\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS AGREGADOS\n",
      "================================================================================\n",
      "✓ Total de datasets: 30\n",
      "✓ Arquivo salvo: results\\catboost_gpu\\catboost_metrics.csv\n",
      "✓ Colunas: ['dataset', 'model', 'accuracy', 'auc_ovo', 'gmean', 'cross_entropy', 'n_samples_train', 'n_samples_test', 'n_features', 'n_classes', 'tuning_time', 'training_time', 'prediction_time', 'total_time']\n",
      "================================================================================\n",
      "\n",
      "Estatísticas das Métricas:\n",
      "        accuracy    auc_ovo      gmean  cross_entropy\n",
      "count  30.000000  30.000000  30.000000      30.000000\n",
      "mean    0.831974   0.885509   0.724364       0.378208\n",
      "std     0.170369   0.128294   0.223191       0.326866\n",
      "min     0.221106   0.539319   0.202861       0.009123\n",
      "25%     0.756558   0.816174   0.532624       0.156086\n",
      "50%     0.895552   0.928106   0.721427       0.285166\n",
      "75%     0.943350   0.995874   0.941446       0.507427\n",
      "max     0.997573   0.999952   0.997264       1.605199\n",
      "\n",
      "================================================================================\n",
      "DATASETS PROCESSADOS (ordenados alfabeticamente):\n",
      "================================================================================\n",
      "  1. MiceProtein\n",
      "  2. analcatdata_authorship\n",
      "  3. analcatdata_dmft\n",
      "  4. balance-scale\n",
      "  5. banknote-authentication\n",
      "  6. blood-transfusion-service-center\n",
      "  7. breast-w\n",
      "  8. car\n",
      "  9. climate-model-simulation-crashes\n",
      " 10. cmc\n",
      " 11. cnae-9\n",
      " 12. credit-approval\n",
      " 13. credit-g\n",
      " 14. cylinder-bands\n",
      " 15. diabetes\n",
      " 16. dresses-sales\n",
      " 17. eucalyptus\n",
      " 18. ilpd\n",
      " 19. kc2\n",
      " 20. mfeat-factors\n",
      " 21. pc1\n",
      " 22. pc3\n",
      " 23. pc4\n",
      " 24. qsar-biodeg\n",
      " 25. semeion\n",
      " 26. steel-plates-fault\n",
      " 27. tic-tac-toe\n",
      " 28. vehicle\n",
      " 29. vowel\n",
      " 30. wdbc\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc_ovo</th>\n",
       "      <th>gmean</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>n_samples_train</th>\n",
       "      <th>n_samples_test</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>tuning_time</th>\n",
       "      <th>training_time</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MiceProtein</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.981613</td>\n",
       "      <td>0.087627</td>\n",
       "      <td>756</td>\n",
       "      <td>324</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>3349.165567</td>\n",
       "      <td>4.883476</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>3354.051007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>analcatdata_authorship</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.976285</td>\n",
       "      <td>0.991943</td>\n",
       "      <td>0.958738</td>\n",
       "      <td>0.075878</td>\n",
       "      <td>588</td>\n",
       "      <td>253</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>1342.305657</td>\n",
       "      <td>0.806375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1343.112032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>analcatdata_dmft</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.221106</td>\n",
       "      <td>0.539319</td>\n",
       "      <td>0.202861</td>\n",
       "      <td>1.605199</td>\n",
       "      <td>462</td>\n",
       "      <td>199</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>612.767336</td>\n",
       "      <td>0.939453</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>613.707788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balance-scale</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.904255</td>\n",
       "      <td>0.946322</td>\n",
       "      <td>0.500987</td>\n",
       "      <td>0.262813</td>\n",
       "      <td>437</td>\n",
       "      <td>188</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>897.549063</td>\n",
       "      <td>1.593031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>899.142094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.997573</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.997264</td>\n",
       "      <td>0.009123</td>\n",
       "      <td>960</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1328.160801</td>\n",
       "      <td>4.393395</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>1332.555165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blood-transfusion-service-center</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.791111</td>\n",
       "      <td>0.744369</td>\n",
       "      <td>0.584990</td>\n",
       "      <td>0.481412</td>\n",
       "      <td>523</td>\n",
       "      <td>225</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>620.634992</td>\n",
       "      <td>0.795215</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>621.431205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>breast-w</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.983092</td>\n",
       "      <td>0.939869</td>\n",
       "      <td>0.141368</td>\n",
       "      <td>489</td>\n",
       "      <td>210</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>765.195982</td>\n",
       "      <td>1.648280</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>766.845259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>car</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.980732</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>0.981696</td>\n",
       "      <td>0.085407</td>\n",
       "      <td>1209</td>\n",
       "      <td>519</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1985.252568</td>\n",
       "      <td>1.829828</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>1987.086385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>climate-model-simulation-crashes</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.919753</td>\n",
       "      <td>0.867278</td>\n",
       "      <td>0.459772</td>\n",
       "      <td>0.216901</td>\n",
       "      <td>378</td>\n",
       "      <td>162</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1009.208080</td>\n",
       "      <td>1.593813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1010.801893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cmc</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.527149</td>\n",
       "      <td>0.700388</td>\n",
       "      <td>0.512370</td>\n",
       "      <td>0.977350</td>\n",
       "      <td>1031</td>\n",
       "      <td>442</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1508.884505</td>\n",
       "      <td>1.667368</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>1510.552839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cnae-9</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.996592</td>\n",
       "      <td>0.937190</td>\n",
       "      <td>0.290614</td>\n",
       "      <td>756</td>\n",
       "      <td>324</td>\n",
       "      <td>856</td>\n",
       "      <td>9</td>\n",
       "      <td>1080.070008</td>\n",
       "      <td>1.525050</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>1081.598047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>credit-approval</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.931191</td>\n",
       "      <td>0.867171</td>\n",
       "      <td>0.333423</td>\n",
       "      <td>483</td>\n",
       "      <td>207</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>698.937115</td>\n",
       "      <td>1.004064</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>699.944170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>credit-g</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.786349</td>\n",
       "      <td>0.627416</td>\n",
       "      <td>0.496541</td>\n",
       "      <td>700</td>\n",
       "      <td>300</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>713.764560</td>\n",
       "      <td>0.872793</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>714.643337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cylinder-bands</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.746914</td>\n",
       "      <td>0.816802</td>\n",
       "      <td>0.724374</td>\n",
       "      <td>0.549827</td>\n",
       "      <td>378</td>\n",
       "      <td>162</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>704.583264</td>\n",
       "      <td>1.890944</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>706.480230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.848313</td>\n",
       "      <td>0.718480</td>\n",
       "      <td>0.458720</td>\n",
       "      <td>537</td>\n",
       "      <td>231</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>504.824600</td>\n",
       "      <td>1.194341</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>506.019939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dresses-sales</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.574986</td>\n",
       "      <td>0.478320</td>\n",
       "      <td>0.672423</td>\n",
       "      <td>350</td>\n",
       "      <td>150</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>510.106950</td>\n",
       "      <td>0.865029</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>510.978989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eucalyptus</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.660633</td>\n",
       "      <td>0.911231</td>\n",
       "      <td>0.605162</td>\n",
       "      <td>0.756533</td>\n",
       "      <td>515</td>\n",
       "      <td>221</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>1246.185279</td>\n",
       "      <td>3.878146</td>\n",
       "      <td>0.006952</td>\n",
       "      <td>1250.070378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ilpd</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.763040</td>\n",
       "      <td>0.530660</td>\n",
       "      <td>0.511055</td>\n",
       "      <td>408</td>\n",
       "      <td>175</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>552.860341</td>\n",
       "      <td>0.837759</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>553.699098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kc2</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.802548</td>\n",
       "      <td>0.751250</td>\n",
       "      <td>0.538516</td>\n",
       "      <td>0.477763</td>\n",
       "      <td>365</td>\n",
       "      <td>157</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>675.802402</td>\n",
       "      <td>0.691590</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>676.494989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mfeat-factors</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.998407</td>\n",
       "      <td>0.961200</td>\n",
       "      <td>0.145555</td>\n",
       "      <td>1400</td>\n",
       "      <td>600</td>\n",
       "      <td>216</td>\n",
       "      <td>10</td>\n",
       "      <td>1293.091309</td>\n",
       "      <td>2.380325</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>1295.473628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pc1</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.933934</td>\n",
       "      <td>0.875526</td>\n",
       "      <td>0.463235</td>\n",
       "      <td>0.187679</td>\n",
       "      <td>776</td>\n",
       "      <td>333</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>583.637553</td>\n",
       "      <td>0.930451</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>584.569002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pc3</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.886994</td>\n",
       "      <td>0.815964</td>\n",
       "      <td>0.401896</td>\n",
       "      <td>0.279718</td>\n",
       "      <td>1094</td>\n",
       "      <td>469</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>763.489693</td>\n",
       "      <td>1.156829</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>764.647520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pc4</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.904110</td>\n",
       "      <td>0.933448</td>\n",
       "      <td>0.648410</td>\n",
       "      <td>0.205622</td>\n",
       "      <td>1020</td>\n",
       "      <td>438</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>881.772684</td>\n",
       "      <td>1.947397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>883.720081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qsar-biodeg</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.867508</td>\n",
       "      <td>0.908545</td>\n",
       "      <td>0.823714</td>\n",
       "      <td>0.358890</td>\n",
       "      <td>738</td>\n",
       "      <td>317</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>723.465989</td>\n",
       "      <td>1.187312</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>724.654298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>semeion</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.943515</td>\n",
       "      <td>0.997796</td>\n",
       "      <td>0.941972</td>\n",
       "      <td>0.204608</td>\n",
       "      <td>1115</td>\n",
       "      <td>478</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>918.211785</td>\n",
       "      <td>2.165748</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>920.379527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>steel-plates-fault</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.785592</td>\n",
       "      <td>0.967724</td>\n",
       "      <td>0.774860</td>\n",
       "      <td>0.544356</td>\n",
       "      <td>1358</td>\n",
       "      <td>583</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>1854.846699</td>\n",
       "      <td>2.603464</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>1857.451136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tic-tac-toe</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.982639</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.974679</td>\n",
       "      <td>0.056631</td>\n",
       "      <td>670</td>\n",
       "      <td>288</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2491.945123</td>\n",
       "      <td>9.417473</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>2501.366586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>vehicle</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.728346</td>\n",
       "      <td>0.925020</td>\n",
       "      <td>0.696143</td>\n",
       "      <td>0.541386</td>\n",
       "      <td>592</td>\n",
       "      <td>254</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1381.854828</td>\n",
       "      <td>2.578419</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>1384.434246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vowel</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.997069</td>\n",
       "      <td>0.936390</td>\n",
       "      <td>0.215708</td>\n",
       "      <td>693</td>\n",
       "      <td>297</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>4468.930405</td>\n",
       "      <td>21.111073</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>4490.048490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>wdbc</td>\n",
       "      <td>catboost</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.993721</td>\n",
       "      <td>0.960979</td>\n",
       "      <td>0.116101</td>\n",
       "      <td>398</td>\n",
       "      <td>171</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>972.865263</td>\n",
       "      <td>3.228368</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>976.094629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dataset     model  accuracy   auc_ovo     gmean  \\\n",
       "0                        MiceProtein  catboost  0.981481  0.999923  0.981613   \n",
       "1             analcatdata_authorship  catboost  0.976285  0.991943  0.958738   \n",
       "2                   analcatdata_dmft  catboost  0.221106  0.539319  0.202861   \n",
       "3                      balance-scale  catboost  0.904255  0.946322  0.500987   \n",
       "4            banknote-authentication  catboost  0.997573  0.999952  0.997264   \n",
       "5   blood-transfusion-service-center  catboost  0.791111  0.744369  0.584990   \n",
       "6                           breast-w  catboost  0.942857  0.983092  0.939869   \n",
       "7                                car  catboost  0.980732  0.999808  0.981696   \n",
       "8   climate-model-simulation-crashes  catboost  0.919753  0.867278  0.459772   \n",
       "9                                cmc  catboost  0.527149  0.700388  0.512370   \n",
       "10                            cnae-9  catboost  0.938272  0.996592  0.937190   \n",
       "11                   credit-approval  catboost  0.869565  0.931191  0.867171   \n",
       "12                          credit-g  catboost  0.753333  0.786349  0.627416   \n",
       "13                    cylinder-bands  catboost  0.746914  0.816802  0.724374   \n",
       "14                          diabetes  catboost  0.766234  0.848313  0.718480   \n",
       "15                     dresses-sales  catboost  0.566667  0.574986  0.478320   \n",
       "16                        eucalyptus  catboost  0.660633  0.911231  0.605162   \n",
       "17                              ilpd  catboost  0.720000  0.763040  0.530660   \n",
       "18                               kc2  catboost  0.802548  0.751250  0.538516   \n",
       "19                     mfeat-factors  catboost  0.961667  0.998407  0.961200   \n",
       "20                               pc1  catboost  0.933934  0.875526  0.463235   \n",
       "21                               pc3  catboost  0.886994  0.815964  0.401896   \n",
       "22                               pc4  catboost  0.904110  0.933448  0.648410   \n",
       "23                       qsar-biodeg  catboost  0.867508  0.908545  0.823714   \n",
       "24                           semeion  catboost  0.943515  0.997796  0.941972   \n",
       "25                steel-plates-fault  catboost  0.785592  0.967724  0.774860   \n",
       "26                       tic-tac-toe  catboost  0.982639  0.999894  0.974679   \n",
       "27                           vehicle  catboost  0.728346  0.925020  0.696143   \n",
       "28                             vowel  catboost  0.939394  0.997069  0.936390   \n",
       "29                              wdbc  catboost  0.959064  0.993721  0.960979   \n",
       "\n",
       "    cross_entropy  n_samples_train  n_samples_test  n_features  n_classes  \\\n",
       "0        0.087627              756             324          77          8   \n",
       "1        0.075878              588             253          70          4   \n",
       "2        1.605199              462             199           7          5   \n",
       "3        0.262813              437             188           4          3   \n",
       "4        0.009123              960             412           4          2   \n",
       "5        0.481412              523             225           4          2   \n",
       "6        0.141368              489             210           9          2   \n",
       "7        0.085407             1209             519          21          4   \n",
       "8        0.216901              378             162          18          2   \n",
       "9        0.977350             1031             442           9          3   \n",
       "10       0.290614              756             324         856          9   \n",
       "11       0.333423              483             207          46          2   \n",
       "12       0.496541              700             300          61          2   \n",
       "13       0.549827              378             162         119          2   \n",
       "14       0.458720              537             231           8          2   \n",
       "15       0.672423              350             150         141          2   \n",
       "16       0.756533              515             221          91          5   \n",
       "17       0.511055              408             175          11          2   \n",
       "18       0.477763              365             157          21          2   \n",
       "19       0.145555             1400             600         216         10   \n",
       "20       0.187679              776             333          21          2   \n",
       "21       0.279718             1094             469          37          2   \n",
       "22       0.205622             1020             438          37          2   \n",
       "23       0.358890              738             317          41          2   \n",
       "24       0.204608             1115             478         256         10   \n",
       "25       0.544356             1358             583          27          7   \n",
       "26       0.056631              670             288          27          2   \n",
       "27       0.541386              592             254          18          4   \n",
       "28       0.215708              693             297          27         11   \n",
       "29       0.116101              398             171          30          2   \n",
       "\n",
       "    tuning_time  training_time  prediction_time   total_time  \n",
       "0   3349.165567       4.883476         0.001964  3354.051007  \n",
       "1   1342.305657       0.806375         0.000000  1343.112032  \n",
       "2    612.767336       0.939453         0.000998   613.707788  \n",
       "3    897.549063       1.593031         0.000000   899.142094  \n",
       "4   1328.160801       4.393395         0.000968  1332.555165  \n",
       "5    620.634992       0.795215         0.000998   621.431205  \n",
       "6    765.195982       1.648280         0.000997   766.845259  \n",
       "7   1985.252568       1.829828         0.003989  1987.086385  \n",
       "8   1009.208080       1.593813         0.000000  1010.801893  \n",
       "9   1508.884505       1.667368         0.000966  1510.552839  \n",
       "10  1080.070008       1.525050         0.002990  1081.598047  \n",
       "11   698.937115       1.004064         0.002992   699.944170  \n",
       "12   713.764560       0.872793         0.005984   714.643337  \n",
       "13   704.583264       1.890944         0.006022   706.480230  \n",
       "14   504.824600       1.194341         0.000997   506.019939  \n",
       "15   510.106950       0.865029         0.007011   510.978989  \n",
       "16  1246.185279       3.878146         0.006952  1250.070378  \n",
       "17   552.860341       0.837759         0.000998   553.699098  \n",
       "18   675.802402       0.691590         0.000997   676.494989  \n",
       "19  1293.091309       2.380325         0.001994  1295.473628  \n",
       "20   583.637553       0.930451         0.000998   584.569002  \n",
       "21   763.489693       1.156829         0.000998   764.647520  \n",
       "22   881.772684       1.947397         0.000000   883.720081  \n",
       "23   723.465989       1.187312         0.000997   724.654298  \n",
       "24   918.211785       2.165748         0.001994   920.379527  \n",
       "25  1854.846699       2.603464         0.000972  1857.451136  \n",
       "26  2491.945123       9.417473         0.003990  2501.366586  \n",
       "27  1381.854828       2.578419         0.000999  1384.434246  \n",
       "28  4468.930405      21.111073         0.007012  4490.048490  \n",
       "29   972.865263       3.228368         0.000998   976.094629  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_results(results_dir=\"./results/catboost_gpu\", model_name=\"catboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightgbm_section",
   "metadata": {},
   "source": [
    "## Experimentos com LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=UserWarning, message=\".*does not have valid feature names.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "run_lightgbm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LIGHTGBM - EXPERIMENT PIPELINE\n",
      "================================================================================\n",
      "Model: lightgbm\n",
      "Mode: CPU\n",
      "Seed: 123\n",
      "Optuna trials: 50\n",
      "CV folds: 10\n",
      "Results directory: ./results/lightgbm\n",
      "================================================================================\n",
      "\n",
      "✓ Found 30 processed datasets\n",
      "\n",
      "\n",
      "################################################################################\n",
      "DATASET 1/30: mfeat-factors\n",
      "################################################################################\n",
      "Loading processed dataset from cache: mfeat-factors\n",
      "Dataset: mfeat-factors\n",
      "  Train: (1400, 216), Test: (600, 216)\n",
      "  Features: 216, Classes: 10\n",
      "  Model: LIGHTGBM\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: mfeat-factors\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "\n",
      "✓ Optimization complete! Time: 1392.20s\n",
      "  Best CV G-Mean: 0.9762\n",
      "  Best parameters:\n",
      "    n_estimators: 493\n",
      "    max_depth: 3\n",
      "    learning_rate: 0.035830515983720015\n",
      "    subsample: 0.9785227828248506\n",
      "    colsample_bytree: 0.9952433957260511\n",
      "    min_child_samples: 97\n",
      "    reg_alpha: 0.00383814423375467\n",
      "    reg_lambda: 0.8357035402441148\n",
      "    num_leaves: 26\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 4.14s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR mfeat-factors\n",
      "================================================================================\n",
      "Accuracy:        0.9650\n",
      "AUC OVO:         0.9981\n",
      "G-Mean:          0.9642\n",
      "Cross-Entropy:   0.1335\n",
      "================================================================================\n",
      "✓ Saved results for mfeat-factors\n",
      "\n",
      "✓ Completed mfeat-factors (1/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 2/30: MiceProtein\n",
      "################################################################################\n",
      "Loading processed dataset from cache: MiceProtein\n",
      "Dataset: MiceProtein\n",
      "  Train: (756, 77), Test: (324, 77)\n",
      "  Features: 77, Classes: 8\n",
      "  Model: LIGHTGBM\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: MiceProtein\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "\n",
      "✓ Optimization complete! Time: 545.48s\n",
      "  Best CV G-Mean: 0.9751\n",
      "  Best parameters:\n",
      "    n_estimators: 97\n",
      "    max_depth: 8\n",
      "    learning_rate: 0.28276434975717923\n",
      "    subsample: 0.8509355440624858\n",
      "    colsample_bytree: 0.9778992844449906\n",
      "    min_child_samples: 36\n",
      "    reg_alpha: 0.0021883502824614487\n",
      "    reg_lambda: 0.8175840609751288\n",
      "    num_leaves: 109\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.48s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR MiceProtein\n",
      "================================================================================\n",
      "Accuracy:        0.9722\n",
      "AUC OVO:         0.9997\n",
      "G-Mean:          0.9717\n",
      "Cross-Entropy:   0.0816\n",
      "================================================================================\n",
      "✓ Saved results for MiceProtein\n",
      "\n",
      "✓ Completed MiceProtein (2/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 3/30: pc1\n",
      "################################################################################\n",
      "Loading processed dataset from cache: pc1\n",
      "Dataset: pc1\n",
      "  Train: (776, 21), Test: (333, 21)\n",
      "  Features: 21, Classes: 2\n",
      "  Model: LIGHTGBM\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: pc1\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "\n",
      "✓ Optimization complete! Time: 43.97s\n",
      "  Best CV G-Mean: 0.5592\n",
      "  Best parameters:\n",
      "    n_estimators: 217\n",
      "    max_depth: 5\n",
      "    learning_rate: 0.16379041400302136\n",
      "    subsample: 0.6736423440345215\n",
      "    colsample_bytree: 0.6737437338433164\n",
      "    min_child_samples: 100\n",
      "    reg_alpha: 0.4967937513161497\n",
      "    reg_lambda: 0.7410477608946282\n",
      "    num_leaves: 150\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.06s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR pc1\n",
      "================================================================================\n",
      "Accuracy:        0.9159\n",
      "AUC OVO:         0.8799\n",
      "G-Mean:          0.3565\n",
      "Cross-Entropy:   0.1922\n",
      "================================================================================\n",
      "✓ Saved results for pc1\n",
      "\n",
      "✓ Completed pc1 (3/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 4/30: pc3\n",
      "################################################################################\n",
      "Loading processed dataset from cache: pc3\n",
      "Dataset: pc3\n",
      "  Train: (1094, 37), Test: (469, 37)\n",
      "  Features: 37, Classes: 2\n",
      "  Model: LIGHTGBM\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: pc3\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "\n",
      "✓ Optimization complete! Time: 81.70s\n",
      "  Best CV G-Mean: 0.4910\n",
      "  Best parameters:\n",
      "    n_estimators: 467\n",
      "    max_depth: 9\n",
      "    learning_rate: 0.13901664240635617\n",
      "    subsample: 0.6923132430274409\n",
      "    colsample_bytree: 0.9816070714381698\n",
      "    min_child_samples: 81\n",
      "    reg_alpha: 0.18172552712368245\n",
      "    reg_lambda: 0.8915532940040232\n",
      "    num_leaves: 124\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.24s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR pc3\n",
      "================================================================================\n",
      "Accuracy:        0.8827\n",
      "AUC OVO:         0.8100\n",
      "G-Mean:          0.4247\n",
      "Cross-Entropy:   0.3846\n",
      "================================================================================\n",
      "✓ Saved results for pc3\n",
      "\n",
      "✓ Completed pc3 (4/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 5/30: pc4\n",
      "################################################################################\n",
      "Loading processed dataset from cache: pc4\n",
      "Dataset: pc4\n",
      "  Train: (1020, 37), Test: (438, 37)\n",
      "  Features: 37, Classes: 2\n",
      "  Model: LIGHTGBM\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: pc4\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "\n",
      "✓ Optimization complete! Time: 64.13s\n",
      "  Best CV G-Mean: 0.7037\n",
      "  Best parameters:\n",
      "    n_estimators: 334\n",
      "    max_depth: 5\n",
      "    learning_rate: 0.04499627128921318\n",
      "    subsample: 0.9262586456823296\n",
      "    colsample_bytree: 0.9547178385309042\n",
      "    min_child_samples: 61\n",
      "    reg_alpha: 0.7722903588551377\n",
      "    reg_lambda: 0.353354767120337\n",
      "    num_leaves: 68\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.13s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR pc4\n",
      "================================================================================\n",
      "Accuracy:        0.9110\n",
      "AUC OVO:         0.9276\n",
      "G-Mean:          0.7135\n",
      "Cross-Entropy:   0.2174\n",
      "================================================================================\n",
      "✓ Saved results for pc4\n",
      "\n",
      "✓ Completed pc4 (5/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 6/30: qsar-biodeg\n",
      "################################################################################\n",
      "Loading processed dataset from cache: qsar-biodeg\n",
      "Dataset: qsar-biodeg\n",
      "  Train: (738, 41), Test: (317, 41)\n",
      "  Features: 41, Classes: 2\n",
      "  Model: LIGHTGBM\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: qsar-biodeg\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "\n",
      "✓ Optimization complete! Time: 57.70s\n",
      "  Best CV G-Mean: 0.8547\n",
      "  Best parameters:\n",
      "    n_estimators: 332\n",
      "    max_depth: 9\n",
      "    learning_rate: 0.0738836532390207\n",
      "    subsample: 0.8577953250040635\n",
      "    colsample_bytree: 0.7509758895683415\n",
      "    min_child_samples: 59\n",
      "    reg_alpha: 0.22197236910001117\n",
      "    reg_lambda: 0.1080845818572422\n",
      "    num_leaves: 85\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.12s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR qsar-biodeg\n",
      "================================================================================\n",
      "Accuracy:        0.8612\n",
      "AUC OVO:         0.9076\n",
      "G-Mean:          0.8227\n",
      "Cross-Entropy:   0.3939\n",
      "================================================================================\n",
      "✓ Saved results for qsar-biodeg\n",
      "\n",
      "✓ Completed qsar-biodeg (6/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 7/30: semeion\n",
      "################################################################################\n",
      "Loading processed dataset from cache: semeion\n",
      "Dataset: semeion\n",
      "  Train: (1115, 256), Test: (478, 256)\n",
      "  Features: 256, Classes: 10\n",
      "  Model: LIGHTGBM\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: semeion\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "\n",
      "✓ Optimization complete! Time: 706.29s\n",
      "  Best CV G-Mean: 0.9255\n",
      "  Best parameters:\n",
      "    n_estimators: 457\n",
      "    max_depth: 3\n",
      "    learning_rate: 0.031531520139092294\n",
      "    subsample: 0.935772624306638\n",
      "    colsample_bytree: 0.9623556764989907\n",
      "    min_child_samples: 89\n",
      "    reg_alpha: 0.10202134684529918\n",
      "    reg_lambda: 0.9117072561328516\n",
      "    num_leaves: 53\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.62s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR semeion\n",
      "================================================================================\n",
      "Accuracy:        0.9121\n",
      "AUC OVO:         0.9948\n",
      "G-Mean:          0.9100\n",
      "Cross-Entropy:   0.2900\n",
      "================================================================================\n",
      "✓ Saved results for semeion\n",
      "\n",
      "✓ Completed semeion (7/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 8/30: steel-plates-fault\n",
      "################################################################################\n",
      "Loading processed dataset from cache: steel-plates-fault\n",
      "Dataset: steel-plates-fault\n",
      "  Train: (1358, 27), Test: (583, 27)\n",
      "  Features: 27, Classes: 7\n",
      "  Model: LIGHTGBM\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: steel-plates-fault\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "\n",
      "✓ Optimization complete! Time: 380.41s\n",
      "  Best CV G-Mean: 0.7866\n",
      "  Best parameters:\n",
      "    n_estimators: 463\n",
      "    max_depth: 8\n",
      "    learning_rate: 0.06628257560227281\n",
      "    subsample: 0.9174333309255558\n",
      "    colsample_bytree: 0.9908054636863404\n",
      "    min_child_samples: 69\n",
      "    reg_alpha: 0.2622483676120474\n",
      "    reg_lambda: 0.012283918831203389\n",
      "    num_leaves: 108\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.10s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR steel-plates-fault\n",
      "================================================================================\n",
      "Accuracy:        0.7822\n",
      "AUC OVO:         0.9620\n",
      "G-Mean:          0.7962\n",
      "Cross-Entropy:   0.6538\n",
      "================================================================================\n",
      "✓ Saved results for steel-plates-fault\n",
      "\n",
      "✓ Completed steel-plates-fault (8/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 9/30: tic-tac-toe\n",
      "################################################################################\n",
      "Loading processed dataset from cache: tic-tac-toe\n",
      "Dataset: tic-tac-toe\n",
      "  Train: (670, 27), Test: (288, 27)\n",
      "  Features: 27, Classes: 2\n",
      "  Model: LIGHTGBM\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: tic-tac-toe\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "\n",
      "✓ Optimization complete! Time: 47.33s\n",
      "  Best CV G-Mean: 0.9957\n",
      "  Best parameters:\n",
      "    n_estimators: 436\n",
      "    max_depth: 8\n",
      "    learning_rate: 0.1273582950827998\n",
      "    subsample: 0.6513707855674208\n",
      "    colsample_bytree: 0.8004133413779114\n",
      "    min_child_samples: 31\n",
      "    reg_alpha: 0.10476757167952011\n",
      "    reg_lambda: 0.0018730592122097045\n",
      "    num_leaves: 21\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.09s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR tic-tac-toe\n",
      "================================================================================\n",
      "Accuracy:        0.9931\n",
      "AUC OVO:         1.0000\n",
      "G-Mean:          0.9899\n",
      "Cross-Entropy:   0.0292\n",
      "================================================================================\n",
      "✓ Saved results for tic-tac-toe\n",
      "\n",
      "✓ Completed tic-tac-toe (9/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 10/30: vehicle\n",
      "################################################################################\n",
      "Loading processed dataset from cache: vehicle\n",
      "Dataset: vehicle\n",
      "  Train: (592, 18), Test: (254, 18)\n",
      "  Features: 18, Classes: 4\n",
      "  Model: LIGHTGBM\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: vehicle\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "\n",
      "✓ Optimization complete! Time: 157.92s\n",
      "  Best CV G-Mean: 0.7891\n",
      "  Best parameters:\n",
      "    n_estimators: 308\n",
      "    max_depth: 8\n",
      "    learning_rate: 0.07630380818877312\n",
      "    subsample: 0.6532649032666076\n",
      "    colsample_bytree: 0.8699413223080217\n",
      "    min_child_samples: 42\n",
      "    reg_alpha: 0.21566918047173728\n",
      "    reg_lambda: 0.30707547049597517\n",
      "    num_leaves: 149\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.31s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR vehicle\n",
      "================================================================================\n",
      "Accuracy:        0.7165\n",
      "AUC OVO:         0.9159\n",
      "G-Mean:          0.6816\n",
      "Cross-Entropy:   0.6692\n",
      "================================================================================\n",
      "✓ Saved results for vehicle\n",
      "\n",
      "✓ Completed vehicle (10/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 11/30: vowel\n",
      "################################################################################\n",
      "Loading processed dataset from cache: vowel\n",
      "Dataset: vowel\n",
      "  Train: (693, 27), Test: (297, 27)\n",
      "  Features: 27, Classes: 11\n",
      "  Model: LIGHTGBM\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: vowel\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "\n",
      "✓ Optimization complete! Time: 390.99s\n",
      "  Best CV G-Mean: 0.9209\n",
      "  Best parameters:\n",
      "    n_estimators: 451\n",
      "    max_depth: 10\n",
      "    learning_rate: 0.17265193035375012\n",
      "    subsample: 0.6875496181104785\n",
      "    colsample_bytree: 0.6809842488703094\n",
      "    min_child_samples: 30\n",
      "    reg_alpha: 0.011276685574300623\n",
      "    reg_lambda: 0.8785149582603874\n",
      "    num_leaves: 123\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 1.26s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR vowel\n",
      "================================================================================\n",
      "Accuracy:        0.9192\n",
      "AUC OVO:         0.9947\n",
      "G-Mean:          0.9146\n",
      "Cross-Entropy:   0.2869\n",
      "================================================================================\n",
      "✓ Saved results for vowel\n",
      "\n",
      "✓ Completed vowel (11/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 12/30: wdbc\n",
      "################################################################################\n",
      "Loading processed dataset from cache: wdbc\n",
      "Dataset: wdbc\n",
      "  Train: (398, 30), Test: (171, 30)\n",
      "  Features: 30, Classes: 2\n",
      "  Model: LIGHTGBM\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: wdbc\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n",
      "\n",
      "✓ Optimization complete! Time: 26.39s\n",
      "  Best CV G-Mean: 0.9641\n",
      "  Best parameters:\n",
      "    n_estimators: 288\n",
      "    max_depth: 9\n",
      "    learning_rate: 0.061858058194804465\n",
      "    subsample: 0.8812925628316273\n",
      "    colsample_bytree: 0.7348466085392096\n",
      "    min_child_samples: 66\n",
      "    reg_alpha: 0.792731112895739\n",
      "    reg_lambda: 0.014015836934028025\n",
      "    num_leaves: 120\n",
      "\n",
      "Training final model...\n",
      "✓ Training complete! Time: 0.05s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR wdbc\n",
      "================================================================================\n",
      "Accuracy:        0.9649\n",
      "AUC OVO:         0.9885\n",
      "G-Mean:          0.9625\n",
      "Cross-Entropy:   0.1168\n",
      "================================================================================\n",
      "✓ Saved results for wdbc\n",
      "\n",
      "✓ Completed wdbc (12/30)\n",
      "\n",
      "================================================================================\n",
      "SAVING FINAL RESULTS\n",
      "================================================================================\n",
      "\n",
      "✓ Saved metrics CSV: results\\lightgbm\\lightgbm_metrics.csv\n",
      "  Total datasets: 12\n",
      "  Columns: ['dataset', 'model', 'accuracy', 'auc_ovo', 'gmean', 'cross_entropy', 'n_samples_train', 'n_samples_test', 'n_features', 'n_classes']\n",
      "\n",
      "Metrics Summary:\n",
      "        accuracy    auc_ovo      gmean  cross_entropy\n",
      "count  12.000000  12.000000  12.000000      12.000000\n",
      "mean    0.899668   0.948235   0.792347       0.287412\n",
      "std     0.081213   0.060946   0.213845       0.208140\n",
      "min     0.716535   0.809976   0.356467       0.029194\n",
      "25%     0.877347   0.913820   0.705541       0.129345\n",
      "50%     0.914025   0.975234   0.866355       0.252122\n",
      "75%     0.964934   0.995634   0.962914       0.386888\n",
      "max     0.993056   1.000000   0.989949       0.669163\n",
      "\n",
      "================================================================================\n",
      "RESULTS SUMMARY - LIGHTGBM\n",
      "================================================================================\n",
      "Total datasets: 12\n",
      "\n",
      "Metrics Statistics:\n",
      "        accuracy    auc_ovo      gmean  cross_entropy\n",
      "count  12.000000  12.000000  12.000000      12.000000\n",
      "mean    0.899668   0.948235   0.792347       0.287412\n",
      "std     0.081213   0.060946   0.213845       0.208140\n",
      "min     0.716535   0.809976   0.356467       0.029194\n",
      "25%     0.877347   0.913820   0.705541       0.129345\n",
      "50%     0.914025   0.975234   0.866355       0.252122\n",
      "75%     0.964934   0.995634   0.962914       0.386888\n",
      "max     0.993056   1.000000   0.989949       0.669163\n",
      "\n",
      "Top 5 datasets by accuracy:\n",
      "      dataset  accuracy  auc_ovo    gmean\n",
      "  tic-tac-toe  0.993056 1.000000 0.989949\n",
      "  MiceProtein  0.972222 0.999713 0.971667\n",
      "mfeat-factors  0.965000 0.998120 0.964162\n",
      "         wdbc  0.964912 0.988464 0.962498\n",
      "        vowel  0.919192 0.994713 0.914635\n",
      "\n",
      "Bottom 5 datasets by accuracy:\n",
      "           dataset  accuracy  auc_ovo    gmean\n",
      "           vehicle  0.716535 0.915905 0.681646\n",
      "steel-plates-fault  0.782161 0.962004 0.796223\n",
      "       qsar-biodeg  0.861199 0.907566 0.822741\n",
      "               pc3  0.882729 0.809976 0.424705\n",
      "               pc4  0.910959 0.927616 0.713506\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT COMPLETE FOR LIGHTGBM!\n",
      "================================================================================\n",
      "✓ Total datasets: 30\n",
      "✓ Successful: 12\n",
      "✓ Failed: 0\n",
      "\n",
      "✓ Metrics CSV saved: ./results/lightgbm/lightgbm_metrics.csv\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "run_experiments_for_model(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a4e14da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Encontrados 30 arquivos de resultado\n",
      "  Diretório: results\\lightgbm_final\\individual_results\n",
      "\n",
      "  ✓ analcatdata_authorship\n",
      "  ✓ analcatdata_dmft\n",
      "  ✓ balance-scale\n",
      "  ✓ banknote-authentication\n",
      "  ✓ blood-transfusion-service-center\n",
      "  ✓ breast-w\n",
      "  ✓ car\n",
      "  ✓ climate-model-simulation-crashes\n",
      "  ✓ cmc\n",
      "  ✓ cnae-9\n",
      "  ✓ credit-approval\n",
      "  ✓ credit-g\n",
      "  ✓ cylinder-bands\n",
      "  ✓ diabetes\n",
      "  ✓ dresses-sales\n",
      "  ✓ eucalyptus\n",
      "  ✓ ilpd\n",
      "  ✓ kc2\n",
      "  ✓ mfeat-factors\n",
      "  ✓ MiceProtein\n",
      "  ✓ pc1\n",
      "  ✓ pc3\n",
      "  ✓ pc4\n",
      "  ✓ qsar-biodeg\n",
      "  ✓ semeion\n",
      "  ✓ steel-plates-fault\n",
      "  ✓ tic-tac-toe\n",
      "  ✓ vehicle\n",
      "  ✓ vowel\n",
      "  ✓ wdbc\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS AGREGADOS\n",
      "================================================================================\n",
      "✓ Total de datasets: 30\n",
      "✓ Arquivo salvo: results\\lightgbm_final\\lightgbm_metrics.csv\n",
      "✓ Colunas: ['dataset', 'model', 'accuracy', 'auc_ovo', 'gmean', 'cross_entropy', 'n_samples_train', 'n_samples_test', 'n_features', 'n_classes', 'tuning_time', 'training_time', 'prediction_time', 'total_time']\n",
      "================================================================================\n",
      "\n",
      "Estatísticas das Métricas:\n",
      "        accuracy    auc_ovo      gmean  cross_entropy\n",
      "count  30.000000  30.000000  30.000000      30.000000\n",
      "mean    0.830739   0.887637   0.724398       0.392190\n",
      "std     0.168939   0.120268   0.228504       0.331436\n",
      "min     0.216080   0.575025   0.210395       0.008070\n",
      "25%     0.761358   0.815260   0.572793       0.164225\n",
      "50%     0.896844   0.919058   0.727795       0.329542\n",
      "75%     0.934722   0.994782   0.933023       0.516503\n",
      "max     1.000000   1.000000   1.000000       1.598736\n",
      "\n",
      "================================================================================\n",
      "DATASETS PROCESSADOS (ordenados alfabeticamente):\n",
      "================================================================================\n",
      "  1. MiceProtein\n",
      "  2. analcatdata_authorship\n",
      "  3. analcatdata_dmft\n",
      "  4. balance-scale\n",
      "  5. banknote-authentication\n",
      "  6. blood-transfusion-service-center\n",
      "  7. breast-w\n",
      "  8. car\n",
      "  9. climate-model-simulation-crashes\n",
      " 10. cmc\n",
      " 11. cnae-9\n",
      " 12. credit-approval\n",
      " 13. credit-g\n",
      " 14. cylinder-bands\n",
      " 15. diabetes\n",
      " 16. dresses-sales\n",
      " 17. eucalyptus\n",
      " 18. ilpd\n",
      " 19. kc2\n",
      " 20. mfeat-factors\n",
      " 21. pc1\n",
      " 22. pc3\n",
      " 23. pc4\n",
      " 24. qsar-biodeg\n",
      " 25. semeion\n",
      " 26. steel-plates-fault\n",
      " 27. tic-tac-toe\n",
      " 28. vehicle\n",
      " 29. vowel\n",
      " 30. wdbc\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc_ovo</th>\n",
       "      <th>gmean</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>n_samples_train</th>\n",
       "      <th>n_samples_test</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>tuning_time</th>\n",
       "      <th>training_time</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MiceProtein</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.999713</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.081560</td>\n",
       "      <td>756</td>\n",
       "      <td>324</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>545.476862</td>\n",
       "      <td>0.481711</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>545.969544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>analcatdata_authorship</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.980237</td>\n",
       "      <td>0.998959</td>\n",
       "      <td>0.959238</td>\n",
       "      <td>0.056321</td>\n",
       "      <td>588</td>\n",
       "      <td>253</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>562.540354</td>\n",
       "      <td>0.933503</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>563.475853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>analcatdata_dmft</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.575025</td>\n",
       "      <td>0.210395</td>\n",
       "      <td>1.598736</td>\n",
       "      <td>462</td>\n",
       "      <td>199</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>408.131138</td>\n",
       "      <td>0.455782</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>408.587918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balance-scale</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.920213</td>\n",
       "      <td>0.961344</td>\n",
       "      <td>0.633699</td>\n",
       "      <td>0.202047</td>\n",
       "      <td>437</td>\n",
       "      <td>188</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>434.957399</td>\n",
       "      <td>0.976389</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>435.936780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008070</td>\n",
       "      <td>960</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250.728616</td>\n",
       "      <td>0.340091</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>251.070701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blood-transfusion-service-center</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.782222</td>\n",
       "      <td>0.765053</td>\n",
       "      <td>0.495595</td>\n",
       "      <td>0.467822</td>\n",
       "      <td>523</td>\n",
       "      <td>225</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>130.466971</td>\n",
       "      <td>0.198468</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>130.666437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>breast-w</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.983243</td>\n",
       "      <td>0.929261</td>\n",
       "      <td>0.154893</td>\n",
       "      <td>489</td>\n",
       "      <td>210</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>108.012728</td>\n",
       "      <td>0.164560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>108.177288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>car</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.980732</td>\n",
       "      <td>0.999557</td>\n",
       "      <td>0.991576</td>\n",
       "      <td>0.068121</td>\n",
       "      <td>1209</td>\n",
       "      <td>519</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>944.546756</td>\n",
       "      <td>3.689135</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>948.251848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>climate-model-simulation-crashes</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.919753</td>\n",
       "      <td>0.879826</td>\n",
       "      <td>0.589483</td>\n",
       "      <td>0.223970</td>\n",
       "      <td>378</td>\n",
       "      <td>162</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>149.796075</td>\n",
       "      <td>0.425861</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>150.223931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cmc</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.522624</td>\n",
       "      <td>0.709721</td>\n",
       "      <td>0.488263</td>\n",
       "      <td>0.935712</td>\n",
       "      <td>1031</td>\n",
       "      <td>442</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>628.163919</td>\n",
       "      <td>0.881642</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>629.047556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cnae-9</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.995370</td>\n",
       "      <td>0.934278</td>\n",
       "      <td>0.249386</td>\n",
       "      <td>756</td>\n",
       "      <td>324</td>\n",
       "      <td>856</td>\n",
       "      <td>9</td>\n",
       "      <td>655.473542</td>\n",
       "      <td>1.822127</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>657.303647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>credit-approval</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.874396</td>\n",
       "      <td>0.922212</td>\n",
       "      <td>0.872712</td>\n",
       "      <td>0.369051</td>\n",
       "      <td>483</td>\n",
       "      <td>207</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>145.536342</td>\n",
       "      <td>0.289227</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>145.826566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>credit-g</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.767249</td>\n",
       "      <td>0.642910</td>\n",
       "      <td>0.514917</td>\n",
       "      <td>700</td>\n",
       "      <td>300</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>173.865962</td>\n",
       "      <td>0.514624</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>174.382581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cylinder-bands</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.831195</td>\n",
       "      <td>0.742084</td>\n",
       "      <td>0.517031</td>\n",
       "      <td>378</td>\n",
       "      <td>162</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>304.786197</td>\n",
       "      <td>0.429851</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>305.217045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.692583</td>\n",
       "      <td>0.481606</td>\n",
       "      <td>537</td>\n",
       "      <td>231</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>126.957733</td>\n",
       "      <td>0.185504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>127.143236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dresses-sales</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.644682</td>\n",
       "      <td>0.561490</td>\n",
       "      <td>0.667470</td>\n",
       "      <td>350</td>\n",
       "      <td>150</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>123.138482</td>\n",
       "      <td>0.280250</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>123.419729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eucalyptus</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.903316</td>\n",
       "      <td>0.604433</td>\n",
       "      <td>0.811150</td>\n",
       "      <td>515</td>\n",
       "      <td>221</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>685.447329</td>\n",
       "      <td>1.866010</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>687.317328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ilpd</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.708571</td>\n",
       "      <td>0.708560</td>\n",
       "      <td>0.308545</td>\n",
       "      <td>0.528602</td>\n",
       "      <td>408</td>\n",
       "      <td>175</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>148.532252</td>\n",
       "      <td>0.229387</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>148.762635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kc2</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.815287</td>\n",
       "      <td>0.773875</td>\n",
       "      <td>0.567230</td>\n",
       "      <td>0.461844</td>\n",
       "      <td>365</td>\n",
       "      <td>157</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>143.261064</td>\n",
       "      <td>0.307179</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>143.569239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mfeat-factors</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.998120</td>\n",
       "      <td>0.964162</td>\n",
       "      <td>0.133537</td>\n",
       "      <td>1400</td>\n",
       "      <td>600</td>\n",
       "      <td>216</td>\n",
       "      <td>10</td>\n",
       "      <td>1392.204723</td>\n",
       "      <td>4.138931</td>\n",
       "      <td>0.090758</td>\n",
       "      <td>1396.434412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pc1</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.915916</td>\n",
       "      <td>0.879944</td>\n",
       "      <td>0.356467</td>\n",
       "      <td>0.192223</td>\n",
       "      <td>776</td>\n",
       "      <td>333</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>43.972415</td>\n",
       "      <td>0.064826</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>44.042229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pc3</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.882729</td>\n",
       "      <td>0.809976</td>\n",
       "      <td>0.424705</td>\n",
       "      <td>0.384551</td>\n",
       "      <td>1094</td>\n",
       "      <td>469</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>81.696538</td>\n",
       "      <td>0.237365</td>\n",
       "      <td>0.011968</td>\n",
       "      <td>81.945871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pc4</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.910959</td>\n",
       "      <td>0.927616</td>\n",
       "      <td>0.713506</td>\n",
       "      <td>0.217368</td>\n",
       "      <td>1020</td>\n",
       "      <td>438</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>64.129512</td>\n",
       "      <td>0.128656</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>64.266147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qsar-biodeg</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.861199</td>\n",
       "      <td>0.907566</td>\n",
       "      <td>0.822741</td>\n",
       "      <td>0.393900</td>\n",
       "      <td>738</td>\n",
       "      <td>317</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>57.702698</td>\n",
       "      <td>0.124667</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>57.833349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>semeion</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.912134</td>\n",
       "      <td>0.994805</td>\n",
       "      <td>0.909970</td>\n",
       "      <td>0.290033</td>\n",
       "      <td>1115</td>\n",
       "      <td>478</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>706.293828</td>\n",
       "      <td>1.616675</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>707.972339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>steel-plates-fault</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.782161</td>\n",
       "      <td>0.962004</td>\n",
       "      <td>0.796223</td>\n",
       "      <td>0.653766</td>\n",
       "      <td>1358</td>\n",
       "      <td>583</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>380.413747</td>\n",
       "      <td>1.097066</td>\n",
       "      <td>0.056848</td>\n",
       "      <td>381.567661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tic-tac-toe</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>0.029194</td>\n",
       "      <td>670</td>\n",
       "      <td>288</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>47.325447</td>\n",
       "      <td>0.093749</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>47.425181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>vehicle</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>0.915905</td>\n",
       "      <td>0.681646</td>\n",
       "      <td>0.669163</td>\n",
       "      <td>592</td>\n",
       "      <td>254</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>157.917717</td>\n",
       "      <td>0.307179</td>\n",
       "      <td>0.012966</td>\n",
       "      <td>158.237862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vowel</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.994713</td>\n",
       "      <td>0.914635</td>\n",
       "      <td>0.286876</td>\n",
       "      <td>693</td>\n",
       "      <td>297</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>390.992459</td>\n",
       "      <td>1.264618</td>\n",
       "      <td>0.063829</td>\n",
       "      <td>392.320905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>wdbc</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>0.962498</td>\n",
       "      <td>0.116772</td>\n",
       "      <td>398</td>\n",
       "      <td>171</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>26.391427</td>\n",
       "      <td>0.048869</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>26.443289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dataset     model  accuracy   auc_ovo     gmean  \\\n",
       "0                        MiceProtein  lightgbm  0.972222  0.999713  0.971667   \n",
       "1             analcatdata_authorship  lightgbm  0.980237  0.998959  0.959238   \n",
       "2                   analcatdata_dmft  lightgbm  0.216080  0.575025  0.210395   \n",
       "3                      balance-scale  lightgbm  0.920213  0.961344  0.633699   \n",
       "4            banknote-authentication  lightgbm  1.000000  1.000000  1.000000   \n",
       "5   blood-transfusion-service-center  lightgbm  0.782222  0.765053  0.495595   \n",
       "6                           breast-w  lightgbm  0.933333  0.983243  0.929261   \n",
       "7                                car  lightgbm  0.980732  0.999557  0.991576   \n",
       "8   climate-model-simulation-crashes  lightgbm  0.919753  0.879826  0.589483   \n",
       "9                                cmc  lightgbm  0.522624  0.709721  0.488263   \n",
       "10                            cnae-9  lightgbm  0.935185  0.995370  0.934278   \n",
       "11                   credit-approval  lightgbm  0.874396  0.922212  0.872712   \n",
       "12                          credit-g  lightgbm  0.760000  0.767249  0.642910   \n",
       "13                    cylinder-bands  lightgbm  0.765432  0.831195  0.742084   \n",
       "14                          diabetes  lightgbm  0.740260  0.831111  0.692583   \n",
       "15                     dresses-sales  lightgbm  0.606667  0.644682  0.561490   \n",
       "16                        eucalyptus  lightgbm  0.665158  0.903316  0.604433   \n",
       "17                              ilpd  lightgbm  0.708571  0.708560  0.308545   \n",
       "18                               kc2  lightgbm  0.815287  0.773875  0.567230   \n",
       "19                     mfeat-factors  lightgbm  0.965000  0.998120  0.964162   \n",
       "20                               pc1  lightgbm  0.915916  0.879944  0.356467   \n",
       "21                               pc3  lightgbm  0.882729  0.809976  0.424705   \n",
       "22                               pc4  lightgbm  0.910959  0.927616  0.713506   \n",
       "23                       qsar-biodeg  lightgbm  0.861199  0.907566  0.822741   \n",
       "24                           semeion  lightgbm  0.912134  0.994805  0.909970   \n",
       "25                steel-plates-fault  lightgbm  0.782161  0.962004  0.796223   \n",
       "26                       tic-tac-toe  lightgbm  0.993056  1.000000  0.989949   \n",
       "27                           vehicle  lightgbm  0.716535  0.915905  0.681646   \n",
       "28                             vowel  lightgbm  0.919192  0.994713  0.914635   \n",
       "29                              wdbc  lightgbm  0.964912  0.988464  0.962498   \n",
       "\n",
       "    cross_entropy  n_samples_train  n_samples_test  n_features  n_classes  \\\n",
       "0        0.081560              756             324          77          8   \n",
       "1        0.056321              588             253          70          4   \n",
       "2        1.598736              462             199           7          5   \n",
       "3        0.202047              437             188           4          3   \n",
       "4        0.008070              960             412           4          2   \n",
       "5        0.467822              523             225           4          2   \n",
       "6        0.154893              489             210           9          2   \n",
       "7        0.068121             1209             519          21          4   \n",
       "8        0.223970              378             162          18          2   \n",
       "9        0.935712             1031             442           9          3   \n",
       "10       0.249386              756             324         856          9   \n",
       "11       0.369051              483             207          46          2   \n",
       "12       0.514917              700             300          61          2   \n",
       "13       0.517031              378             162         119          2   \n",
       "14       0.481606              537             231           8          2   \n",
       "15       0.667470              350             150         141          2   \n",
       "16       0.811150              515             221          91          5   \n",
       "17       0.528602              408             175          11          2   \n",
       "18       0.461844              365             157          21          2   \n",
       "19       0.133537             1400             600         216         10   \n",
       "20       0.192223              776             333          21          2   \n",
       "21       0.384551             1094             469          37          2   \n",
       "22       0.217368             1020             438          37          2   \n",
       "23       0.393900              738             317          41          2   \n",
       "24       0.290033             1115             478         256         10   \n",
       "25       0.653766             1358             583          27          7   \n",
       "26       0.029194              670             288          27          2   \n",
       "27       0.669163              592             254          18          4   \n",
       "28       0.286876              693             297          27         11   \n",
       "29       0.116772              398             171          30          2   \n",
       "\n",
       "    tuning_time  training_time  prediction_time   total_time  \n",
       "0    545.476862       0.481711         0.010971   545.969544  \n",
       "1    562.540354       0.933503         0.001995   563.475853  \n",
       "2    408.131138       0.455782         0.000998   408.587918  \n",
       "3    434.957399       0.976389         0.002993   435.936780  \n",
       "4    250.728616       0.340091         0.001995   251.070701  \n",
       "5    130.466971       0.198468         0.000998   130.666437  \n",
       "6    108.012728       0.164560         0.000000   108.177288  \n",
       "7    944.546756       3.689135         0.015958   948.251848  \n",
       "8    149.796075       0.425861         0.001995   150.223931  \n",
       "9    628.163919       0.881642         0.001995   629.047556  \n",
       "10   655.473542       1.822127         0.007979   657.303647  \n",
       "11   145.536342       0.289227         0.000997   145.826566  \n",
       "12   173.865962       0.514624         0.001995   174.382581  \n",
       "13   304.786197       0.429851         0.000997   305.217045  \n",
       "14   126.957733       0.185504         0.000000   127.143236  \n",
       "15   123.138482       0.280250         0.000998   123.419729  \n",
       "16   685.447329       1.866010         0.003989   687.317328  \n",
       "17   148.532252       0.229387         0.000997   148.762635  \n",
       "18   143.261064       0.307179         0.000997   143.569239  \n",
       "19  1392.204723       4.138931         0.090758  1396.434412  \n",
       "20    43.972415       0.064826         0.004988    44.042229  \n",
       "21    81.696538       0.237365         0.011968    81.945871  \n",
       "22    64.129512       0.128656         0.007979    64.266147  \n",
       "23    57.702698       0.124667         0.005983    57.833349  \n",
       "24   706.293828       1.616675         0.061836   707.972339  \n",
       "25   380.413747       1.097066         0.056848   381.567661  \n",
       "26    47.325447       0.093749         0.005985    47.425181  \n",
       "27   157.917717       0.307179         0.012966   158.237862  \n",
       "28   390.992459       1.264618         0.063829   392.320905  \n",
       "29    26.391427       0.048869         0.002993    26.443289  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_results(results_dir=\"./results/lightgbm_final\", model_name=\"lightgbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d8452c",
   "metadata": {},
   "source": [
    "## Resnet\n",
    "\n",
    "(apenas agregando os resultados dos datasets individuais pra incluir o tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f81bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Encontrados 30 arquivos de resultado\n",
      "  Diretório: results\\resnet\\individual_results\n",
      "\n",
      "  ✓ analcatdata_authorship\n",
      "  ✓ analcatdata_dmft\n",
      "  ✓ balance-scale\n",
      "  ✓ banknote-authentication\n",
      "  ✓ blood-transfusion-service-center\n",
      "  ✓ breast-w\n",
      "  ✓ car\n",
      "  ✓ climate-model-simulation-crashes\n",
      "  ✓ cmc\n",
      "  ✓ cnae-9\n",
      "  ✓ credit-approval\n",
      "  ✓ credit-g\n",
      "  ✓ cylinder-bands\n",
      "  ✓ diabetes\n",
      "  ✓ dresses-sales\n",
      "  ✓ eucalyptus\n",
      "  ✓ ilpd\n",
      "  ✓ kc2\n",
      "  ✓ mfeat-factors\n",
      "  ✓ MiceProtein\n",
      "  ✓ pc1\n",
      "  ✓ pc3\n",
      "  ✓ pc4\n",
      "  ✓ qsar-biodeg\n",
      "  ✓ semeion\n",
      "  ✓ steel-plates-fault\n",
      "  ✓ tic-tac-toe\n",
      "  ✓ vehicle\n",
      "  ✓ vowel\n",
      "  ✓ wdbc\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS AGREGADOS\n",
      "================================================================================\n",
      "✓ Total de datasets: 30\n",
      "✓ Arquivo salvo: results\\resnet\\resnet_metrics.csv\n",
      "✓ Colunas: ['dataset', 'model', 'accuracy', 'auc_ovo', 'gmean', 'cross_entropy', 'n_samples_train', 'n_samples_test', 'n_features', 'n_classes', 'tuning_time', 'training_time', 'prediction_time', 'total_time']\n",
      "================================================================================\n",
      "\n",
      "Estatísticas das Métricas:\n",
      "        accuracy    auc_ovo      gmean  cross_entropy\n",
      "count  30.000000  30.000000  30.000000      30.000000\n",
      "mean    0.827024   0.891088   0.785000       0.401201\n",
      "std     0.182493   0.126148   0.201549       0.372629\n",
      "min     0.231156   0.556069   0.227015       0.014495\n",
      "25%     0.742520   0.807025   0.669558       0.108775\n",
      "50%     0.884833   0.924514   0.821570       0.326806\n",
      "75%     0.967242   0.996815   0.964126       0.548645\n",
      "max     1.000000   1.000000   1.000000       1.753764\n",
      "\n",
      "================================================================================\n",
      "DATASETS PROCESSADOS (ordenados alfabeticamente):\n",
      "================================================================================\n",
      "  1. MiceProtein\n",
      "  2. analcatdata_authorship\n",
      "  3. analcatdata_dmft\n",
      "  4. balance-scale\n",
      "  5. banknote-authentication\n",
      "  6. blood-transfusion-service-center\n",
      "  7. breast-w\n",
      "  8. car\n",
      "  9. climate-model-simulation-crashes\n",
      " 10. cmc\n",
      " 11. cnae-9\n",
      " 12. credit-approval\n",
      " 13. credit-g\n",
      " 14. cylinder-bands\n",
      " 15. diabetes\n",
      " 16. dresses-sales\n",
      " 17. eucalyptus\n",
      " 18. ilpd\n",
      " 19. kc2\n",
      " 20. mfeat-factors\n",
      " 21. pc1\n",
      " 22. pc3\n",
      " 23. pc4\n",
      " 24. qsar-biodeg\n",
      " 25. semeion\n",
      " 26. steel-plates-fault\n",
      " 27. tic-tac-toe\n",
      " 28. vehicle\n",
      " 29. vowel\n",
      " 30. wdbc\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc_ovo</th>\n",
       "      <th>gmean</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>n_samples_train</th>\n",
       "      <th>n_samples_test</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>tuning_time</th>\n",
       "      <th>training_time</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MiceProtein</td>\n",
       "      <td>resnet</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015068</td>\n",
       "      <td>756</td>\n",
       "      <td>324</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>5354.079092</td>\n",
       "      <td>16.843500</td>\n",
       "      <td>0.011285</td>\n",
       "      <td>5370.933877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>analcatdata_authorship</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.988142</td>\n",
       "      <td>0.999905</td>\n",
       "      <td>0.991464</td>\n",
       "      <td>0.045285</td>\n",
       "      <td>588</td>\n",
       "      <td>253</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>4799.100377</td>\n",
       "      <td>13.060215</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>4812.162596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>analcatdata_dmft</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.231156</td>\n",
       "      <td>0.556069</td>\n",
       "      <td>0.227015</td>\n",
       "      <td>1.753764</td>\n",
       "      <td>462</td>\n",
       "      <td>199</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>420.625941</td>\n",
       "      <td>0.751168</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>421.380017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balance-scale</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.996818</td>\n",
       "      <td>0.965945</td>\n",
       "      <td>0.070676</td>\n",
       "      <td>437</td>\n",
       "      <td>188</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>503.645045</td>\n",
       "      <td>0.174086</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>503.819616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>resnet</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017180</td>\n",
       "      <td>960</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2413.925925</td>\n",
       "      <td>1.024395</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>2414.951865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blood-transfusion-service-center</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.604444</td>\n",
       "      <td>0.717349</td>\n",
       "      <td>0.653873</td>\n",
       "      <td>0.680959</td>\n",
       "      <td>523</td>\n",
       "      <td>225</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>824.185309</td>\n",
       "      <td>2.923539</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>827.111244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>breast-w</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.983696</td>\n",
       "      <td>0.932667</td>\n",
       "      <td>0.319321</td>\n",
       "      <td>489</td>\n",
       "      <td>210</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>713.480148</td>\n",
       "      <td>1.936967</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>715.418145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>car</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>0.999831</td>\n",
       "      <td>0.971309</td>\n",
       "      <td>0.027829</td>\n",
       "      <td>1209</td>\n",
       "      <td>519</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>3397.871263</td>\n",
       "      <td>11.452116</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>3409.325118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>climate-model-simulation-crashes</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.895062</td>\n",
       "      <td>0.910232</td>\n",
       "      <td>0.843439</td>\n",
       "      <td>0.313689</td>\n",
       "      <td>378</td>\n",
       "      <td>162</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>467.067612</td>\n",
       "      <td>0.352445</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>467.421067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cmc</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.719239</td>\n",
       "      <td>0.528419</td>\n",
       "      <td>0.984051</td>\n",
       "      <td>1031</td>\n",
       "      <td>442</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>924.599920</td>\n",
       "      <td>0.898741</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>925.503849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cnae-9</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.959877</td>\n",
       "      <td>0.994995</td>\n",
       "      <td>0.958668</td>\n",
       "      <td>0.184240</td>\n",
       "      <td>756</td>\n",
       "      <td>324</td>\n",
       "      <td>856</td>\n",
       "      <td>9</td>\n",
       "      <td>833.555741</td>\n",
       "      <td>0.247812</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>833.804316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>credit-approval</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.835749</td>\n",
       "      <td>0.916919</td>\n",
       "      <td>0.833491</td>\n",
       "      <td>0.398045</td>\n",
       "      <td>483</td>\n",
       "      <td>207</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>1577.421031</td>\n",
       "      <td>8.030673</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>1585.453908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>credit-g</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.761058</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555203</td>\n",
       "      <td>700</td>\n",
       "      <td>300</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>896.121319</td>\n",
       "      <td>1.182522</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>897.306596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cylinder-bands</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.826658</td>\n",
       "      <td>0.749531</td>\n",
       "      <td>0.639057</td>\n",
       "      <td>378</td>\n",
       "      <td>162</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>779.544501</td>\n",
       "      <td>1.579031</td>\n",
       "      <td>0.007210</td>\n",
       "      <td>781.130742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.783550</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.693177</td>\n",
       "      <td>0.505810</td>\n",
       "      <td>537</td>\n",
       "      <td>231</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>485.310113</td>\n",
       "      <td>0.315379</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>485.626225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dresses-sales</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.586389</td>\n",
       "      <td>0.447988</td>\n",
       "      <td>0.748362</td>\n",
       "      <td>350</td>\n",
       "      <td>150</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>576.755337</td>\n",
       "      <td>0.742513</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>577.499119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eucalyptus</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.628959</td>\n",
       "      <td>0.901013</td>\n",
       "      <td>0.575871</td>\n",
       "      <td>0.822552</td>\n",
       "      <td>515</td>\n",
       "      <td>221</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>1837.123058</td>\n",
       "      <td>6.387278</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>1843.512311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ilpd</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.800480</td>\n",
       "      <td>0.701769</td>\n",
       "      <td>0.527811</td>\n",
       "      <td>408</td>\n",
       "      <td>175</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>512.774971</td>\n",
       "      <td>0.270946</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>513.048588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kc2</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.834395</td>\n",
       "      <td>0.798125</td>\n",
       "      <td>0.678233</td>\n",
       "      <td>0.528971</td>\n",
       "      <td>365</td>\n",
       "      <td>157</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>470.931065</td>\n",
       "      <td>0.410381</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>471.343713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mfeat-factors</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.978333</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.977986</td>\n",
       "      <td>0.076406</td>\n",
       "      <td>1400</td>\n",
       "      <td>600</td>\n",
       "      <td>216</td>\n",
       "      <td>10</td>\n",
       "      <td>6063.917691</td>\n",
       "      <td>9.926876</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>6073.847251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pc1</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.909910</td>\n",
       "      <td>0.851613</td>\n",
       "      <td>0.457139</td>\n",
       "      <td>0.271326</td>\n",
       "      <td>776</td>\n",
       "      <td>333</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>801.228540</td>\n",
       "      <td>0.113705</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>801.343180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pc3</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.876333</td>\n",
       "      <td>0.788500</td>\n",
       "      <td>0.575719</td>\n",
       "      <td>0.355050</td>\n",
       "      <td>1094</td>\n",
       "      <td>469</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>1286.607191</td>\n",
       "      <td>0.522914</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>1287.131875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pc4</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.892694</td>\n",
       "      <td>0.928645</td>\n",
       "      <td>0.791402</td>\n",
       "      <td>0.236218</td>\n",
       "      <td>1020</td>\n",
       "      <td>438</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>1160.086151</td>\n",
       "      <td>0.647653</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>1160.737485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qsar-biodeg</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.876972</td>\n",
       "      <td>0.920383</td>\n",
       "      <td>0.867758</td>\n",
       "      <td>0.334290</td>\n",
       "      <td>738</td>\n",
       "      <td>317</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1781.810495</td>\n",
       "      <td>4.696576</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>1786.508661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>semeion</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.928870</td>\n",
       "      <td>0.996808</td>\n",
       "      <td>0.926845</td>\n",
       "      <td>0.229133</td>\n",
       "      <td>1115</td>\n",
       "      <td>478</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>6035.203535</td>\n",
       "      <td>11.567870</td>\n",
       "      <td>0.013789</td>\n",
       "      <td>6046.785194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>steel-plates-fault</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.747856</td>\n",
       "      <td>0.954008</td>\n",
       "      <td>0.802754</td>\n",
       "      <td>0.758142</td>\n",
       "      <td>1358</td>\n",
       "      <td>583</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>2177.643274</td>\n",
       "      <td>0.336215</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>2177.980653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tic-tac-toe</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.996528</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>670</td>\n",
       "      <td>288</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1036.843957</td>\n",
       "      <td>2.439770</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>1039.287743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>vehicle</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.962059</td>\n",
       "      <td>0.809650</td>\n",
       "      <td>0.387724</td>\n",
       "      <td>592</td>\n",
       "      <td>254</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3487.249420</td>\n",
       "      <td>9.478545</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>3496.730029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vowel</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.968365</td>\n",
       "      <td>0.099866</td>\n",
       "      <td>693</td>\n",
       "      <td>297</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>2328.039556</td>\n",
       "      <td>2.346353</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>2330.391649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>wdbc</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.989632</td>\n",
       "      <td>0.957859</td>\n",
       "      <td>0.135501</td>\n",
       "      <td>398</td>\n",
       "      <td>171</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>906.965761</td>\n",
       "      <td>0.364606</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>907.331275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dataset   model  accuracy   auc_ovo     gmean  \\\n",
       "0                        MiceProtein  resnet  1.000000  1.000000  1.000000   \n",
       "1             analcatdata_authorship  resnet  0.988142  0.999905  0.991464   \n",
       "2                   analcatdata_dmft  resnet  0.231156  0.556069  0.227015   \n",
       "3                      balance-scale  resnet  0.978723  0.996818  0.965945   \n",
       "4            banknote-authentication  resnet  1.000000  1.000000  1.000000   \n",
       "5   blood-transfusion-service-center  resnet  0.604444  0.717349  0.653873   \n",
       "6                           breast-w  resnet  0.933333  0.983696  0.932667   \n",
       "7                                car  resnet  0.988439  0.999831  0.971309   \n",
       "8   climate-model-simulation-crashes  resnet  0.895062  0.910232  0.843439   \n",
       "9                                cmc  resnet  0.538462  0.719239  0.528419   \n",
       "10                            cnae-9  resnet  0.959877  0.994995  0.958668   \n",
       "11                   credit-approval  resnet  0.835749  0.916919  0.833491   \n",
       "12                          credit-g  resnet  0.726667  0.761058  0.666667   \n",
       "13                    cylinder-bands  resnet  0.740741  0.826658  0.749531   \n",
       "14                          diabetes  resnet  0.783550  0.874074  0.693177   \n",
       "15                     dresses-sales  resnet  0.500000  0.586389  0.447988   \n",
       "16                        eucalyptus  resnet  0.628959  0.901013  0.575871   \n",
       "17                              ilpd  resnet  0.680000  0.800480  0.701769   \n",
       "18                               kc2  resnet  0.834395  0.798125  0.678233   \n",
       "19                     mfeat-factors  resnet  0.978333  0.999250  0.977986   \n",
       "20                               pc1  resnet  0.909910  0.851613  0.457139   \n",
       "21                               pc3  resnet  0.876333  0.788500  0.575719   \n",
       "22                               pc4  resnet  0.892694  0.928645  0.791402   \n",
       "23                       qsar-biodeg  resnet  0.876972  0.920383  0.867758   \n",
       "24                           semeion  resnet  0.928870  0.996808  0.926845   \n",
       "25                steel-plates-fault  resnet  0.747856  0.954008  0.802754   \n",
       "26                       tic-tac-toe  resnet  0.996528  0.999894  0.994987   \n",
       "27                           vehicle  resnet  0.826772  0.962059  0.809650   \n",
       "28                             vowel  resnet  0.969697  0.999002  0.968365   \n",
       "29                              wdbc  resnet  0.959064  0.989632  0.957859   \n",
       "\n",
       "    cross_entropy  n_samples_train  n_samples_test  n_features  n_classes  \\\n",
       "0        0.015068              756             324          77          8   \n",
       "1        0.045285              588             253          70          4   \n",
       "2        1.753764              462             199           7          5   \n",
       "3        0.070676              437             188           4          3   \n",
       "4        0.017180              960             412           4          2   \n",
       "5        0.680959              523             225           4          2   \n",
       "6        0.319321              489             210           9          2   \n",
       "7        0.027829             1209             519          21          4   \n",
       "8        0.313689              378             162          18          2   \n",
       "9        0.984051             1031             442           9          3   \n",
       "10       0.184240              756             324         856          9   \n",
       "11       0.398045              483             207          46          2   \n",
       "12       0.555203              700             300          61          2   \n",
       "13       0.639057              378             162         119          2   \n",
       "14       0.505810              537             231           8          2   \n",
       "15       0.748362              350             150         141          2   \n",
       "16       0.822552              515             221          91          5   \n",
       "17       0.527811              408             175          11          2   \n",
       "18       0.528971              365             157          21          2   \n",
       "19       0.076406             1400             600         216         10   \n",
       "20       0.271326              776             333          21          2   \n",
       "21       0.355050             1094             469          37          2   \n",
       "22       0.236218             1020             438          37          2   \n",
       "23       0.334290              738             317          41          2   \n",
       "24       0.229133             1115             478         256         10   \n",
       "25       0.758142             1358             583          27          7   \n",
       "26       0.014495              670             288          27          2   \n",
       "27       0.387724              592             254          18          4   \n",
       "28       0.099866              693             297          27         11   \n",
       "29       0.135501              398             171          30          2   \n",
       "\n",
       "    tuning_time  training_time  prediction_time   total_time  \n",
       "0   5354.079092      16.843500         0.011285  5370.933877  \n",
       "1   4799.100377      13.060215         0.002005  4812.162596  \n",
       "2    420.625941       0.751168         0.002909   421.380017  \n",
       "3    503.645045       0.174086         0.000485   503.819616  \n",
       "4   2413.925925       1.024395         0.001544  2414.951865  \n",
       "5    824.185309       2.923539         0.002396   827.111244  \n",
       "6    713.480148       1.936967         0.001030   715.418145  \n",
       "7   3397.871263      11.452116         0.001740  3409.325118  \n",
       "8    467.067612       0.352445         0.001011   467.421067  \n",
       "9    924.599920       0.898741         0.005188   925.503849  \n",
       "10   833.555741       0.247812         0.000763   833.804316  \n",
       "11  1577.421031       8.030673         0.002204  1585.453908  \n",
       "12   896.121319       1.182522         0.002755   897.306596  \n",
       "13   779.544501       1.579031         0.007210   781.130742  \n",
       "14   485.310113       0.315379         0.000733   485.626225  \n",
       "15   576.755337       0.742513         0.001270   577.499119  \n",
       "16  1837.123058       6.387278         0.001975  1843.512311  \n",
       "17   512.774971       0.270946         0.002671   513.048588  \n",
       "18   470.931065       0.410381         0.002268   471.343713  \n",
       "19  6063.917691       9.926876         0.002683  6073.847251  \n",
       "20   801.228540       0.113705         0.000935   801.343180  \n",
       "21  1286.607191       0.522914         0.001770  1287.131875  \n",
       "22  1160.086151       0.647653         0.003681  1160.737485  \n",
       "23  1781.810495       4.696576         0.001590  1786.508661  \n",
       "24  6035.203535      11.567870         0.013789  6046.785194  \n",
       "25  2177.643274       0.336215         0.001165  2177.980653  \n",
       "26  1036.843957       2.439770         0.004016  1039.287743  \n",
       "27  3487.249420       9.478545         0.002064  3496.730029  \n",
       "28  2328.039556       2.346353         0.005740  2330.391649  \n",
       "29   906.965761       0.364606         0.000908   907.331275  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_results(results_dir=\"./results/resnet\", model_name=\"resnet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
