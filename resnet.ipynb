{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecef440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/Research/tabular-resnet/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "from data.data import DataProcessor\n",
    "from evaluation.evaluation import ResultsManager\n",
    "from experiments.resnet_experiment import TabularResNetExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9556c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = \"./data/openml_cache\"\n",
    "RESULTS_DIR = \"./results/resnet\"\n",
    "MODEL_NAME = \"resnet\"\n",
    "\n",
    "SEED = 123\n",
    "N_TRIALS = 50  # Optuna trials\n",
    "CV_FOLDS = 10  # Cross-validation folds\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"TABULAR RESNET - EXPERIMENT PIPELINE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Model: {MODEL_NAME}\")\n",
    "    print(f\"Seed: {SEED}\")\n",
    "    print(f\"Optuna trials: {N_TRIALS}\")\n",
    "    print(f\"CV folds: {CV_FOLDS}\")\n",
    "    print(f\"Results directory: {RESULTS_DIR}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Initialize data processor and results manager\n",
    "    processor = DataProcessor(seed=SEED, cache_dir=CACHE_DIR)\n",
    "    results_manager = ResultsManager(save_dir=RESULTS_DIR, model_name=MODEL_NAME)\n",
    "\n",
    "    # Find all processed PKL files\n",
    "    pkl_files = list(processor.cache_dir.glob(\"*_dataset.pkl\"))\n",
    "\n",
    "    if not pkl_files:\n",
    "        print(\"\\nNo processed datasets found!\")\n",
    "        print(f\"Looking in: {processor.cache_dir}\")\n",
    "        print(\"\\nPlease run one of these first:\")\n",
    "        print(\"  1. python data.py (Pattern 1: to download and process)\")\n",
    "        print(\"  2. python data.py (Pattern 2: to process from raw CSVs)\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n✓ Found {len(pkl_files)} processed datasets\\n\")\n",
    "\n",
    "    # Run experiments on all datasets\n",
    "    failed_datasets = []\n",
    "\n",
    "    for idx, pkl_file in enumerate(pkl_files, 1):\n",
    "        # Extract dataset name\n",
    "        dataset_name = pkl_file.stem.replace(\"_dataset\", \"\")\n",
    "\n",
    "        print(f\"\\n{'#' * 80}\")\n",
    "        print(f\"DATASET {idx}/{len(pkl_files)}: {dataset_name}\")\n",
    "        print(f\"{'#' * 80}\")\n",
    "\n",
    "        try:\n",
    "            # Load processed dataset (numpy arrays)\n",
    "            X_train, y_train, X_test, y_test = processor.load_or_process_dataset(\n",
    "                name=dataset_name\n",
    "            )\n",
    "\n",
    "            # Get number of classes\n",
    "            n_classes = len(set(y_train))\n",
    "\n",
    "            # Create experiment\n",
    "            experiment = TabularResNetExperiment(\n",
    "                dataset_name=dataset_name,\n",
    "                X_train=X_train,\n",
    "                y_train=y_train,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                n_classes=n_classes,\n",
    "                n_trials=N_TRIALS,\n",
    "                cv_folds=CV_FOLDS,\n",
    "                seed=SEED,\n",
    "            )\n",
    "\n",
    "            # Run complete experiment\n",
    "            results = experiment.run_complete_experiment()\n",
    "\n",
    "            # Extract metrics and info for saving\n",
    "            metrics = {\n",
    "                \"accuracy\": results[\"accuracy\"],\n",
    "                \"auc_ovo\": results[\"auc_ovo\"],\n",
    "                \"gmean\": results[\"gmean\"],\n",
    "                \"cross_entropy\": results[\"cross_entropy\"],\n",
    "            }\n",
    "\n",
    "            dataset_info = {\n",
    "                \"n_samples_train\": results[\"n_samples_train\"],\n",
    "                \"n_samples_test\": results[\"n_samples_test\"],\n",
    "                \"n_features\": results[\"n_features\"],\n",
    "                \"n_classes\": results[\"n_classes\"],\n",
    "            }\n",
    "\n",
    "            timings = {\n",
    "                \"tuning_time\": results[\"tuning_time\"],\n",
    "                \"training_time\": results[\"training_time\"],\n",
    "                \"prediction_time\": results[\"prediction_time\"],\n",
    "                \"total_time\": results[\"total_time\"],\n",
    "            }\n",
    "\n",
    "            # Save results\n",
    "            results_manager.save_dataset_result(\n",
    "                dataset_name=dataset_name,\n",
    "                metrics=metrics,\n",
    "                dataset_info=dataset_info,\n",
    "                timings=timings,\n",
    "                hyperparameters=results[\"best_params\"],\n",
    "            )\n",
    "\n",
    "            print(f\"\\n✓ Completed {dataset_name} ({idx}/{len(pkl_files)})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ Failed: {dataset_name}\")\n",
    "            print(f\"   Error: {e}\")\n",
    "            failed_datasets.append((dataset_name, e))\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "    # ========================================================================\n",
    "    # Save final results\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SAVING FINAL RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Save metrics CSV (for hypothesis testing)\n",
    "    results_manager.save_metrics_csv()\n",
    "\n",
    "    # Print final summary\n",
    "    results_manager.print_summary()\n",
    "\n",
    "    # Print failed datasets if any\n",
    "    if failed_datasets:\n",
    "        print(f\"\\nFailed datasets ({len(failed_datasets)}):\")\n",
    "        for dataset, error in failed_datasets:\n",
    "            print(f\"  - {dataset}: {error}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXPERIMENT COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"✓ Total datasets: {len(pkl_files)}\")\n",
    "    print(f\"✓ Successful: {len(results_manager.all_results)}\")\n",
    "    print(f\"✓ Failed: {len(failed_datasets)}\")\n",
    "    print(f\"\\n✓ Metrics CSV saved: {RESULTS_DIR}/{MODEL_NAME}_metrics.csv\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae43085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TABULAR RESNET - EXPERIMENT PIPELINE\n",
      "================================================================================\n",
      "Model: resnet\n",
      "Seed: 123\n",
      "Optuna trials: 50\n",
      "CV folds: 10\n",
      "Results directory: ./results/resnet\n",
      "================================================================================\n",
      "\n",
      "✓ Found 30 processed datasets\n",
      "\n",
      "\n",
      "################################################################################\n",
      "DATASET 1/30: MiceProtein\n",
      "################################################################################\n",
      "Loading processed dataset from cache: MiceProtein\n",
      "Using device: cuda\n",
      "Dataset: MiceProtein\n",
      "  Train: (756, 77), Test: (324, 77)\n",
      "  Features: 77, Classes: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-26 23:32:05,557] A new study created in memory with name: no-name-7e345a0e-abda-401a-887f-2e2cd25ff4ea\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: MiceProtein\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-26 23:32:15,050] Trial 0 finished with value: 0.9750431563456203 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.9750431563456203.\n",
      "[I 2025-11-26 23:32:42,050] Trial 1 finished with value: 0.9905003006155368 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.9905003006155368.\n",
      "[I 2025-11-26 23:33:02,677] Trial 2 finished with value: 0.9975073196879075 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 2 with value: 0.9975073196879075.\n",
      "[I 2025-11-26 23:35:26,973] Trial 3 finished with value: 0.9975073196879075 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 2 with value: 0.9975073196879075.\n",
      "[I 2025-11-26 23:35:53,390] Trial 4 finished with value: 0.9929797495610773 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 2 with value: 0.9975073196879075.\n",
      "[I 2025-11-26 23:37:24,777] Trial 5 finished with value: 0.9948905759611077 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 2 with value: 0.9975073196879075.\n",
      "[I 2025-11-26 23:38:35,763] Trial 6 finished with value: 0.9931710007386432 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 2 with value: 0.9975073196879075.\n",
      "[I 2025-11-26 23:38:47,849] Trial 7 finished with value: 0.9783528186792456 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 2 with value: 0.9975073196879075.\n",
      "[I 2025-11-26 23:38:51,274] Trial 8 finished with value: 0.9931518788474717 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 2 with value: 0.9975073196879075.\n",
      "[I 2025-11-26 23:38:53,685] Trial 9 finished with value: 0.9909401292242273 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 2 with value: 0.9975073196879075.\n",
      "[I 2025-11-26 23:41:41,928] Trial 10 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.944801428233171, 'n_layers': 9, 'hidden_dropout': 0.11443328154761422, 'residual_dropout': 0.12302794125503497, 'learning_rate': 0.0006785909050951757, 'batch_size': 128, 'epochs': 161}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-26 23:43:59,642] Trial 11 finished with value: 0.9973832562732003 and parameters: {'d': 512, 'd_hidden_factor': 4.967022916984712, 'n_layers': 9, 'hidden_dropout': 0.12757833818886127, 'residual_dropout': 0.09528514564601334, 'learning_rate': 0.0006684846314917484, 'batch_size': 128, 'epochs': 162}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-26 23:46:27,282] Trial 12 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.597846650705766, 'n_layers': 8, 'hidden_dropout': 0.1319589788162011, 'residual_dropout': 0.17227089063336404, 'learning_rate': 0.0001215381536275238, 'batch_size': 128, 'epochs': 155}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-26 23:49:13,098] Trial 13 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.890354688453254, 'n_layers': 8, 'hidden_dropout': 0.06095633437616085, 'residual_dropout': 0.1602420245302461, 'learning_rate': 0.00010038584476789021, 'batch_size': 128, 'epochs': 158}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-26 23:50:55,641] Trial 14 finished with value: 0.9943532807562722 and parameters: {'d': 512, 'd_hidden_factor': 4.359125044316096, 'n_layers': 8, 'hidden_dropout': 0.10397330173081251, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 0.0009502063685218294, 'batch_size': 128, 'epochs': 158}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-26 23:53:43,866] Trial 15 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.457466110239647, 'n_layers': 8, 'hidden_dropout': 0.057078965867829956, 'residual_dropout': 0.21345780477371123, 'learning_rate': 7.705055411258324e-05, 'batch_size': 128, 'epochs': 182}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-26 23:56:43,527] Trial 16 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.469351754224358, 'n_layers': 10, 'hidden_dropout': 0.18557522109088526, 'residual_dropout': 0.2445047234664179, 'learning_rate': 1.0053994692390951e-05, 'batch_size': 128, 'epochs': 140}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-26 23:59:37,111] Trial 17 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.244990652305846, 'n_layers': 9, 'hidden_dropout': 0.006416368527065647, 'residual_dropout': 0.0625833213754776, 'learning_rate': 0.00041726781593231024, 'batch_size': 128, 'epochs': 177}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:01:48,487] Trial 18 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.921224956666418, 'n_layers': 7, 'hidden_dropout': 0.09929106461541574, 'residual_dropout': 0.17217051166898933, 'learning_rate': 4.86346650401307e-05, 'batch_size': 128, 'epochs': 143}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:02:15,355] Trial 19 finished with value: 0.9986916281366002 and parameters: {'d': 64, 'd_hidden_factor': 2.2965659692481744, 'n_layers': 9, 'hidden_dropout': 0.21817432365003742, 'residual_dropout': 0.12381387159336793, 'learning_rate': 0.0011981058947331945, 'batch_size': 256, 'epochs': 197}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:03:01,908] Trial 20 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 3.605676005367795, 'n_layers': 7, 'hidden_dropout': 0.4202138733708044, 'residual_dropout': 0.022534357225195784, 'learning_rate': 0.0005496885386482005, 'batch_size': 128, 'epochs': 114}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:05:29,948] Trial 21 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.742627915155533, 'n_layers': 8, 'hidden_dropout': 0.06091412594862551, 'residual_dropout': 0.1874149831587076, 'learning_rate': 0.00018615011033483667, 'batch_size': 128, 'epochs': 156}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:08:59,781] Trial 22 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.657695903117786, 'n_layers': 10, 'hidden_dropout': 0.05731797756905959, 'residual_dropout': 0.1329046925915503, 'learning_rate': 0.00011264271453454393, 'batch_size': 128, 'epochs': 173}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:10:48,475] Trial 23 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.073543869179744, 'n_layers': 7, 'hidden_dropout': 0.14838827402273658, 'residual_dropout': 0.2552121933312677, 'learning_rate': 5.984665273408916e-05, 'batch_size': 128, 'epochs': 145}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:13:33,990] Trial 24 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.913997529844387, 'n_layers': 8, 'hidden_dropout': 0.0821823710088693, 'residual_dropout': 0.20988215605402089, 'learning_rate': 0.0002520678483276403, 'batch_size': 128, 'epochs': 169}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:16:50,728] Trial 25 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.563331483016548, 'n_layers': 9, 'hidden_dropout': 0.030984036120915947, 'residual_dropout': 0.26808604711020423, 'learning_rate': 0.00012397920941646065, 'batch_size': 128, 'epochs': 188}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:17:55,138] Trial 26 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.22577438242815, 'n_layers': 4, 'hidden_dropout': 0.13791934968913017, 'residual_dropout': 0.11250311198193438, 'learning_rate': 2.025651097091268e-05, 'batch_size': 128, 'epochs': 133}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:17:59,545] Trial 27 finished with value: 0.9975073196879075 and parameters: {'d': 64, 'd_hidden_factor': 3.545850216757353, 'n_layers': 1, 'hidden_dropout': 0.18817890136768084, 'residual_dropout': 0.061489666344956326, 'learning_rate': 0.0019346091619869869, 'batch_size': 256, 'epochs': 115}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:21:27,279] Trial 28 finished with value: 0.9986916281366002 and parameters: {'d': 256, 'd_hidden_factor': 4.70420922782402, 'n_layers': 7, 'hidden_dropout': 0.10979935422149452, 'residual_dropout': 0.16217701831431586, 'learning_rate': 3.8215087453417845e-05, 'batch_size': 32, 'epochs': 153}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:22:26,825] Trial 29 finished with value: 0.9986916281366002 and parameters: {'d': 64, 'd_hidden_factor': 3.8120181848875667, 'n_layers': 9, 'hidden_dropout': 0.49234790898426983, 'residual_dropout': 0.21319874761731072, 'learning_rate': 0.00028344629944475255, 'batch_size': 128, 'epochs': 185}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:24:47,775] Trial 30 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.068319370204778, 'n_layers': 8, 'hidden_dropout': 0.03764873739067247, 'residual_dropout': 0.045855424143145904, 'learning_rate': 0.00035349627094410213, 'batch_size': 128, 'epochs': 167}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:27:44,814] Trial 31 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.4735411038765385, 'n_layers': 8, 'hidden_dropout': 0.07308771268652649, 'residual_dropout': 0.21859475541747636, 'learning_rate': 8.844767502585517e-05, 'batch_size': 128, 'epochs': 181}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:31:13,287] Trial 32 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.947910839609474, 'n_layers': 10, 'hidden_dropout': 0.03657987853844151, 'residual_dropout': 0.13605306729216704, 'learning_rate': 7.820650874180781e-05, 'batch_size': 128, 'epochs': 150}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:33:53,527] Trial 33 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.684377698747385, 'n_layers': 7, 'hidden_dropout': 0.16906641872266848, 'residual_dropout': 0.19373085932155626, 'learning_rate': 0.00017815534728066776, 'batch_size': 128, 'epochs': 190}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:34:16,523] Trial 34 finished with value: 0.9961989478245077 and parameters: {'d': 128, 'd_hidden_factor': 4.408236758311578, 'n_layers': 5, 'hidden_dropout': 0.21823956672976125, 'residual_dropout': 0.2776990718590704, 'learning_rate': 6.727561199911184e-05, 'batch_size': 64, 'epochs': 54}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:36:33,045] Trial 35 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.076222997318344, 'n_layers': 8, 'hidden_dropout': 0.1136122077343977, 'residual_dropout': 0.14070764382746315, 'learning_rate': 0.00015604795237799505, 'batch_size': 128, 'epochs': 166}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:38:12,486] Trial 36 finished with value: 0.9986916281366002 and parameters: {'d': 256, 'd_hidden_factor': 2.619288141291488, 'n_layers': 9, 'hidden_dropout': 0.0831391631978137, 'residual_dropout': 0.2944228317931578, 'learning_rate': 4.036926085211792e-05, 'batch_size': 64, 'epochs': 133}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:39:04,565] Trial 37 finished with value: 0.9972492472466072 and parameters: {'d': 128, 'd_hidden_factor': 4.785579839347392, 'n_layers': 5, 'hidden_dropout': 0.046880948930641014, 'residual_dropout': 0.2377103635272492, 'learning_rate': 0.0006764750197748614, 'batch_size': 32, 'epochs': 176}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:40:44,349] Trial 38 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 3.1213649892254045, 'n_layers': 10, 'hidden_dropout': 0.24481945607645073, 'residual_dropout': 0.08905326132186808, 'learning_rate': 1.7978949120866522e-05, 'batch_size': 128, 'epochs': 106}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:43:01,188] Trial 39 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 3.393487380267861, 'n_layers': 6, 'hidden_dropout': 0.1336909710810073, 'residual_dropout': 0.3769926764838665, 'learning_rate': 3.247410309229802e-05, 'batch_size': 32, 'epochs': 70}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:43:20,606] Trial 40 finished with value: 0.9886417212078153 and parameters: {'d': 64, 'd_hidden_factor': 1.6463877357855388, 'n_layers': 7, 'hidden_dropout': 0.014729555128336666, 'residual_dropout': 0.16377541235949242, 'learning_rate': 0.0019147857152667994, 'batch_size': 64, 'epochs': 37}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:46:20,580] Trial 41 finished with value: 0.9973832562732003 and parameters: {'d': 512, 'd_hidden_factor': 4.504358412010406, 'n_layers': 10, 'hidden_dropout': 0.17323029958417363, 'residual_dropout': 0.2293415320629726, 'learning_rate': 1.3242512923619966e-05, 'batch_size': 128, 'epochs': 141}. Best is trial 10 with value: 0.9986916281366002.\n",
      "[I 2025-11-27 00:49:09,605] Trial 42 finished with value: 1.0 and parameters: {'d': 512, 'd_hidden_factor': 4.323646972058734, 'n_layers': 10, 'hidden_dropout': 0.1778976046973269, 'residual_dropout': 0.18698998490625918, 'learning_rate': 1.1452211301313298e-05, 'batch_size': 128, 'epochs': 136}. Best is trial 42 with value: 1.0.\n",
      "[I 2025-11-27 00:51:48,853] Trial 43 finished with value: 1.0 and parameters: {'d': 512, 'd_hidden_factor': 4.99738745528689, 'n_layers': 9, 'hidden_dropout': 0.2022563087418586, 'residual_dropout': 0.18380284731658444, 'learning_rate': 0.00023160524223932492, 'batch_size': 128, 'epochs': 133}. Best is trial 42 with value: 1.0.\n",
      "[I 2025-11-27 00:52:41,348] Trial 44 finished with value: 0.9986916281366002 and parameters: {'d': 256, 'd_hidden_factor': 4.838661278000459, 'n_layers': 9, 'hidden_dropout': 0.2530755354102838, 'residual_dropout': 0.10435942394255435, 'learning_rate': 0.00023972738201678544, 'batch_size': 128, 'epochs': 123}. Best is trial 42 with value: 1.0.\n",
      "[I 2025-11-27 00:53:03,328] Trial 45 finished with value: 0.9986916281366002 and parameters: {'d': 128, 'd_hidden_factor': 4.2614823526437515, 'n_layers': 10, 'hidden_dropout': 0.2108066650175741, 'residual_dropout': 0.18489625977220323, 'learning_rate': 0.0004444209503765104, 'batch_size': 256, 'epochs': 132}. Best is trial 42 with value: 1.0.\n",
      "[I 2025-11-27 00:54:06,714] Trial 46 finished with value: 0.9853580535237603 and parameters: {'d': 512, 'd_hidden_factor': 4.953928987985536, 'n_layers': 9, 'hidden_dropout': 0.3670046893359715, 'residual_dropout': 0.14937011867824074, 'learning_rate': 0.0008557163383559548, 'batch_size': 128, 'epochs': 150}. Best is trial 42 with value: 1.0.\n",
      "[I 2025-11-27 00:57:18,260] Trial 47 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 4.602212520319641, 'n_layers': 10, 'hidden_dropout': 0.2823052575291699, 'residual_dropout': 0.18928223034236974, 'learning_rate': 0.0001288456376611863, 'batch_size': 128, 'epochs': 160}. Best is trial 42 with value: 1.0.\n",
      "[I 2025-11-27 00:59:12,959] Trial 48 finished with value: 0.9986916281366002 and parameters: {'d': 512, 'd_hidden_factor': 3.8767236395018982, 'n_layers': 9, 'hidden_dropout': 0.18647182566022158, 'residual_dropout': 0.11908836802741322, 'learning_rate': 2.6493052232638582e-05, 'batch_size': 128, 'epochs': 118}. Best is trial 42 with value: 1.0.\n",
      "[I 2025-11-27 01:01:19,634] Trial 49 finished with value: 0.9973832562732003 and parameters: {'d': 512, 'd_hidden_factor': 4.995163900090759, 'n_layers': 8, 'hidden_dropout': 0.15047756952466496, 'residual_dropout': 0.07585297243740088, 'learning_rate': 0.0004971039221961259, 'batch_size': 128, 'epochs': 135}. Best is trial 42 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 5354.08s\n",
      "  Best CV G-Mean: 1.0000\n",
      "  Best parameters:\n",
      "    d: 512\n",
      "    d_hidden_factor: 4.323646972058734\n",
      "    n_layers: 10\n",
      "    hidden_dropout: 0.1778976046973269\n",
      "    residual_dropout: 0.18698998490625918\n",
      "    learning_rate: 1.1452211301313298e-05\n",
      "    batch_size: 128\n",
      "    epochs: 136\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/136: Train Loss = 0.7731, Val Loss = 0.7337\n",
      "    Epoch 20/136: Train Loss = 0.3239, Val Loss = 0.3143\n",
      "    Epoch 30/136: Train Loss = 0.1632, Val Loss = 0.1508\n",
      "    Epoch 40/136: Train Loss = 0.0960, Val Loss = 0.0822\n",
      "    Epoch 50/136: Train Loss = 0.0665, Val Loss = 0.0534\n",
      "    Epoch 60/136: Train Loss = 0.0503, Val Loss = 0.0402\n",
      "    Epoch 70/136: Train Loss = 0.0368, Val Loss = 0.0317\n",
      "    Epoch 80/136: Train Loss = 0.0343, Val Loss = 0.0249\n",
      "    Epoch 90/136: Train Loss = 0.0285, Val Loss = 0.0219\n",
      "    Epoch 100/136: Train Loss = 0.0223, Val Loss = 0.0182\n",
      "    Epoch 110/136: Train Loss = 0.0204, Val Loss = 0.0163\n",
      "    Epoch 120/136: Train Loss = 0.0187, Val Loss = 0.0147\n",
      "    Epoch 130/136: Train Loss = 0.0185, Val Loss = 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 01:01:36,525] A new study created in memory with name: no-name-a6a6120b-7c8a-420d-bbf8-1ff834739cb6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training complete! Time: 16.84s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR MiceProtein\n",
      "================================================================================\n",
      "Accuracy:        1.0000\n",
      "AUC OVO:         1.0000\n",
      "G-Mean:          1.0000\n",
      "Cross-Entropy:   0.0151\n",
      "================================================================================\n",
      "✓ Saved results for MiceProtein\n",
      "\n",
      "✓ Completed MiceProtein (1/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 2/30: diabetes\n",
      "################################################################################\n",
      "Loading processed dataset from cache: diabetes\n",
      "Using device: cuda\n",
      "Dataset: diabetes\n",
      "  Train: (537, 8), Test: (231, 8)\n",
      "  Features: 8, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: diabetes\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 01:01:41,542] Trial 0 finished with value: 0.6943502108945224 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.6943502108945224.\n",
      "[I 2025-11-27 01:01:49,460] Trial 1 finished with value: 0.6947273251170855 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.6947273251170855.\n",
      "[I 2025-11-27 01:01:57,507] Trial 2 finished with value: 0.6695510939875335 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 1 with value: 0.6947273251170855.\n",
      "[I 2025-11-27 01:02:40,286] Trial 3 finished with value: 0.6904593730929138 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 1 with value: 0.6947273251170855.\n",
      "[I 2025-11-27 01:02:52,017] Trial 4 finished with value: 0.6967989681540777 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 4 with value: 0.6967989681540777.\n",
      "[I 2025-11-27 01:03:33,986] Trial 5 finished with value: 0.6840371693309347 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 4 with value: 0.6967989681540777.\n",
      "[I 2025-11-27 01:04:09,269] Trial 6 finished with value: 0.6988670785951063 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 6 with value: 0.6988670785951063.\n",
      "[I 2025-11-27 01:04:13,779] Trial 7 finished with value: 0.6653840488915079 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 6 with value: 0.6988670785951063.\n",
      "[I 2025-11-27 01:04:15,692] Trial 8 finished with value: 0.6967597972577126 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 6 with value: 0.6988670785951063.\n",
      "[I 2025-11-27 01:04:17,187] Trial 9 finished with value: 0.6922491524498264 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 6 with value: 0.6988670785951063.\n",
      "[I 2025-11-27 01:04:59,735] Trial 10 finished with value: 0.689576215775394 and parameters: {'d': 64, 'd_hidden_factor': 4.898911825744538, 'n_layers': 9, 'hidden_dropout': 0.45987165508765876, 'residual_dropout': 0.1934998040501344, 'learning_rate': 8.436023359535897e-05, 'batch_size': 32, 'epochs': 161}. Best is trial 6 with value: 0.6988670785951063.\n",
      "[I 2025-11-27 01:05:03,373] Trial 11 finished with value: 0.6667394832525411 and parameters: {'d': 256, 'd_hidden_factor': 2.019839569141026, 'n_layers': 4, 'hidden_dropout': 0.3761275059380934, 'residual_dropout': 0.4961689423400903, 'learning_rate': 0.0009031472349418137, 'batch_size': 128, 'epochs': 131}. Best is trial 6 with value: 0.6988670785951063.\n",
      "[I 2025-11-27 01:05:15,299] Trial 12 finished with value: 0.70020030964934 and parameters: {'d': 64, 'd_hidden_factor': 2.1444073493643163, 'n_layers': 8, 'hidden_dropout': 0.39666925881190335, 'residual_dropout': 0.24448556576035885, 'learning_rate': 0.0009332839245769886, 'batch_size': 64, 'epochs': 150}. Best is trial 12 with value: 0.70020030964934.\n",
      "[I 2025-11-27 01:06:05,240] Trial 13 finished with value: 0.6922854895134263 and parameters: {'d': 64, 'd_hidden_factor': 2.0171397522110226, 'n_layers': 8, 'hidden_dropout': 0.40068056585205547, 'residual_dropout': 0.20146483846329177, 'learning_rate': 8.278805751694198e-05, 'batch_size': 32, 'epochs': 163}. Best is trial 12 with value: 0.70020030964934.\n",
      "[I 2025-11-27 01:06:16,540] Trial 14 finished with value: 0.6900212327662439 and parameters: {'d': 64, 'd_hidden_factor': 2.211957797853664, 'n_layers': 8, 'hidden_dropout': 0.4043927526374541, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 0.0004990030195863083, 'batch_size': 64, 'epochs': 155}. Best is trial 12 with value: 0.70020030964934.\n",
      "[I 2025-11-27 01:06:34,433] Trial 15 finished with value: 0.6847637590292635 and parameters: {'d': 64, 'd_hidden_factor': 1.6433292554052423, 'n_layers': 3, 'hidden_dropout': 0.15532850199011827, 'residual_dropout': 0.2588050814785194, 'learning_rate': 0.00011901487645989611, 'batch_size': 32, 'epochs': 179}. Best is trial 12 with value: 0.70020030964934.\n",
      "[I 2025-11-27 01:06:37,770] Trial 16 finished with value: 0.7049034375536546 and parameters: {'d': 512, 'd_hidden_factor': 2.4539209232214865, 'n_layers': 1, 'hidden_dropout': 0.3606332539830651, 'residual_dropout': 0.12312182169098496, 'learning_rate': 1.0007425109373897e-05, 'batch_size': 256, 'epochs': 104}. Best is trial 16 with value: 0.7049034375536546.\n",
      "[I 2025-11-27 01:06:53,614] Trial 17 finished with value: 0.7057863347471925 and parameters: {'d': 512, 'd_hidden_factor': 2.576607494755636, 'n_layers': 8, 'hidden_dropout': 0.4349341665190769, 'residual_dropout': 0.10483325497192575, 'learning_rate': 1.1016598219611525e-05, 'batch_size': 256, 'epochs': 142}. Best is trial 17 with value: 0.7057863347471925.\n",
      "[I 2025-11-27 01:06:57,049] Trial 18 finished with value: 0.7102438682828174 and parameters: {'d': 512, 'd_hidden_factor': 2.6900180359045995, 'n_layers': 1, 'hidden_dropout': 0.444362215287023, 'residual_dropout': 0.09338844173954158, 'learning_rate': 1.302700173515893e-05, 'batch_size': 256, 'epochs': 108}. Best is trial 18 with value: 0.7102438682828174.\n",
      "[I 2025-11-27 01:07:15,734] Trial 19 finished with value: 0.6981583063965793 and parameters: {'d': 512, 'd_hidden_factor': 4.346141356882734, 'n_layers': 7, 'hidden_dropout': 0.45054015264472896, 'residual_dropout': 0.04289862369534672, 'learning_rate': 1.0094165165701898e-05, 'batch_size': 256, 'epochs': 135}. Best is trial 18 with value: 0.7102438682828174.\n",
      "[I 2025-11-27 01:07:27,348] Trial 20 finished with value: 0.7017970741512694 and parameters: {'d': 512, 'd_hidden_factor': 2.707583550979246, 'n_layers': 10, 'hidden_dropout': 0.48590622669359035, 'residual_dropout': 0.10426691307577787, 'learning_rate': 3.414949267759356e-05, 'batch_size': 256, 'epochs': 64}. Best is trial 18 with value: 0.7102438682828174.\n",
      "[I 2025-11-27 01:07:30,716] Trial 21 finished with value: 0.7112037721711566 and parameters: {'d': 512, 'd_hidden_factor': 2.5984901761389696, 'n_layers': 1, 'hidden_dropout': 0.44268097432712944, 'residual_dropout': 0.12368525054279957, 'learning_rate': 1.0056169440523014e-05, 'batch_size': 256, 'epochs': 104}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:07:34,348] Trial 22 finished with value: 0.708944937506143 and parameters: {'d': 512, 'd_hidden_factor': 3.368957843029958, 'n_layers': 1, 'hidden_dropout': 0.43546174202757176, 'residual_dropout': 0.052108310204420916, 'learning_rate': 1.5743524475489675e-05, 'batch_size': 256, 'epochs': 113}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:07:37,592] Trial 23 finished with value: 0.7101454430942515 and parameters: {'d': 512, 'd_hidden_factor': 3.385457000058781, 'n_layers': 1, 'hidden_dropout': 0.43669093104482287, 'residual_dropout': 0.03900472331835175, 'learning_rate': 2.0916629198888118e-05, 'batch_size': 256, 'epochs': 112}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:07:40,952] Trial 24 finished with value: 0.6874678017081034 and parameters: {'d': 512, 'd_hidden_factor': 3.4970408931204413, 'n_layers': 2, 'hidden_dropout': 0.4965075902309658, 'residual_dropout': 0.011607109046457426, 'learning_rate': 4.794216339280623e-05, 'batch_size': 256, 'epochs': 78}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:07:44,087] Trial 25 finished with value: 0.7102836236316393 and parameters: {'d': 512, 'd_hidden_factor': 3.011384735072696, 'n_layers': 1, 'hidden_dropout': 0.013690289438714642, 'residual_dropout': 0.15003844079586273, 'learning_rate': 1.9437514284800185e-05, 'batch_size': 256, 'epochs': 111}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:07:47,684] Trial 26 finished with value: 0.6569197681295365 and parameters: {'d': 512, 'd_hidden_factor': 2.993098980002957, 'n_layers': 3, 'hidden_dropout': 0.0878035890378024, 'residual_dropout': 0.14444706739347185, 'learning_rate': 4.941612606593856e-05, 'batch_size': 256, 'epochs': 115}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:07:53,743] Trial 27 finished with value: 0.6881894412287416 and parameters: {'d': 512, 'd_hidden_factor': 1.7363057633874623, 'n_layers': 3, 'hidden_dropout': 0.030988986895839236, 'residual_dropout': 0.19535392567306292, 'learning_rate': 1.6220374238135538e-05, 'batch_size': 128, 'epochs': 86}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:07:55,603] Trial 28 finished with value: 0.702397518173892 and parameters: {'d': 512, 'd_hidden_factor': 2.948321917443241, 'n_layers': 1, 'hidden_dropout': 0.21412085552860408, 'residual_dropout': 0.16402002225933765, 'learning_rate': 4.319247297474127e-05, 'batch_size': 256, 'epochs': 63}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:07:58,980] Trial 29 finished with value: 0.6599819894917557 and parameters: {'d': 512, 'd_hidden_factor': 3.9750951242246337, 'n_layers': 2, 'hidden_dropout': 0.08686812442984673, 'residual_dropout': 0.23639482994020314, 'learning_rate': 0.00021831105188906412, 'batch_size': 128, 'epochs': 37}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:08:05,411] Trial 30 finished with value: 0.706278725584722 and parameters: {'d': 512, 'd_hidden_factor': 2.4390094311394477, 'n_layers': 4, 'hidden_dropout': 0.13484906765649013, 'residual_dropout': 0.07228090040443136, 'learning_rate': 1.7334264340903652e-05, 'batch_size': 256, 'epochs': 108}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:08:08,763] Trial 31 finished with value: 0.7096039793146893 and parameters: {'d': 512, 'd_hidden_factor': 3.113873353678901, 'n_layers': 1, 'hidden_dropout': 0.4722298293183203, 'residual_dropout': 0.038481529339653875, 'learning_rate': 2.255433459655457e-05, 'batch_size': 256, 'epochs': 117}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:08:12,580] Trial 32 finished with value: 0.6951287704652045 and parameters: {'d': 512, 'd_hidden_factor': 4.271303213440863, 'n_layers': 1, 'hidden_dropout': 0.33068237116321086, 'residual_dropout': 0.09184177505122976, 'learning_rate': 1.745168353067137e-05, 'batch_size': 256, 'epochs': 106}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:08:15,686] Trial 33 finished with value: 0.6674870828970957 and parameters: {'d': 512, 'd_hidden_factor': 3.6297142104875397, 'n_layers': 2, 'hidden_dropout': 0.4220123524613947, 'residual_dropout': 0.135235602136221, 'learning_rate': 6.27004179740672e-05, 'batch_size': 256, 'epochs': 98}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:08:17,643] Trial 34 finished with value: 0.6977606853922347 and parameters: {'d': 512, 'd_hidden_factor': 3.2661287394243756, 'n_layers': 1, 'hidden_dropout': 0.19749657503911655, 'residual_dropout': 0.172017937534243, 'learning_rate': 2.8530019570054073e-05, 'batch_size': 256, 'epochs': 54}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:08:19,960] Trial 35 finished with value: 0.6460306511329319 and parameters: {'d': 128, 'd_hidden_factor': 2.757243940809726, 'n_layers': 3, 'hidden_dropout': 0.24064068725378548, 'residual_dropout': 0.06613512428009391, 'learning_rate': 1.414984824444813e-05, 'batch_size': 256, 'epochs': 75}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:08:24,193] Trial 36 finished with value: 0.7042368834025156 and parameters: {'d': 512, 'd_hidden_factor': 2.7669515274819148, 'n_layers': 2, 'hidden_dropout': 0.376756810514871, 'residual_dropout': 0.02292470631161575, 'learning_rate': 2.3539308888506694e-05, 'batch_size': 256, 'epochs': 125}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:08:25,757] Trial 37 finished with value: 0.6730466468524794 and parameters: {'d': 256, 'd_hidden_factor': 3.147521403894849, 'n_layers': 1, 'hidden_dropout': 0.3310568644947192, 'residual_dropout': 0.1174120754300263, 'learning_rate': 0.00037709689807434405, 'batch_size': 128, 'epochs': 140}. Best is trial 21 with value: 0.7112037721711566.\n",
      "[I 2025-11-27 01:08:30,069] Trial 38 finished with value: 0.71320586473703 and parameters: {'d': 128, 'd_hidden_factor': 3.6620029187509937, 'n_layers': 5, 'hidden_dropout': 0.2798976769448624, 'residual_dropout': 0.0848636985822783, 'learning_rate': 3.645405811873006e-05, 'batch_size': 256, 'epochs': 89}. Best is trial 38 with value: 0.71320586473703.\n",
      "[I 2025-11-27 01:08:34,791] Trial 39 finished with value: 0.708009057239314 and parameters: {'d': 128, 'd_hidden_factor': 3.7340957318225456, 'n_layers': 5, 'hidden_dropout': 0.2852038562351172, 'residual_dropout': 0.2902678242723033, 'learning_rate': 3.981938490636792e-05, 'batch_size': 256, 'epochs': 91}. Best is trial 38 with value: 0.71320586473703.\n",
      "[I 2025-11-27 01:08:46,869] Trial 40 finished with value: 0.6990554208271548 and parameters: {'d': 128, 'd_hidden_factor': 4.142130391617606, 'n_layers': 5, 'hidden_dropout': 0.24637054332818212, 'residual_dropout': 0.21941658447698548, 'learning_rate': 2.886777852552378e-05, 'batch_size': 64, 'epochs': 48}. Best is trial 38 with value: 0.71320586473703.\n",
      "[I 2025-11-27 01:08:50,019] Trial 41 finished with value: 0.7250481434395752 and parameters: {'d': 128, 'd_hidden_factor': 3.468335578150428, 'n_layers': 2, 'hidden_dropout': 0.4995948185903601, 'residual_dropout': 0.08493823160359984, 'learning_rate': 2.1687768236505902e-05, 'batch_size': 256, 'epochs': 101}. Best is trial 41 with value: 0.7250481434395752.\n",
      "[I 2025-11-27 01:08:52,613] Trial 42 finished with value: 0.5663774344059792 and parameters: {'d': 128, 'd_hidden_factor': 2.8767817945512273, 'n_layers': 2, 'hidden_dropout': 0.4660839427538971, 'residual_dropout': 0.08869108492425354, 'learning_rate': 1.318209914921663e-05, 'batch_size': 256, 'epochs': 99}. Best is trial 41 with value: 0.7250481434395752.\n",
      "[I 2025-11-27 01:08:55,749] Trial 43 finished with value: 0.708223791697006 and parameters: {'d': 128, 'd_hidden_factor': 3.528420366524372, 'n_layers': 3, 'hidden_dropout': 0.49432941102212613, 'residual_dropout': 0.15117140794289488, 'learning_rate': 6.588912523840945e-05, 'batch_size': 256, 'epochs': 83}. Best is trial 41 with value: 0.7250481434395752.\n",
      "[I 2025-11-27 01:08:58,123] Trial 44 finished with value: 0.6847471860459289 and parameters: {'d': 128, 'd_hidden_factor': 3.140228754756011, 'n_layers': 4, 'hidden_dropout': 0.08311010078692482, 'residual_dropout': 0.07218840480781655, 'learning_rate': 0.00011740378508062594, 'batch_size': 256, 'epochs': 120}. Best is trial 41 with value: 0.7250481434395752.\n",
      "[I 2025-11-27 01:09:03,544] Trial 45 finished with value: 0.6958785261431404 and parameters: {'d': 128, 'd_hidden_factor': 3.765077506563605, 'n_layers': 7, 'hidden_dropout': 0.047698976974117735, 'residual_dropout': 0.11780754359310086, 'learning_rate': 2.8711969826146393e-05, 'batch_size': 256, 'epochs': 91}. Best is trial 41 with value: 0.7250481434395752.\n",
      "[I 2025-11-27 01:09:27,789] Trial 46 finished with value: 0.708914834419609 and parameters: {'d': 128, 'd_hidden_factor': 2.473032196593007, 'n_layers': 2, 'hidden_dropout': 0.41585504667810436, 'residual_dropout': 0.17610023244773984, 'learning_rate': 1.3593551213774745e-05, 'batch_size': 32, 'epochs': 72}. Best is trial 41 with value: 0.7250481434395752.\n",
      "[I 2025-11-27 01:09:30,309] Trial 47 finished with value: 0.7171692663384623 and parameters: {'d': 256, 'd_hidden_factor': 4.519711413591084, 'n_layers': 1, 'hidden_dropout': 0.3796107796967203, 'residual_dropout': 0.37949087807772763, 'learning_rate': 2.0613722308919772e-05, 'batch_size': 256, 'epochs': 105}. Best is trial 41 with value: 0.7250481434395752.\n",
      "[I 2025-11-27 01:09:34,591] Trial 48 finished with value: 0.6731838666571385 and parameters: {'d': 256, 'd_hidden_factor': 4.6781750387041345, 'n_layers': 2, 'hidden_dropout': 0.3786274867404375, 'residual_dropout': 0.38462517942590624, 'learning_rate': 0.00017208872703546437, 'batch_size': 64, 'epochs': 101}. Best is trial 41 with value: 0.7250481434395752.\n",
      "[I 2025-11-27 01:09:41,834] Trial 49 finished with value: 0.6982618052593261 and parameters: {'d': 256, 'd_hidden_factor': 4.804468291379611, 'n_layers': 3, 'hidden_dropout': 0.2716619227350397, 'residual_dropout': 0.3710206512900029, 'learning_rate': 2.180499001967281e-05, 'batch_size': 128, 'epochs': 93}. Best is trial 41 with value: 0.7250481434395752.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 485.31s\n",
      "  Best CV G-Mean: 0.7250\n",
      "  Best parameters:\n",
      "    d: 128\n",
      "    d_hidden_factor: 3.468335578150428\n",
      "    n_layers: 2\n",
      "    hidden_dropout: 0.4995948185903601\n",
      "    residual_dropout: 0.08493823160359984\n",
      "    learning_rate: 2.1687768236505902e-05\n",
      "    batch_size: 256\n",
      "    epochs: 101\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/101: Train Loss = 0.7352, Val Loss = 0.7777\n",
      "    Epoch 20/101: Train Loss = 0.7109, Val Loss = 0.7443\n",
      "    Epoch 30/101: Train Loss = 0.6350, Val Loss = 0.7065\n",
      "    Epoch 40/101: Train Loss = 0.6399, Val Loss = 0.6736\n",
      "    Epoch 50/101: Train Loss = 0.6046, Val Loss = 0.6448\n",
      "    Epoch 60/101: Train Loss = 0.5927, Val Loss = 0.6208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 01:09:42,157] A new study created in memory with name: no-name-a5ca5606-e3b3-4804-92db-813b7e0a091a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 70/101: Train Loss = 0.5587, Val Loss = 0.6010\n",
      "    Epoch 80/101: Train Loss = 0.5889, Val Loss = 0.5824\n",
      "    Epoch 90/101: Train Loss = 0.5505, Val Loss = 0.5701\n",
      "    Epoch 100/101: Train Loss = 0.5293, Val Loss = 0.5570\n",
      "✓ Training complete! Time: 0.32s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR diabetes\n",
      "================================================================================\n",
      "Accuracy:        0.7835\n",
      "AUC OVO:         0.8741\n",
      "G-Mean:          0.6932\n",
      "Cross-Entropy:   0.5058\n",
      "================================================================================\n",
      "✓ Saved results for diabetes\n",
      "\n",
      "✓ Completed diabetes (2/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 3/30: pc1\n",
      "################################################################################\n",
      "Loading processed dataset from cache: pc1\n",
      "Using device: cuda\n",
      "Dataset: pc1\n",
      "  Train: (776, 21), Test: (333, 21)\n",
      "  Features: 21, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: pc1\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 01:09:50,823] Trial 0 finished with value: 0.41992670118414444 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.41992670118414444.\n",
      "[I 2025-11-27 01:10:04,427] Trial 1 finished with value: 0.5027697944050372 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.5027697944050372.\n",
      "[I 2025-11-27 01:10:23,058] Trial 2 finished with value: 0.3800912914840032 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 1 with value: 0.5027697944050372.\n",
      "[I 2025-11-27 01:12:38,246] Trial 3 finished with value: 0.4314481664117591 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 1 with value: 0.5027697944050372.\n",
      "[I 2025-11-27 01:12:57,196] Trial 4 finished with value: 0.38675695868852006 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 1 with value: 0.5027697944050372.\n",
      "[I 2025-11-27 01:14:30,055] Trial 5 finished with value: 0.4404966789422636 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 1 with value: 0.5027697944050372.\n",
      "[I 2025-11-27 01:15:39,984] Trial 6 finished with value: 0.3998746856395962 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 1 with value: 0.5027697944050372.\n",
      "[I 2025-11-27 01:15:47,174] Trial 7 finished with value: 0.5629671536785099 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 7 with value: 0.5629671536785099.\n",
      "[I 2025-11-27 01:15:50,634] Trial 8 finished with value: 0.41275759480556823 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 7 with value: 0.5629671536785099.\n",
      "[I 2025-11-27 01:15:53,470] Trial 9 finished with value: 0.5498734199586618 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 7 with value: 0.5629671536785099.\n",
      "[I 2025-11-27 01:15:57,682] Trial 10 finished with value: 0.4858550370955448 and parameters: {'d': 512, 'd_hidden_factor': 4.869886258753025, 'n_layers': 1, 'hidden_dropout': 0.10467358725545478, 'residual_dropout': 0.20327186961400082, 'learning_rate': 0.001484521852630656, 'batch_size': 128, 'epochs': 161}. Best is trial 7 with value: 0.5629671536785099.\n",
      "[I 2025-11-27 01:15:59,853] Trial 11 finished with value: 0.5974503462221279 and parameters: {'d': 512, 'd_hidden_factor': 1.031954150873541, 'n_layers': 2, 'hidden_dropout': 0.1785973443419468, 'residual_dropout': 0.3654658770144939, 'learning_rate': 0.00888036766804695, 'batch_size': 256, 'epochs': 131}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:16:02,821] Trial 12 finished with value: 0.44583378559589104 and parameters: {'d': 512, 'd_hidden_factor': 1.0658503514830249, 'n_layers': 3, 'hidden_dropout': 0.14694989989807747, 'residual_dropout': 0.26284575268879906, 'learning_rate': 0.0016179440919177456, 'batch_size': 256, 'epochs': 150}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:16:04,515] Trial 13 finished with value: 0.5333733976522266 and parameters: {'d': 512, 'd_hidden_factor': 1.7897617711971638, 'n_layers': 1, 'hidden_dropout': 0.1282492931447887, 'residual_dropout': 0.39413953355958786, 'learning_rate': 0.003278104381018684, 'batch_size': 256, 'epochs': 150}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:16:19,604] Trial 14 finished with value: 0.409030057239853 and parameters: {'d': 512, 'd_hidden_factor': 1.6598531174077575, 'n_layers': 3, 'hidden_dropout': 0.043005317434201135, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 0.0098013840231289, 'batch_size': 64, 'epochs': 178}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:16:23,232] Trial 15 finished with value: 0.4543267300372582 and parameters: {'d': 512, 'd_hidden_factor': 1.6509259250621737, 'n_layers': 3, 'hidden_dropout': 0.19817203462288857, 'residual_dropout': 0.2571172051415348, 'learning_rate': 0.0006178590691416533, 'batch_size': 256, 'epochs': 118}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:16:50,583] Trial 16 finished with value: 0.5067256794972416 and parameters: {'d': 512, 'd_hidden_factor': 2.2281766868677337, 'n_layers': 8, 'hidden_dropout': 0.1855609311927803, 'residual_dropout': 0.37496612117779893, 'learning_rate': 0.0006960164587986635, 'batch_size': 64, 'epochs': 59}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:16:59,718] Trial 17 finished with value: 0.31588153760587356 and parameters: {'d': 512, 'd_hidden_factor': 1.3621375344534348, 'n_layers': 2, 'hidden_dropout': 0.07436726243220565, 'residual_dropout': 0.193885320471026, 'learning_rate': 5.941072156885347e-05, 'batch_size': 128, 'epochs': 97}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:17:05,009] Trial 18 finished with value: 0.5326921392168968 and parameters: {'d': 512, 'd_hidden_factor': 2.387817421476856, 'n_layers': 1, 'hidden_dropout': 0.39607301245918625, 'residual_dropout': 0.28119696308303177, 'learning_rate': 0.0006248578598342765, 'batch_size': 64, 'epochs': 137}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:17:10,531] Trial 19 finished with value: 0.4044800715530048 and parameters: {'d': 64, 'd_hidden_factor': 1.9247082136744789, 'n_layers': 8, 'hidden_dropout': 0.16557420190168845, 'residual_dropout': 0.43051153032514683, 'learning_rate': 1.0094165165701898e-05, 'batch_size': 256, 'epochs': 77}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:17:26,991] Trial 20 finished with value: 0.581037126109016 and parameters: {'d': 512, 'd_hidden_factor': 1.3054641795299686, 'n_layers': 4, 'hidden_dropout': 0.22736230678925728, 'residual_dropout': 0.204596752764495, 'learning_rate': 0.003922968241286064, 'batch_size': 64, 'epochs': 106}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:17:42,437] Trial 21 finished with value: 0.42549789798605975 and parameters: {'d': 512, 'd_hidden_factor': 1.3505452749149325, 'n_layers': 4, 'hidden_dropout': 0.23501414906562246, 'residual_dropout': 0.12627967482541752, 'learning_rate': 0.003964861516273969, 'batch_size': 64, 'epochs': 109}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:17:50,525] Trial 22 finished with value: 0.48808961547028973 and parameters: {'d': 512, 'd_hidden_factor': 1.0326628343681699, 'n_layers': 2, 'hidden_dropout': 0.09941796322438717, 'residual_dropout': 0.21724988356414807, 'learning_rate': 0.006157586407135778, 'batch_size': 64, 'epochs': 106}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:18:02,548] Trial 23 finished with value: 0.5154315938349893 and parameters: {'d': 512, 'd_hidden_factor': 1.409378102462975, 'n_layers': 4, 'hidden_dropout': 0.22477157556674085, 'residual_dropout': 0.3146251291273621, 'learning_rate': 0.0021300698901821906, 'batch_size': 64, 'epochs': 85}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:18:09,565] Trial 24 finished with value: 0.5513251223411879 and parameters: {'d': 512, 'd_hidden_factor': 1.878439010416609, 'n_layers': 2, 'hidden_dropout': 0.14675716556303214, 'residual_dropout': 0.3719391751199196, 'learning_rate': 0.0009128101857698403, 'batch_size': 64, 'epochs': 131}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:18:14,263] Trial 25 finished with value: 0.46178281023554535 and parameters: {'d': 512, 'd_hidden_factor': 1.445023114555651, 'n_layers': 3, 'hidden_dropout': 0.3771233972286031, 'residual_dropout': 0.22518413519933517, 'learning_rate': 0.006709224182251413, 'batch_size': 256, 'epochs': 143}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:18:31,775] Trial 26 finished with value: 0.4279968052081708 and parameters: {'d': 512, 'd_hidden_factor': 4.8989854589842645, 'n_layers': 4, 'hidden_dropout': 0.18330577226133365, 'residual_dropout': 0.1673978473710499, 'learning_rate': 0.0024548561980775757, 'batch_size': 128, 'epochs': 166}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:18:41,425] Trial 27 finished with value: 0.3322611937417864 and parameters: {'d': 64, 'd_hidden_factor': 2.4941673578103343, 'n_layers': 1, 'hidden_dropout': 0.057180166658926695, 'residual_dropout': 0.09255802491109617, 'learning_rate': 0.005066470438448056, 'batch_size': 32, 'epochs': 67}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:18:47,428] Trial 28 finished with value: 0.4736665587935807 and parameters: {'d': 256, 'd_hidden_factor': 2.0644067145639267, 'n_layers': 2, 'hidden_dropout': 0.2539138753056258, 'residual_dropout': 0.2955471487880107, 'learning_rate': 0.0009570854483223048, 'batch_size': 64, 'epochs': 116}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:18:54,198] Trial 29 finished with value: 0.3730011666343639 and parameters: {'d': 64, 'd_hidden_factor': 4.286514978279635, 'n_layers': 5, 'hidden_dropout': 0.49234790898426983, 'residual_dropout': 0.3446210774819704, 'learning_rate': 0.002470725506355306, 'batch_size': 128, 'epochs': 37}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:18:58,545] Trial 30 finished with value: 0.4798852133962039 and parameters: {'d': 512, 'd_hidden_factor': 1.580868539989401, 'n_layers': 3, 'hidden_dropout': 0.4612933495376838, 'residual_dropout': 0.45827283662591684, 'learning_rate': 0.0003396010126803056, 'batch_size': 256, 'epochs': 53}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:19:06,409] Trial 31 finished with value: 0.5276800682755269 and parameters: {'d': 512, 'd_hidden_factor': 1.2264957842893698, 'n_layers': 2, 'hidden_dropout': 0.17203728873597912, 'residual_dropout': 0.37638933436348754, 'learning_rate': 0.0010462512049629576, 'batch_size': 64, 'epochs': 128}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:19:15,165] Trial 32 finished with value: 0.46291795493245846 and parameters: {'d': 512, 'd_hidden_factor': 1.8947969760837826, 'n_layers': 2, 'hidden_dropout': 0.1393032810991935, 'residual_dropout': 0.35002380247816856, 'learning_rate': 0.0003604030471187802, 'batch_size': 64, 'epochs': 130}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:19:33,526] Trial 33 finished with value: 0.37750773757423184 and parameters: {'d': 512, 'd_hidden_factor': 1.2608051550165953, 'n_layers': 5, 'hidden_dropout': 0.11793141598394863, 'residual_dropout': 0.4033836518358867, 'learning_rate': 0.009581981551336159, 'batch_size': 64, 'epochs': 106}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:19:38,007] Trial 34 finished with value: 0.4454421682619018 and parameters: {'d': 128, 'd_hidden_factor': 1.7115718272910867, 'n_layers': 1, 'hidden_dropout': 0.21680592442283, 'residual_dropout': 0.3261058217244316, 'learning_rate': 0.003967017714361064, 'batch_size': 64, 'epochs': 88}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:20:05,360] Trial 35 finished with value: 0.5202325824121418 and parameters: {'d': 512, 'd_hidden_factor': 2.696608803626071, 'n_layers': 7, 'hidden_dropout': 0.15656988910700423, 'residual_dropout': 0.36471336940711335, 'learning_rate': 0.0013177333511346812, 'batch_size': 64, 'epochs': 75}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:20:25,836] Trial 36 finished with value: 0.3491899429135144 and parameters: {'d': 256, 'd_hidden_factor': 1.0104526113171488, 'n_layers': 10, 'hidden_dropout': 0.27019084096097146, 'residual_dropout': 0.2799019978992617, 'learning_rate': 0.0022176909632056056, 'batch_size': 64, 'epochs': 132}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:21:04,871] Trial 37 finished with value: 0.3829986094153378 and parameters: {'d': 128, 'd_hidden_factor': 2.0435107066711513, 'n_layers': 4, 'hidden_dropout': 0.08618438678976152, 'residual_dropout': 0.2323531592223368, 'learning_rate': 0.00013332229354243969, 'batch_size': 32, 'epochs': 91}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:21:16,299] Trial 38 finished with value: 0.5711006509199 and parameters: {'d': 512, 'd_hidden_factor': 1.5665262752543692, 'n_layers': 3, 'hidden_dropout': 0.20739993728547212, 'residual_dropout': 0.46508985318953683, 'learning_rate': 0.0032507936129316096, 'batch_size': 64, 'epochs': 110}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:21:34,435] Trial 39 finished with value: 0.5062478116326801 and parameters: {'d': 512, 'd_hidden_factor': 3.1496097878319476, 'n_layers': 3, 'hidden_dropout': 0.2890784603364066, 'residual_dropout': 0.45280534577367887, 'learning_rate': 0.006764289987417157, 'batch_size': 64, 'epochs': 108}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:21:57,603] Trial 40 finished with value: 0.3893567091672778 and parameters: {'d': 256, 'd_hidden_factor': 1.4939082438600118, 'n_layers': 5, 'hidden_dropout': 0.33789629777566627, 'residual_dropout': 0.47199398633120365, 'learning_rate': 0.0032504830429730966, 'batch_size': 32, 'epochs': 101}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:22:04,995] Trial 41 finished with value: 0.5033327076805585 and parameters: {'d': 512, 'd_hidden_factor': 1.1910048470547614, 'n_layers': 2, 'hidden_dropout': 0.21066817622631, 'residual_dropout': 0.3155754414292623, 'learning_rate': 0.004558059297047432, 'batch_size': 64, 'epochs': 116}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:22:13,775] Trial 42 finished with value: 0.45577458705791074 and parameters: {'d': 512, 'd_hidden_factor': 1.543163618641577, 'n_layers': 3, 'hidden_dropout': 0.23904353028186953, 'residual_dropout': 0.3994566511414594, 'learning_rate': 0.0018357621946173425, 'batch_size': 64, 'epochs': 140}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:22:21,657] Trial 43 finished with value: 0.5167660617708274 and parameters: {'d': 512, 'd_hidden_factor': 1.8692162333527151, 'n_layers': 2, 'hidden_dropout': 0.18644845295644685, 'residual_dropout': 0.4242139046567494, 'learning_rate': 0.002914732153439603, 'batch_size': 64, 'epochs': 123}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:22:23,864] Trial 44 finished with value: 0.43471313453260096 and parameters: {'d': 128, 'd_hidden_factor': 1.2284886022759296, 'n_layers': 4, 'hidden_dropout': 0.14218928785788193, 'residual_dropout': 0.4754671887325842, 'learning_rate': 0.006948041648263682, 'batch_size': 256, 'epochs': 151}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:22:28,922] Trial 45 finished with value: 0.4948158466511853 and parameters: {'d': 512, 'd_hidden_factor': 2.1343533579726905, 'n_layers': 1, 'hidden_dropout': 0.25660708771290036, 'residual_dropout': 0.16259465012931784, 'learning_rate': 0.0011509890003887334, 'batch_size': 64, 'epochs': 93}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:22:46,802] Trial 46 finished with value: 0.4462930105819917 and parameters: {'d': 64, 'd_hidden_factor': 3.5705428487878144, 'n_layers': 3, 'hidden_dropout': 0.2086588961191078, 'residual_dropout': 0.4172677916896324, 'learning_rate': 0.0005156000523290103, 'batch_size': 64, 'epochs': 160}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:22:49,333] Trial 47 finished with value: 0.5194349006682775 and parameters: {'d': 512, 'd_hidden_factor': 1.7788112568192525, 'n_layers': 2, 'hidden_dropout': 0.1666088978911778, 'residual_dropout': 0.37949087807772763, 'learning_rate': 0.0008164985352901907, 'batch_size': 256, 'epochs': 122}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:22:57,278] Trial 48 finished with value: 0.40103325145959945 and parameters: {'d': 512, 'd_hidden_factor': 2.2963680976839758, 'n_layers': 3, 'hidden_dropout': 0.01590098806945847, 'residual_dropout': 0.3533790788369421, 'learning_rate': 0.0001957086251975031, 'batch_size': 128, 'epochs': 67}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:23:03,385] Trial 49 finished with value: 0.48883182893365584 and parameters: {'d': 512, 'd_hidden_factor': 2.9030855839111926, 'n_layers': 1, 'hidden_dropout': 0.11995108218420844, 'residual_dropout': 0.2514023215229181, 'learning_rate': 0.00479089014397341, 'batch_size': 64, 'epochs': 195}. Best is trial 11 with value: 0.5974503462221279.\n",
      "[I 2025-11-27 01:23:03,510] A new study created in memory with name: no-name-4d2c7527-616f-4bdf-a7f8-923226153f17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 801.23s\n",
      "  Best CV G-Mean: 0.5975\n",
      "  Best parameters:\n",
      "    d: 512\n",
      "    d_hidden_factor: 1.031954150873541\n",
      "    n_layers: 2\n",
      "    hidden_dropout: 0.1785973443419468\n",
      "    residual_dropout: 0.3654658770144939\n",
      "    learning_rate: 0.00888036766804695\n",
      "    batch_size: 256\n",
      "    epochs: 131\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/131: Train Loss = 0.1738, Val Loss = 0.3982\n",
      "    Early stopping at epoch 17\n",
      "✓ Training complete! Time: 0.11s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR pc1\n",
      "================================================================================\n",
      "Accuracy:        0.9099\n",
      "AUC OVO:         0.8516\n",
      "G-Mean:          0.4571\n",
      "Cross-Entropy:   0.2713\n",
      "================================================================================\n",
      "✓ Saved results for pc1\n",
      "\n",
      "✓ Completed pc1 (3/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 4/30: qsar-biodeg\n",
      "################################################################################\n",
      "Loading processed dataset from cache: qsar-biodeg\n",
      "Using device: cuda\n",
      "Dataset: qsar-biodeg\n",
      "  Train: (738, 41), Test: (317, 41)\n",
      "  Features: 41, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: qsar-biodeg\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 01:23:12,093] Trial 0 finished with value: 0.867448185762472 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.867448185762472.\n",
      "[I 2025-11-27 01:23:25,936] Trial 1 finished with value: 0.8347228390247536 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 0 with value: 0.867448185762472.\n",
      "[I 2025-11-27 01:23:40,866] Trial 2 finished with value: 0.8563149103310381 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: 0.867448185762472.\n",
      "[I 2025-11-27 01:25:08,205] Trial 3 finished with value: 0.8706544415612072 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:25:23,552] Trial 4 finished with value: 0.8464894366925781 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:26:43,331] Trial 5 finished with value: 0.8669961370013628 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:27:34,252] Trial 6 finished with value: 0.8635500096510406 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:27:40,734] Trial 7 finished with value: 0.8451420068521307 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:27:44,457] Trial 8 finished with value: 0.8616729716187725 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:27:46,820] Trial 9 finished with value: 0.8461507809085951 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:29:31,191] Trial 10 finished with value: 0.8614702680940839 and parameters: {'d': 256, 'd_hidden_factor': 4.956401873386991, 'n_layers': 10, 'hidden_dropout': 0.10467358725545478, 'residual_dropout': 0.21319384192877996, 'learning_rate': 1.0455868741494775e-05, 'batch_size': 32, 'epochs': 159}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:29:44,286] Trial 11 finished with value: 0.8496330033742989 and parameters: {'d': 64, 'd_hidden_factor': 4.165311503713209, 'n_layers': 10, 'hidden_dropout': 0.4816139361200471, 'residual_dropout': 0.31057355375310725, 'learning_rate': 0.0004659790366835251, 'batch_size': 128, 'epochs': 37}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:30:02,993] Trial 12 finished with value: 0.8586396056322816 and parameters: {'d': 64, 'd_hidden_factor': 4.576233003303846, 'n_layers': 8, 'hidden_dropout': 0.4957404235255466, 'residual_dropout': 0.2516982997345141, 'learning_rate': 5.375248322425842e-05, 'batch_size': 128, 'epochs': 60}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:30:15,624] Trial 13 finished with value: 0.853446851504966 and parameters: {'d': 512, 'd_hidden_factor': 2.339717324184146, 'n_layers': 8, 'hidden_dropout': 0.4084700168016447, 'residual_dropout': 0.2546621950713965, 'learning_rate': 0.0004658473533614093, 'batch_size': 128, 'epochs': 71}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:30:58,248] Trial 14 finished with value: 0.8568075998205602 and parameters: {'d': 256, 'd_hidden_factor': 3.5041905277875633, 'n_layers': 8, 'hidden_dropout': 0.39772170074704827, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 1.4376009077366401e-05, 'batch_size': 32, 'epochs': 30}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:31:13,136] Trial 15 finished with value: 0.8572991969023585 and parameters: {'d': 64, 'd_hidden_factor': 2.807117753726553, 'n_layers': 4, 'hidden_dropout': 0.08247982261357112, 'residual_dropout': 0.3875843198971794, 'learning_rate': 6.120905171649753e-05, 'batch_size': 128, 'epochs': 82}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:31:15,426] Trial 16 finished with value: 0.8610523419602293 and parameters: {'d': 256, 'd_hidden_factor': 1.9365190882077505, 'n_layers': 1, 'hidden_dropout': 0.21019889974776085, 'residual_dropout': 0.18249691037653085, 'learning_rate': 0.0011801142500613441, 'batch_size': 128, 'epochs': 142}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:31:44,683] Trial 17 finished with value: 0.8544847283008059 and parameters: {'d': 64, 'd_hidden_factor': 4.244990652305846, 'n_layers': 4, 'hidden_dropout': 0.42361711480884384, 'residual_dropout': 0.28748841272625203, 'learning_rate': 0.00018137458359533798, 'batch_size': 32, 'epochs': 51}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:32:11,909] Trial 18 finished with value: 0.863143136429928 and parameters: {'d': 512, 'd_hidden_factor': 2.673995984894828, 'n_layers': 9, 'hidden_dropout': 0.21210013735620484, 'residual_dropout': 0.38398590992880943, 'learning_rate': 3.895410380484855e-05, 'batch_size': 256, 'epochs': 108}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:32:33,734] Trial 19 finished with value: 0.8404323088455067 and parameters: {'d': 256, 'd_hidden_factor': 3.6656530638082954, 'n_layers': 3, 'hidden_dropout': 0.0027416982897154885, 'residual_dropout': 0.15156870090272612, 'learning_rate': 0.0011981058947331945, 'batch_size': 32, 'epochs': 74}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:32:46,878] Trial 20 finished with value: 0.8074275315489843 and parameters: {'d': 64, 'd_hidden_factor': 4.622184555212415, 'n_layers': 7, 'hidden_dropout': 0.45783186690659256, 'residual_dropout': 0.3502192010948755, 'learning_rate': 2.2026446429467672e-05, 'batch_size': 128, 'epochs': 47}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:34:06,964] Trial 21 finished with value: 0.8632465986964171 and parameters: {'d': 128, 'd_hidden_factor': 1.0103220403349225, 'n_layers': 5, 'hidden_dropout': 0.2749764227284816, 'residual_dropout': 0.05691742478522008, 'learning_rate': 3.0058905072681507e-05, 'batch_size': 32, 'epochs': 108}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:34:57,330] Trial 22 finished with value: 0.8584427487320465 and parameters: {'d': 128, 'd_hidden_factor': 1.730392036289813, 'n_layers': 7, 'hidden_dropout': 0.2518695882706262, 'residual_dropout': 0.1056259701869368, 'learning_rate': 9.366930763948897e-05, 'batch_size': 32, 'epochs': 92}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:37:28,625] Trial 23 finished with value: 0.8568795900309987 and parameters: {'d': 128, 'd_hidden_factor': 1.5073219348522309, 'n_layers': 9, 'hidden_dropout': 0.3643742923151697, 'residual_dropout': 0.21788721108783282, 'learning_rate': 1.8015743903064992e-05, 'batch_size': 32, 'epochs': 151}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:38:16,015] Trial 24 finished with value: 0.8663976365999562 and parameters: {'d': 256, 'd_hidden_factor': 1.0237952823763947, 'n_layers': 7, 'hidden_dropout': 0.1811133142917013, 'residual_dropout': 0.2849030677441335, 'learning_rate': 6.542013227905847e-05, 'batch_size': 32, 'epochs': 61}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:38:38,655] Trial 25 finished with value: 0.8400944683753 and parameters: {'d': 128, 'd_hidden_factor': 2.3772455717500707, 'n_layers': 5, 'hidden_dropout': 0.10746223630017698, 'residual_dropout': 0.07148519157645067, 'learning_rate': 0.00027007726355580475, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:38:58,460] Trial 26 finished with value: 0.8585648995535307 and parameters: {'d': 64, 'd_hidden_factor': 3.9444694589927214, 'n_layers': 3, 'hidden_dropout': 0.3491669621678477, 'residual_dropout': 0.011630100065252544, 'learning_rate': 2.872069686570791e-05, 'batch_size': 128, 'epochs': 131}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:39:56,968] Trial 27 finished with value: 0.853726182439275 and parameters: {'d': 512, 'd_hidden_factor': 3.1699697342780335, 'n_layers': 9, 'hidden_dropout': 0.26194856085882995, 'residual_dropout': 0.37222891963465365, 'learning_rate': 1.0791842603595943e-05, 'batch_size': 256, 'epochs': 182}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:40:16,130] Trial 28 finished with value: 0.8540640388154804 and parameters: {'d': 64, 'd_hidden_factor': 4.456786266626951, 'n_layers': 3, 'hidden_dropout': 0.4495368518151206, 'residual_dropout': 0.41648757157292077, 'learning_rate': 0.000668880320899989, 'batch_size': 32, 'epochs': 101}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:40:34,857] Trial 29 finished with value: 0.8470809436271592 and parameters: {'d': 128, 'd_hidden_factor': 2.948790854481383, 'n_layers': 6, 'hidden_dropout': 0.15586067597875358, 'residual_dropout': 0.44835149805440233, 'learning_rate': 0.00012402668758508477, 'batch_size': 64, 'epochs': 59}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:40:55,541] Trial 30 finished with value: 0.8651966858769281 and parameters: {'d': 256, 'd_hidden_factor': 3.338388546616556, 'n_layers': 7, 'hidden_dropout': 0.3708100846035076, 'residual_dropout': 0.28289876405830217, 'learning_rate': 4.719784111382512e-05, 'batch_size': 128, 'epochs': 114}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:41:37,703] Trial 31 finished with value: 0.8559503429510391 and parameters: {'d': 256, 'd_hidden_factor': 1.1557210363836523, 'n_layers': 7, 'hidden_dropout': 0.1535579752892529, 'residual_dropout': 0.28673952050640583, 'learning_rate': 6.75052914149632e-05, 'batch_size': 32, 'epochs': 62}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:42:11,741] Trial 32 finished with value: 0.8633941589239654 and parameters: {'d': 256, 'd_hidden_factor': 1.376463885823822, 'n_layers': 5, 'hidden_dropout': 0.1893499225575471, 'residual_dropout': 0.22255575834931715, 'learning_rate': 2.4952909289783714e-05, 'batch_size': 32, 'epochs': 41}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:42:43,598] Trial 33 finished with value: 0.8550681941067555 and parameters: {'d': 256, 'd_hidden_factor': 1.9155914304902688, 'n_layers': 6, 'hidden_dropout': 0.2802488850649814, 'residual_dropout': 0.3099983252534858, 'learning_rate': 0.0002002202450253117, 'batch_size': 32, 'epochs': 84}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:42:59,191] Trial 34 finished with value: 0.8637452330803137 and parameters: {'d': 256, 'd_hidden_factor': 1.153645268940164, 'n_layers': 4, 'hidden_dropout': 0.2306241912881013, 'residual_dropout': 0.1531887242734133, 'learning_rate': 8.344120224251835e-05, 'batch_size': 64, 'epochs': 66}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:43:41,695] Trial 35 finished with value: 0.8585408544437975 and parameters: {'d': 128, 'd_hidden_factor': 1.7101084788940928, 'n_layers': 5, 'hidden_dropout': 0.05581799246455546, 'residual_dropout': 0.34649583020101254, 'learning_rate': 3.699515751043821e-05, 'batch_size': 32, 'epochs': 52}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:44:51,275] Trial 36 finished with value: 0.8694016417438075 and parameters: {'d': 256, 'd_hidden_factor': 2.619288141291488, 'n_layers': 6, 'hidden_dropout': 0.32702182479983805, 'residual_dropout': 0.26162523303158836, 'learning_rate': 1.5587510816180243e-05, 'batch_size': 32, 'epochs': 75}. Best is trial 3 with value: 0.8706544415612072.\n",
      "[I 2025-11-27 01:45:36,966] Trial 37 finished with value: 0.8731310914547097 and parameters: {'d': 128, 'd_hidden_factor': 2.5729864627729686, 'n_layers': 6, 'hidden_dropout': 0.32042016596789136, 'residual_dropout': 0.17918429275508574, 'learning_rate': 1.4981021007483853e-05, 'batch_size': 64, 'epochs': 97}. Best is trial 37 with value: 0.8731310914547097.\n",
      "[I 2025-11-27 01:46:20,579] Trial 38 finished with value: 0.863678369985926 and parameters: {'d': 128, 'd_hidden_factor': 2.5951899435072336, 'n_layers': 8, 'hidden_dropout': 0.30873501856979046, 'residual_dropout': 0.18074016357717665, 'learning_rate': 1.8291897286445867e-05, 'batch_size': 64, 'epochs': 74}. Best is trial 37 with value: 0.8731310914547097.\n",
      "[I 2025-11-27 01:46:33,660] Trial 39 finished with value: 0.8412761614029849 and parameters: {'d': 256, 'd_hidden_factor': 3.012458684446139, 'n_layers': 6, 'hidden_dropout': 0.3164327716142362, 'residual_dropout': 0.19608981403563563, 'learning_rate': 0.002433833241748695, 'batch_size': 64, 'epochs': 101}. Best is trial 37 with value: 0.8731310914547097.\n",
      "[I 2025-11-27 01:47:14,346] Trial 40 finished with value: 0.8598188229692696 and parameters: {'d': 512, 'd_hidden_factor': 2.515340214254711, 'n_layers': 4, 'hidden_dropout': 0.3274217446132086, 'residual_dropout': 0.2389357254570082, 'learning_rate': 1.3874829048098379e-05, 'batch_size': 64, 'epochs': 120}. Best is trial 37 with value: 0.8731310914547097.\n",
      "[I 2025-11-27 01:47:49,207] Trial 41 finished with value: 0.8616571901468288 and parameters: {'d': 128, 'd_hidden_factor': 2.0129776295474606, 'n_layers': 5, 'hidden_dropout': 0.2901382904665285, 'residual_dropout': 0.09654099518409642, 'learning_rate': 1.2822548459407814e-05, 'batch_size': 64, 'epochs': 83}. Best is trial 37 with value: 0.8731310914547097.\n",
      "[I 2025-11-27 01:48:04,134] Trial 42 finished with value: 0.8389610253058841 and parameters: {'d': 128, 'd_hidden_factor': 2.1397428775230365, 'n_layers': 10, 'hidden_dropout': 0.33465673922745465, 'residual_dropout': 0.13012096322747677, 'learning_rate': 1.692537595918364e-05, 'batch_size': 256, 'epochs': 92}. Best is trial 37 with value: 0.8731310914547097.\n",
      "[I 2025-11-27 01:48:45,949] Trial 43 finished with value: 0.8633882371470604 and parameters: {'d': 128, 'd_hidden_factor': 3.206746817842486, 'n_layers': 6, 'hidden_dropout': 0.38520460478384766, 'residual_dropout': 0.3170062398686547, 'learning_rate': 3.692536070893813e-05, 'batch_size': 64, 'epochs': 97}. Best is trial 37 with value: 0.8731310914547097.\n",
      "[I 2025-11-27 01:50:24,459] Trial 44 finished with value: 0.8488993078410724 and parameters: {'d': 64, 'd_hidden_factor': 2.8867703511640186, 'n_layers': 6, 'hidden_dropout': 0.23574134008213438, 'residual_dropout': 0.035457979200699624, 'learning_rate': 2.33811395499378e-05, 'batch_size': 32, 'epochs': 131}. Best is trial 37 with value: 0.8731310914547097.\n",
      "[I 2025-11-27 01:50:41,105] Trial 45 finished with value: 0.831142961245799 and parameters: {'d': 128, 'd_hidden_factor': 3.3968571787666564, 'n_layers': 5, 'hidden_dropout': 0.4217186938230467, 'residual_dropout': 0.26160525742733043, 'learning_rate': 1.048237631131025e-05, 'batch_size': 128, 'epochs': 76}. Best is trial 37 with value: 0.8731310914547097.\n",
      "[I 2025-11-27 01:51:22,699] Trial 46 finished with value: 0.8469888888744291 and parameters: {'d': 256, 'd_hidden_factor': 3.642011160522412, 'n_layers': 8, 'hidden_dropout': 0.3417535464136858, 'residual_dropout': 0.12477188510268428, 'learning_rate': 0.0006416461265319349, 'batch_size': 32, 'epochs': 110}. Best is trial 37 with value: 0.8731310914547097.\n",
      "[I 2025-11-27 01:51:30,871] Trial 47 finished with value: 0.8545396881034069 and parameters: {'d': 64, 'd_hidden_factor': 3.919191729741995, 'n_layers': 1, 'hidden_dropout': 0.2678523461695479, 'residual_dropout': 0.32983742568135005, 'learning_rate': 0.00011704607656717075, 'batch_size': 128, 'epochs': 90}. Best is trial 37 with value: 0.8731310914547097.\n",
      "[I 2025-11-27 01:51:35,451] Trial 48 finished with value: 0.8521024637775009 and parameters: {'d': 256, 'd_hidden_factor': 2.4510878260359927, 'n_layers': 7, 'hidden_dropout': 0.2958991467841756, 'residual_dropout': 0.26185402121455686, 'learning_rate': 0.00517423742647702, 'batch_size': 256, 'epochs': 34}. Best is trial 37 with value: 0.8731310914547097.\n",
      "[I 2025-11-27 01:52:45,320] Trial 49 finished with value: 0.8457268855127381 and parameters: {'d': 512, 'd_hidden_factor': 4.972595621287559, 'n_layers': 6, 'hidden_dropout': 0.23209827459151983, 'residual_dropout': 0.3617678087735639, 'learning_rate': 4.6563539929969164e-05, 'batch_size': 32, 'epochs': 67}. Best is trial 37 with value: 0.8731310914547097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 1781.81s\n",
      "  Best CV G-Mean: 0.8731\n",
      "  Best parameters:\n",
      "    d: 128\n",
      "    d_hidden_factor: 2.5729864627729686\n",
      "    n_layers: 6\n",
      "    hidden_dropout: 0.32042016596789136\n",
      "    residual_dropout: 0.17918429275508574\n",
      "    learning_rate: 1.4981021007483853e-05\n",
      "    batch_size: 64\n",
      "    epochs: 97\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/97: Train Loss = 0.5010, Val Loss = 0.4872\n",
      "    Epoch 20/97: Train Loss = 0.4384, Val Loss = 0.4274\n",
      "    Epoch 30/97: Train Loss = 0.3876, Val Loss = 0.3939\n",
      "    Epoch 40/97: Train Loss = 0.3699, Val Loss = 0.3754\n",
      "    Epoch 50/97: Train Loss = 0.3438, Val Loss = 0.3474\n",
      "    Epoch 60/97: Train Loss = 0.3134, Val Loss = 0.3307\n",
      "    Epoch 70/97: Train Loss = 0.3141, Val Loss = 0.3266\n",
      "    Epoch 80/97: Train Loss = 0.2974, Val Loss = 0.3118\n",
      "    Epoch 90/97: Train Loss = 0.2912, Val Loss = 0.3023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 01:52:50,025] A new study created in memory with name: no-name-6d04f2a4-7cbf-404b-9ce9-b279487fdb32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training complete! Time: 4.70s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR qsar-biodeg\n",
      "================================================================================\n",
      "Accuracy:        0.8770\n",
      "AUC OVO:         0.9204\n",
      "G-Mean:          0.8678\n",
      "Cross-Entropy:   0.3343\n",
      "================================================================================\n",
      "✓ Saved results for qsar-biodeg\n",
      "\n",
      "✓ Completed qsar-biodeg (4/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 5/30: banknote-authentication\n",
      "################################################################################\n",
      "Loading processed dataset from cache: banknote-authentication\n",
      "Using device: cuda\n",
      "Dataset: banknote-authentication\n",
      "  Train: (960, 4), Test: (412, 4)\n",
      "  Features: 4, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: banknote-authentication\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 01:53:00,286] Trial 0 finished with value: 1.0 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 01:53:32,510] Trial 1 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 01:53:58,652] Trial 2 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 01:57:01,565] Trial 3 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 01:57:37,335] Trial 4 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 01:59:37,667] Trial 5 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:01:06,537] Trial 6 finished with value: 1.0 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:01:19,865] Trial 7 finished with value: 1.0 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:01:29,208] Trial 8 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:01:37,826] Trial 9 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:02:26,707] Trial 10 finished with value: 1.0 and parameters: {'d': 64, 'd_hidden_factor': 4.982751445203364, 'n_layers': 9, 'hidden_dropout': 0.4730853252665121, 'residual_dropout': 0.20864544555392683, 'learning_rate': 0.0006039122933759166, 'batch_size': 128, 'epochs': 161}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:02:40,299] Trial 11 finished with value: 1.0 and parameters: {'d': 64, 'd_hidden_factor': 4.165311503713209, 'n_layers': 8, 'hidden_dropout': 0.4816139361200471, 'residual_dropout': 0.3735745363958049, 'learning_rate': 0.0008904221936858838, 'batch_size': 128, 'epochs': 37}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:03:09,633] Trial 12 finished with value: 0.9981306762925316 and parameters: {'d': 512, 'd_hidden_factor': 4.576233003303846, 'n_layers': 4, 'hidden_dropout': 0.401750064194321, 'residual_dropout': 0.4124102148475389, 'learning_rate': 0.001252969797257985, 'batch_size': 128, 'epochs': 57}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:03:58,858] Trial 13 finished with value: 1.0 and parameters: {'d': 64, 'd_hidden_factor': 2.2848503025755864, 'n_layers': 8, 'hidden_dropout': 0.1282492931447887, 'residual_dropout': 0.2659133260764792, 'learning_rate': 0.00010038584476789021, 'batch_size': 64, 'epochs': 65}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:04:05,546] Trial 14 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 3.5041905277875633, 'n_layers': 4, 'hidden_dropout': 0.41350001377121465, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 0.00033040787452620087, 'batch_size': 128, 'epochs': 30}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:04:25,003] Trial 15 finished with value: 0.997182531580755 and parameters: {'d': 64, 'd_hidden_factor': 4.273931074142787, 'n_layers': 7, 'hidden_dropout': 0.39035215308736265, 'residual_dropout': 0.41326894035669814, 'learning_rate': 0.0016427055372210378, 'batch_size': 128, 'epochs': 62}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:04:41,864] Trial 16 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 2.4539209232214865, 'n_layers': 1, 'hidden_dropout': 0.49492098166065274, 'residual_dropout': 0.23760248619629204, 'learning_rate': 5.3922455425206265e-05, 'batch_size': 64, 'epochs': 75}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:05:22,379] Trial 17 finished with value: 1.0 and parameters: {'d': 512, 'd_hidden_factor': 3.2193529700744383, 'n_layers': 3, 'hidden_dropout': 0.07436726243220565, 'residual_dropout': 0.44323589729784874, 'learning_rate': 1.1016598219611525e-05, 'batch_size': 256, 'epochs': 152}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:05:45,670] Trial 18 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 1.8747705522934435, 'n_layers': 5, 'hidden_dropout': 0.43653859603260703, 'residual_dropout': 0.3702164166690924, 'learning_rate': 0.0003981051489951351, 'batch_size': 64, 'epochs': 44}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:06:11,045] Trial 19 finished with value: 0.9990697472229279 and parameters: {'d': 64, 'd_hidden_factor': 3.7445100071771797, 'n_layers': 7, 'hidden_dropout': 0.3433986773467199, 'residual_dropout': 0.16885219213971683, 'learning_rate': 0.0016905616848600495, 'batch_size': 128, 'epochs': 110}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:07:00,768] Trial 20 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 4.709925350693749, 'n_layers': 7, 'hidden_dropout': 0.20169667026185617, 'residual_dropout': 0.2854948959224487, 'learning_rate': 0.00015858631579797946, 'batch_size': 64, 'epochs': 70}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:07:27,381] Trial 21 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 2.8148989912720137, 'n_layers': 5, 'hidden_dropout': 0.22133007595235646, 'residual_dropout': 0.13706512216850325, 'learning_rate': 0.00021688196569733282, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:07:53,364] Trial 22 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 2.8004687488188957, 'n_layers': 5, 'hidden_dropout': 0.16911468368303426, 'residual_dropout': 0.08016980483256025, 'learning_rate': 0.0005676560139887397, 'batch_size': 64, 'epochs': 48}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:08:05,457] Trial 23 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 3.1544427923604155, 'n_layers': 3, 'hidden_dropout': 0.10292578708461073, 'residual_dropout': 0.19655522786710222, 'learning_rate': 6.397812866141783e-05, 'batch_size': 64, 'epochs': 31}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:08:35,603] Trial 24 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 2.6471416110078985, 'n_layers': 5, 'hidden_dropout': 0.3545779951352004, 'residual_dropout': 0.12600423917709647, 'learning_rate': 0.00021024661434851388, 'batch_size': 64, 'epochs': 56}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:08:52,612] Trial 25 finished with value: 1.0 and parameters: {'d': 64, 'd_hidden_factor': 1.9000907890731633, 'n_layers': 4, 'hidden_dropout': 0.1932768633102075, 'residual_dropout': 0.3720031333464797, 'learning_rate': 0.0006327241667596677, 'batch_size': 128, 'epochs': 79}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:09:54,335] Trial 26 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 4.038855794671711, 'n_layers': 6, 'hidden_dropout': 0.4467381779225382, 'residual_dropout': 0.23297846912449743, 'learning_rate': 0.00029629580374128964, 'batch_size': 32, 'epochs': 42}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:10:22,493] Trial 27 finished with value: 1.0 and parameters: {'d': 512, 'd_hidden_factor': 3.397835696218262, 'n_layers': 3, 'hidden_dropout': 0.23132405881320414, 'residual_dropout': 0.46111393939144224, 'learning_rate': 6.84214747117789e-05, 'batch_size': 256, 'epochs': 105}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:11:07,824] Trial 28 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 3.0432471885307013, 'n_layers': 8, 'hidden_dropout': 0.26032128022446976, 'residual_dropout': 0.34262113048160614, 'learning_rate': 0.0024580885760103082, 'batch_size': 64, 'epochs': 85}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:13:10,996] Trial 29 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 3.679748562117274, 'n_layers': 7, 'hidden_dropout': 0.25357305475316944, 'residual_dropout': 0.31495630060156476, 'learning_rate': 2.5896855356642666e-05, 'batch_size': 32, 'epochs': 72}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:13:35,327] Trial 30 finished with value: 1.0 and parameters: {'d': 64, 'd_hidden_factor': 2.5514055717204966, 'n_layers': 10, 'hidden_dropout': 0.05031861309134311, 'residual_dropout': 0.28289876405830217, 'learning_rate': 0.0001356810979584868, 'batch_size': 128, 'epochs': 57}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:16:38,253] Trial 31 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 2.9139209721158896, 'n_layers': 10, 'hidden_dropout': 0.3124190825579105, 'residual_dropout': 0.31460578100777414, 'learning_rate': 1.0504066193294574e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:18:10,771] Trial 32 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 2.0203643740190964, 'n_layers': 9, 'hidden_dropout': 0.28439892636632846, 'residual_dropout': 0.36059873437055584, 'learning_rate': 2.4338579701661697e-05, 'batch_size': 32, 'epochs': 49}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:20:36,913] Trial 33 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 3.5504083348365865, 'n_layers': 6, 'hidden_dropout': 0.3574778748203774, 'residual_dropout': 0.4045449026883996, 'learning_rate': 4.069181616369386e-05, 'batch_size': 32, 'epochs': 98}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:24:52,816] Trial 34 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 1.4651441243819172, 'n_layers': 9, 'hidden_dropout': 0.15920223954428186, 'residual_dropout': 0.29963322146926374, 'learning_rate': 1.8950176635683575e-05, 'batch_size': 32, 'epochs': 142}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:25:50,220] Trial 35 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 3.0757853887475144, 'n_layers': 6, 'hidden_dropout': 0.2655585952159805, 'residual_dropout': 0.4723446400280793, 'learning_rate': 9.963416140692602e-05, 'batch_size': 64, 'epochs': 94}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:26:41,921] Trial 36 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 2.2913562201545257, 'n_layers': 4, 'hidden_dropout': 0.32208765644548903, 'residual_dropout': 0.0371078794097789, 'learning_rate': 0.004451597124467344, 'batch_size': 32, 'epochs': 118}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:26:57,156] Trial 37 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 2.7185251033095508, 'n_layers': 5, 'hidden_dropout': 0.22770002955180524, 'residual_dropout': 0.3371632820831451, 'learning_rate': 0.0009239477488450994, 'batch_size': 256, 'epochs': 177}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:27:20,708] Trial 38 finished with value: 0.9886039598196092 and parameters: {'d': 64, 'd_hidden_factor': 3.2974792124470307, 'n_layers': 3, 'hidden_dropout': 0.19101460051798827, 'residual_dropout': 0.25787110815589676, 'learning_rate': 1.632208901023464e-05, 'batch_size': 64, 'epochs': 63}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:27:34,005] Trial 39 finished with value: 0.9988303691203525 and parameters: {'d': 512, 'd_hidden_factor': 3.855421599893769, 'n_layers': 2, 'hidden_dropout': 0.2890784603364066, 'residual_dropout': 0.3938134204677436, 'learning_rate': 0.009715021794362554, 'batch_size': 128, 'epochs': 89}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:28:19,934] Trial 40 finished with value: 1.0 and parameters: {'d': 64, 'd_hidden_factor': 4.352960169926183, 'n_layers': 6, 'hidden_dropout': 0.1414577394954828, 'residual_dropout': 0.21099337264645432, 'learning_rate': 0.0004711252390318203, 'batch_size': 32, 'epochs': 37}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:28:54,088] Trial 41 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 3.9966419634660557, 'n_layers': 6, 'hidden_dropout': 0.333147477459005, 'residual_dropout': 0.3485783148238635, 'learning_rate': 0.00632964108988905, 'batch_size': 64, 'epochs': 132}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:29:41,130] Trial 42 finished with value: 0.9990697472229279 and parameters: {'d': 256, 'd_hidden_factor': 3.484602169754857, 'n_layers': 8, 'hidden_dropout': 0.3764102359713825, 'residual_dropout': 0.3178534604101932, 'learning_rate': 0.004312360260135459, 'batch_size': 64, 'epochs': 125}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:30:06,464] Trial 43 finished with value: 0.9990697472229279 and parameters: {'d': 256, 'd_hidden_factor': 3.7530466935625757, 'n_layers': 4, 'hidden_dropout': 0.29816140656162105, 'residual_dropout': 0.38448028371568854, 'learning_rate': 0.002489642710990812, 'batch_size': 64, 'epochs': 104}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:30:43,324] Trial 44 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 2.927391984567044, 'n_layers': 7, 'hidden_dropout': 0.4216980281571866, 'residual_dropout': 0.42897203545598184, 'learning_rate': 0.0009047808149455247, 'batch_size': 64, 'epochs': 134}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:30:56,885] Trial 45 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 2.396121744826128, 'n_layers': 5, 'hidden_dropout': 0.3743018967091659, 'residual_dropout': 0.29074868815072796, 'learning_rate': 0.002614605594757574, 'batch_size': 128, 'epochs': 66}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:31:10,944] Trial 46 finished with value: 0.9962613525850632 and parameters: {'d': 64, 'd_hidden_factor': 4.509747300463812, 'n_layers': 4, 'hidden_dropout': 0.2415045613041113, 'residual_dropout': 0.48291256798256815, 'learning_rate': 0.001784274728966719, 'batch_size': 256, 'epochs': 161}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:32:29,754] Trial 47 finished with value: 1.0 and parameters: {'d': 512, 'd_hidden_factor': 3.289041467604963, 'n_layers': 8, 'hidden_dropout': 0.4685029289390552, 'residual_dropout': 0.26944564236262647, 'learning_rate': 0.0011969403642386014, 'batch_size': 64, 'epochs': 76}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:32:34,952] Trial 48 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 3.6173216338199103, 'n_layers': 1, 'hidden_dropout': 0.2716195661460554, 'residual_dropout': 0.23935276227319197, 'learning_rate': 0.006460340925275683, 'batch_size': 128, 'epochs': 54}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-11-27 02:33:03,950] Trial 49 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 4.148333544652458, 'n_layers': 7, 'hidden_dropout': 0.3084402035990277, 'residual_dropout': 0.42820060858454706, 'learning_rate': 4.040618018454688e-05, 'batch_size': 64, 'epochs': 33}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 2413.93s\n",
      "  Best CV G-Mean: 1.0000\n",
      "  Best parameters:\n",
      "    d: 64\n",
      "    d_hidden_factor: 3.8778758791422523\n",
      "    n_layers: 5\n",
      "    hidden_dropout: 0.49038209919230774\n",
      "    residual_dropout: 0.34241486929243165\n",
      "    learning_rate: 0.00027720158198153483\n",
      "    batch_size: 128\n",
      "    epochs: 40\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/40: Train Loss = 0.1310, Val Loss = 0.0833\n",
      "    Epoch 20/40: Train Loss = 0.0679, Val Loss = 0.0444\n",
      "    Epoch 30/40: Train Loss = 0.0445, Val Loss = 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 02:33:04,986] A new study created in memory with name: no-name-57d6154c-0dba-4d21-bcaf-2add0e25d619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 40/40: Train Loss = 0.0295, Val Loss = 0.0166\n",
      "✓ Training complete! Time: 1.02s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR banknote-authentication\n",
      "================================================================================\n",
      "Accuracy:        1.0000\n",
      "AUC OVO:         1.0000\n",
      "G-Mean:          1.0000\n",
      "Cross-Entropy:   0.0172\n",
      "================================================================================\n",
      "✓ Saved results for banknote-authentication\n",
      "\n",
      "✓ Completed banknote-authentication (5/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 6/30: cnae-9\n",
      "################################################################################\n",
      "Loading processed dataset from cache: cnae-9\n",
      "Using device: cuda\n",
      "Dataset: cnae-9\n",
      "  Train: (756, 856), Test: (324, 856)\n",
      "  Features: 856, Classes: 9\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: cnae-9\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 02:33:13,625] Trial 0 finished with value: 0.8950627750601343 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.8950627750601343.\n",
      "[I 2025-11-27 02:33:28,284] Trial 1 finished with value: 0.9049041293380278 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.9049041293380278.\n",
      "[I 2025-11-27 02:33:49,168] Trial 2 finished with value: 0.8618572970758228 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 1 with value: 0.9049041293380278.\n",
      "[I 2025-11-27 02:36:14,545] Trial 3 finished with value: 0.8857496235828854 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 1 with value: 0.9049041293380278.\n",
      "[I 2025-11-27 02:36:29,975] Trial 4 finished with value: 0.9282821061349275 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 4 with value: 0.9282821061349275.\n",
      "[I 2025-11-27 02:38:04,126] Trial 5 finished with value: 0.8847144595268291 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 4 with value: 0.9282821061349275.\n",
      "[I 2025-11-27 02:39:15,807] Trial 6 finished with value: 0.9115059027001768 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 4 with value: 0.9282821061349275.\n",
      "[I 2025-11-27 02:39:22,423] Trial 7 finished with value: 0.9218412731999457 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 4 with value: 0.9282821061349275.\n",
      "[I 2025-11-27 02:39:25,254] Trial 8 finished with value: 0.9228044924283513 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 4 with value: 0.9282821061349275.\n",
      "[I 2025-11-27 02:39:27,083] Trial 9 finished with value: 0.9244152438012965 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 4 with value: 0.9282821061349275.\n",
      "[I 2025-11-27 02:39:39,602] Trial 10 finished with value: 0.917340708498867 and parameters: {'d': 256, 'd_hidden_factor': 4.979424057639253, 'n_layers': 9, 'hidden_dropout': 0.4492503695658236, 'residual_dropout': 0.20527952505392744, 'learning_rate': 0.0014870022276803282, 'batch_size': 128, 'epochs': 145}. Best is trial 4 with value: 0.9282821061349275.\n",
      "[I 2025-11-27 02:39:41,334] Trial 11 finished with value: 0.9299425135726747 and parameters: {'d': 256, 'd_hidden_factor': 4.203203101790258, 'n_layers': 2, 'hidden_dropout': 0.3860113813495768, 'residual_dropout': 0.3700848354896414, 'learning_rate': 0.00888036766804695, 'batch_size': 256, 'epochs': 138}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:39:48,753] Trial 12 finished with value: 0.9273841191917735 and parameters: {'d': 256, 'd_hidden_factor': 4.774303166899394, 'n_layers': 8, 'hidden_dropout': 0.39666925881190335, 'residual_dropout': 0.26031347748228334, 'learning_rate': 0.0016179440919177456, 'batch_size': 256, 'epochs': 150}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:39:50,089] Trial 13 finished with value: 0.9185127727812066 and parameters: {'d': 256, 'd_hidden_factor': 4.157376568945096, 'n_layers': 1, 'hidden_dropout': 0.40068056585205547, 'residual_dropout': 0.39413953355958786, 'learning_rate': 0.0029198904986921475, 'batch_size': 256, 'epochs': 172}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:40:09,232] Trial 14 finished with value: 0.9089204359771923 and parameters: {'d': 512, 'd_hidden_factor': 4.3709269285098005, 'n_layers': 3, 'hidden_dropout': 0.13877060271827935, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 0.009800254662636202, 'batch_size': 64, 'epochs': 130}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:40:18,505] Trial 15 finished with value: 0.9110899309148841 and parameters: {'d': 256, 'd_hidden_factor': 3.5461429951984633, 'n_layers': 8, 'hidden_dropout': 0.3651227203502917, 'residual_dropout': 0.262547820532361, 'learning_rate': 0.0006221274340282898, 'batch_size': 256, 'epochs': 165}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:40:38,353] Trial 16 finished with value: 0.8999671179464892 and parameters: {'d': 256, 'd_hidden_factor': 2.320744988615705, 'n_layers': 7, 'hidden_dropout': 0.21019889974776085, 'residual_dropout': 0.37496612117779893, 'learning_rate': 0.0006960164587986635, 'batch_size': 64, 'epochs': 116}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:41:16,276] Trial 17 finished with value: 0.8921153693270123 and parameters: {'d': 256, 'd_hidden_factor': 4.426874031416949, 'n_layers': 4, 'hidden_dropout': 0.4456293387845388, 'residual_dropout': 0.193885320471026, 'learning_rate': 5.941072156885347e-05, 'batch_size': 128, 'epochs': 189}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:41:37,319] Trial 18 finished with value: 0.9084182653987929 and parameters: {'d': 512, 'd_hidden_factor': 3.597501866049522, 'n_layers': 4, 'hidden_dropout': 0.09660139463621625, 'residual_dropout': 0.2847989249817007, 'learning_rate': 0.0006248578598342765, 'batch_size': 64, 'epochs': 142}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:41:41,152] Trial 19 finished with value: 0.065437031782087 and parameters: {'d': 64, 'd_hidden_factor': 2.51771139266297, 'n_layers': 1, 'hidden_dropout': 0.3176470193106473, 'residual_dropout': 0.43267316260628785, 'learning_rate': 1.0094165165701898e-05, 'batch_size': 256, 'epochs': 173}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:41:56,605] Trial 20 finished with value: 0.9167010780487537 and parameters: {'d': 256, 'd_hidden_factor': 4.41502437797543, 'n_layers': 7, 'hidden_dropout': 0.4202138733708044, 'residual_dropout': 0.2101399147354028, 'learning_rate': 0.003922968241286064, 'batch_size': 64, 'epochs': 109}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:42:03,694] Trial 21 finished with value: 0.9107258397068236 and parameters: {'d': 256, 'd_hidden_factor': 4.824688695160367, 'n_layers': 9, 'hidden_dropout': 0.3777276325291212, 'residual_dropout': 0.34712630187038673, 'learning_rate': 0.0013816052223770178, 'batch_size': 256, 'epochs': 140}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:42:09,112] Trial 22 finished with value: 0.9184998923215499 and parameters: {'d': 256, 'd_hidden_factor': 4.737159199376487, 'n_layers': 8, 'hidden_dropout': 0.48374454639193804, 'residual_dropout': 0.25143307695389633, 'learning_rate': 0.0022455783795632795, 'batch_size': 256, 'epochs': 157}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:42:14,421] Trial 23 finished with value: 0.9177479982619297 and parameters: {'d': 256, 'd_hidden_factor': 3.968134961726784, 'n_layers': 7, 'hidden_dropout': 0.3484221787695022, 'residual_dropout': 0.2940330673714887, 'learning_rate': 0.006940382042529256, 'batch_size': 256, 'epochs': 151}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:42:22,021] Trial 24 finished with value: 0.9160415966009834 and parameters: {'d': 256, 'd_hidden_factor': 4.546449891167755, 'n_layers': 8, 'hidden_dropout': 0.4120208912609716, 'residual_dropout': 0.1582152982718022, 'learning_rate': 0.0009128101857698403, 'batch_size': 256, 'epochs': 126}. Best is trial 11 with value: 0.9299425135726747.\n",
      "[I 2025-11-27 02:42:27,824] Trial 25 finished with value: 0.9316537744728588 and parameters: {'d': 256, 'd_hidden_factor': 3.5400776277770056, 'n_layers': 9, 'hidden_dropout': 0.45023947551887733, 'residual_dropout': 0.3721742517568828, 'learning_rate': 0.005175748124283204, 'batch_size': 256, 'epochs': 109}. Best is trial 25 with value: 0.9316537744728588.\n",
      "[I 2025-11-27 02:42:44,688] Trial 26 finished with value: 0.9331193306060447 and parameters: {'d': 256, 'd_hidden_factor': 3.550730806046488, 'n_layers': 3, 'hidden_dropout': 0.4455917804361151, 'residual_dropout': 0.38426015529371643, 'learning_rate': 0.0052309780251211776, 'batch_size': 32, 'epochs': 110}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:43:13,774] Trial 27 finished with value: 0.9174269661003602 and parameters: {'d': 512, 'd_hidden_factor': 3.2622385063736776, 'n_layers': 3, 'hidden_dropout': 0.45057812203567393, 'residual_dropout': 0.3891122452464532, 'learning_rate': 0.005098886279401942, 'batch_size': 32, 'epochs': 67}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:43:27,068] Trial 28 finished with value: 0.9209298533352716 and parameters: {'d': 64, 'd_hidden_factor': 2.8613208920111775, 'n_layers': 2, 'hidden_dropout': 0.4945361377358033, 'residual_dropout': 0.4561631804003807, 'learning_rate': 0.006311849821504755, 'batch_size': 32, 'epochs': 103}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:43:32,433] Trial 29 finished with value: 0.9153619487148301 and parameters: {'d': 64, 'd_hidden_factor': 4.080465586229383, 'n_layers': 3, 'hidden_dropout': 0.4963578133418579, 'residual_dropout': 0.356002616986575, 'learning_rate': 0.002323902533884301, 'batch_size': 128, 'epochs': 37}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:43:50,911] Trial 30 finished with value: 0.9095516065651047 and parameters: {'d': 256, 'd_hidden_factor': 3.745709213629606, 'n_layers': 1, 'hidden_dropout': 0.4612933495376838, 'residual_dropout': 0.46110333959886823, 'learning_rate': 0.0003396010126803056, 'batch_size': 32, 'epochs': 78}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:44:47,314] Trial 31 finished with value: 0.9245923237182415 and parameters: {'d': 256, 'd_hidden_factor': 3.447389109249286, 'n_layers': 10, 'hidden_dropout': 0.3337615633693109, 'residual_dropout': 0.4041564047344491, 'learning_rate': 0.00425365905042781, 'batch_size': 32, 'epochs': 115}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:44:55,346] Trial 32 finished with value: 0.9291961060310111 and parameters: {'d': 256, 'd_hidden_factor': 3.7972419178435612, 'n_layers': 5, 'hidden_dropout': 0.4235409355515073, 'residual_dropout': 0.32031467099474703, 'learning_rate': 0.009687358923099337, 'batch_size': 128, 'epochs': 133}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:45:02,395] Trial 33 finished with value: 0.9267523616135328 and parameters: {'d': 256, 'd_hidden_factor': 4.215175537780104, 'n_layers': 5, 'hidden_dropout': 0.42420466068996937, 'residual_dropout': 0.320000671695561, 'learning_rate': 0.009679103602431868, 'batch_size': 128, 'epochs': 134}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:45:07,796] Trial 34 finished with value: 0.9300928083388753 and parameters: {'d': 128, 'd_hidden_factor': 3.1651228510886726, 'n_layers': 5, 'hidden_dropout': 0.3793418642486517, 'residual_dropout': 0.3729147040531676, 'learning_rate': 0.00692035891073962, 'batch_size': 128, 'epochs': 54}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:45:11,097] Trial 35 finished with value: 0.9297606222287124 and parameters: {'d': 128, 'd_hidden_factor': 3.1795415058959193, 'n_layers': 3, 'hidden_dropout': 0.3758330872719149, 'residual_dropout': 0.3655382980729184, 'learning_rate': 0.0059866680591664605, 'batch_size': 128, 'epochs': 50}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:45:16,851] Trial 36 finished with value: 0.9144348125793593 and parameters: {'d': 128, 'd_hidden_factor': 3.043807682199177, 'n_layers': 4, 'hidden_dropout': 0.4731093090616949, 'residual_dropout': 0.4132771154500627, 'learning_rate': 0.002223368900206612, 'batch_size': 128, 'epochs': 61}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:45:35,877] Trial 37 finished with value: 0.9104503403311826 and parameters: {'d': 128, 'd_hidden_factor': 2.7726966246232987, 'n_layers': 2, 'hidden_dropout': 0.2501504232796835, 'residual_dropout': 0.45449964699805834, 'learning_rate': 0.0010203178486908754, 'batch_size': 32, 'epochs': 88}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:45:39,749] Trial 38 finished with value: 0.8832954737100938 and parameters: {'d': 128, 'd_hidden_factor': 3.4168304194999823, 'n_layers': 4, 'hidden_dropout': 0.28603835068216826, 'residual_dropout': 0.35990055235404234, 'learning_rate': 0.00023693904158290102, 'batch_size': 256, 'epochs': 47}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:46:05,389] Trial 39 finished with value: 0.9172254077755004 and parameters: {'d': 128, 'd_hidden_factor': 2.5453780958893066, 'n_layers': 6, 'hidden_dropout': 0.39231477329315656, 'residual_dropout': 0.2902678242723033, 'learning_rate': 0.003109955508540754, 'batch_size': 32, 'epochs': 79}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:46:10,087] Trial 40 finished with value: 0.9243658062774338 and parameters: {'d': 128, 'd_hidden_factor': 1.6463877357855388, 'n_layers': 5, 'hidden_dropout': 0.3321166897755952, 'residual_dropout': 0.4227750017551077, 'learning_rate': 0.006341159685976935, 'batch_size': 128, 'epochs': 105}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:46:14,276] Trial 41 finished with value: 0.928920247629412 and parameters: {'d': 128, 'd_hidden_factor': 3.047731830649197, 'n_layers': 3, 'hidden_dropout': 0.37258395604219324, 'residual_dropout': 0.35647045001833866, 'learning_rate': 0.006293874649704742, 'batch_size': 128, 'epochs': 54}. Best is trial 26 with value: 0.9331193306060447.\n",
      "[I 2025-11-27 02:46:17,321] Trial 42 finished with value: 0.93390484168128 and parameters: {'d': 128, 'd_hidden_factor': 3.1420110156483068, 'n_layers': 2, 'hidden_dropout': 0.43457026433287416, 'residual_dropout': 0.37878978088039383, 'learning_rate': 0.004142235254085385, 'batch_size': 128, 'epochs': 44}. Best is trial 42 with value: 0.93390484168128.\n",
      "[I 2025-11-27 02:46:20,283] Trial 43 finished with value: 0.9280088542462085 and parameters: {'d': 128, 'd_hidden_factor': 3.2861971676667645, 'n_layers': 2, 'hidden_dropout': 0.4343873478178342, 'residual_dropout': 0.38485831207365123, 'learning_rate': 0.00410700256568229, 'batch_size': 128, 'epochs': 37}. Best is trial 42 with value: 0.93390484168128.\n",
      "[I 2025-11-27 02:46:23,234] Trial 44 finished with value: 0.9242931893934268 and parameters: {'d': 128, 'd_hidden_factor': 3.684989093664318, 'n_layers': 1, 'hidden_dropout': 0.4652010853972638, 'residual_dropout': 0.3403480606293195, 'learning_rate': 0.002673383868662041, 'batch_size': 128, 'epochs': 66}. Best is trial 42 with value: 0.93390484168128.\n",
      "[I 2025-11-27 02:46:25,477] Trial 45 finished with value: 0.9189162675130766 and parameters: {'d': 128, 'd_hidden_factor': 2.929709671267578, 'n_layers': 2, 'hidden_dropout': 0.21789036857932392, 'residual_dropout': 0.4052311768368401, 'learning_rate': 0.0017666935485597165, 'batch_size': 256, 'epochs': 44}. Best is trial 42 with value: 0.93390484168128.\n",
      "[I 2025-11-27 02:46:47,568] Trial 46 finished with value: 0.9144107311002339 and parameters: {'d': 512, 'd_hidden_factor': 1.9451734361228792, 'n_layers': 3, 'hidden_dropout': 0.4025509733279368, 'residual_dropout': 0.48291256798256815, 'learning_rate': 0.007637130870527069, 'batch_size': 32, 'epochs': 94}. Best is trial 42 with value: 0.93390484168128.\n",
      "[I 2025-11-27 02:46:49,799] Trial 47 finished with value: 0.931127718655423 and parameters: {'d': 64, 'd_hidden_factor': 2.6148179280661474, 'n_layers': 2, 'hidden_dropout': 0.44065571712241697, 'residual_dropout': 0.3186934240564875, 'learning_rate': 0.005146984473504512, 'batch_size': 256, 'epochs': 121}. Best is trial 42 with value: 0.93390484168128.\n",
      "[I 2025-11-27 02:46:52,450] Trial 48 finished with value: 0.9269188469950445 and parameters: {'d': 64, 'd_hidden_factor': 2.637081549681498, 'n_layers': 1, 'hidden_dropout': 0.4409578086671615, 'residual_dropout': 0.31031517393875363, 'learning_rate': 0.0049627977894147, 'batch_size': 128, 'epochs': 31}. Best is trial 42 with value: 0.93390484168128.\n",
      "[I 2025-11-27 02:46:58,540] Trial 49 finished with value: 0.926344056346825 and parameters: {'d': 64, 'd_hidden_factor': 2.2722424380526527, 'n_layers': 9, 'hidden_dropout': 0.471428983594125, 'residual_dropout': 0.22956304400666647, 'learning_rate': 0.003163089907789456, 'batch_size': 256, 'epochs': 119}. Best is trial 42 with value: 0.93390484168128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 833.56s\n",
      "  Best CV G-Mean: 0.9339\n",
      "  Best parameters:\n",
      "    d: 128\n",
      "    d_hidden_factor: 3.1420110156483068\n",
      "    n_layers: 2\n",
      "    hidden_dropout: 0.43457026433287416\n",
      "    residual_dropout: 0.37878978088039383\n",
      "    learning_rate: 0.004142235254085385\n",
      "    batch_size: 128\n",
      "    epochs: 44\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/44: Train Loss = 0.0137, Val Loss = 0.3899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 02:46:58,833] A new study created in memory with name: no-name-0b9aa3a5-ea8b-40e1-8ad2-5ae531f386c7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Early stopping at epoch 19\n",
      "✓ Training complete! Time: 0.25s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR cnae-9\n",
      "================================================================================\n",
      "Accuracy:        0.9599\n",
      "AUC OVO:         0.9950\n",
      "G-Mean:          0.9587\n",
      "Cross-Entropy:   0.1842\n",
      "================================================================================\n",
      "✓ Saved results for cnae-9\n",
      "\n",
      "✓ Completed cnae-9 (6/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 7/30: car\n",
      "################################################################################\n",
      "Loading processed dataset from cache: car\n",
      "Using device: cuda\n",
      "Dataset: car\n",
      "  Train: (1209, 21), Test: (519, 21)\n",
      "  Features: 21, Classes: 4\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: car\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 02:47:12,228] Trial 0 finished with value: 0.6012162385280678 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.6012162385280678.\n",
      "[I 2025-11-27 02:48:00,248] Trial 1 finished with value: 0.9782466430665664 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.9782466430665664.\n",
      "[I 2025-11-27 02:48:34,829] Trial 2 finished with value: 0.9788115103106009 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 2 with value: 0.9788115103106009.\n",
      "[I 2025-11-27 02:52:21,876] Trial 3 finished with value: 0.9789584955637508 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.9789584955637508.\n",
      "[I 2025-11-27 02:53:17,466] Trial 4 finished with value: 0.9839787383126165 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 4 with value: 0.9839787383126165.\n",
      "[I 2025-11-27 02:55:47,817] Trial 5 finished with value: 0.9545934775061731 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 4 with value: 0.9839787383126165.\n",
      "[I 2025-11-27 02:57:43,583] Trial 6 finished with value: 0.9596503782148387 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 4 with value: 0.9839787383126165.\n",
      "[I 2025-11-27 02:58:12,812] Trial 7 finished with value: 0.9767652189291873 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 4 with value: 0.9839787383126165.\n",
      "[I 2025-11-27 02:58:25,313] Trial 8 finished with value: 0.9839882158330232 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 8 with value: 0.9839882158330232.\n",
      "[I 2025-11-27 02:58:31,547] Trial 9 finished with value: 0.9834909210407193 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 8 with value: 0.9839882158330232.\n",
      "[I 2025-11-27 03:00:53,287] Trial 10 finished with value: 0.9854664497368409 and parameters: {'d': 512, 'd_hidden_factor': 4.97088426861444, 'n_layers': 9, 'hidden_dropout': 0.004030571702010294, 'residual_dropout': 0.19485930498507747, 'learning_rate': 0.0006550956088886104, 'batch_size': 256, 'epochs': 196}. Best is trial 10 with value: 0.9854664497368409.\n",
      "[I 2025-11-27 03:02:37,446] Trial 11 finished with value: 0.9691411985863139 and parameters: {'d': 512, 'd_hidden_factor': 4.994248805807082, 'n_layers': 9, 'hidden_dropout': 0.010469431921434912, 'residual_dropout': 0.1906752818537771, 'learning_rate': 0.0009031472349418137, 'batch_size': 256, 'epochs': 198}. Best is trial 10 with value: 0.9854664497368409.\n",
      "[I 2025-11-27 03:04:33,944] Trial 12 finished with value: 0.9765193210348337 and parameters: {'d': 512, 'd_hidden_factor': 4.8961709895626155, 'n_layers': 8, 'hidden_dropout': 0.008038652206972724, 'residual_dropout': 0.004006859886477587, 'learning_rate': 0.0007635432584603426, 'batch_size': 256, 'epochs': 200}. Best is trial 10 with value: 0.9854664497368409.\n",
      "[I 2025-11-27 03:05:43,398] Trial 13 finished with value: 0.9488980042643911 and parameters: {'d': 512, 'd_hidden_factor': 4.386751592180583, 'n_layers': 8, 'hidden_dropout': 0.11074965551116456, 'residual_dropout': 0.17079518298973073, 'learning_rate': 0.007457580543907536, 'batch_size': 256, 'epochs': 163}. Best is trial 10 with value: 0.9854664497368409.\n",
      "[I 2025-11-27 03:06:24,804] Trial 14 finished with value: 0.9798180291673058 and parameters: {'d': 128, 'd_hidden_factor': 2.0489934704481887, 'n_layers': 8, 'hidden_dropout': 0.08633207785056744, 'residual_dropout': 0.26112477859973704, 'learning_rate': 6.669007789675228e-05, 'batch_size': 256, 'epochs': 166}. Best is trial 10 with value: 0.9854664497368409.\n",
      "[I 2025-11-27 03:07:52,885] Trial 15 finished with value: 0.9903158466679134 and parameters: {'d': 512, 'd_hidden_factor': 4.435014418587728, 'n_layers': 7, 'hidden_dropout': 0.0731544777239275, 'residual_dropout': 0.23414926391329935, 'learning_rate': 0.0004936383544051086, 'batch_size': 128, 'epochs': 168}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:09:52,105] Trial 16 finished with value: 0.9214604226330974 and parameters: {'d': 512, 'd_hidden_factor': 4.477623372223359, 'n_layers': 10, 'hidden_dropout': 0.07655408895870165, 'residual_dropout': 0.23522941064174924, 'learning_rate': 0.0005617893570977609, 'batch_size': 128, 'epochs': 163}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:11:13,379] Trial 17 finished with value: 0.9702657289580499 and parameters: {'d': 512, 'd_hidden_factor': 4.426874031416949, 'n_layers': 7, 'hidden_dropout': 0.14888886338659357, 'residual_dropout': 0.0998627456193413, 'learning_rate': 0.0004050466135465005, 'batch_size': 128, 'epochs': 144}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:12:38,811] Trial 18 finished with value: 0.9538191828565392 and parameters: {'d': 512, 'd_hidden_factor': 4.624484928682662, 'n_layers': 9, 'hidden_dropout': 0.054681788794640966, 'residual_dropout': 0.240849024602776, 'learning_rate': 0.001370120320492544, 'batch_size': 128, 'epochs': 180}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:14:00,167] Trial 19 finished with value: 0.9737893858924342 and parameters: {'d': 512, 'd_hidden_factor': 4.040747965850659, 'n_layers': 3, 'hidden_dropout': 0.17403227059959028, 'residual_dropout': 0.1164727265570033, 'learning_rate': 1.0094165165701898e-05, 'batch_size': 128, 'epochs': 144}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:15:15,896] Trial 20 finished with value: 0.9773713665756798 and parameters: {'d': 64, 'd_hidden_factor': 3.4607712390514846, 'n_layers': 7, 'hidden_dropout': 0.4202138733708044, 'residual_dropout': 0.022534357225195784, 'learning_rate': 0.00011985406109872162, 'batch_size': 128, 'epochs': 183}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:15:26,333] Trial 21 finished with value: 0.9684404891439387 and parameters: {'d': 128, 'd_hidden_factor': 3.4415273620207083, 'n_layers': 7, 'hidden_dropout': 0.02312212340434704, 'residual_dropout': 0.28135971254124686, 'learning_rate': 0.0026312807570427793, 'batch_size': 256, 'epochs': 183}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:15:42,830] Trial 22 finished with value: 0.9676663990356815 and parameters: {'d': 128, 'd_hidden_factor': 4.250523562189704, 'n_layers': 9, 'hidden_dropout': 0.04988164326266203, 'residual_dropout': 0.21025466726890574, 'learning_rate': 0.0017886918197600782, 'batch_size': 256, 'epochs': 199}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:16:23,221] Trial 23 finished with value: 0.9764922632933782 and parameters: {'d': 512, 'd_hidden_factor': 4.806200304645403, 'n_layers': 4, 'hidden_dropout': 0.10796776799958202, 'residual_dropout': 0.3972986163741464, 'learning_rate': 0.00026131742784044987, 'batch_size': 256, 'epochs': 151}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:16:59,698] Trial 24 finished with value: 0.9576607677275943 and parameters: {'d': 512, 'd_hidden_factor': 2.483678334676637, 'n_layers': 7, 'hidden_dropout': 0.049628365568243044, 'residual_dropout': 0.37958219789911474, 'learning_rate': 0.00426873721054136, 'batch_size': 256, 'epochs': 177}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:17:26,815] Trial 25 finished with value: 0.9873194452618836 and parameters: {'d': 128, 'd_hidden_factor': 4.157882051250973, 'n_layers': 8, 'hidden_dropout': 0.11710752730259673, 'residual_dropout': 0.49914583927651746, 'learning_rate': 0.0005134688498664188, 'batch_size': 256, 'epochs': 189}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:18:25,194] Trial 26 finished with value: 0.9830389031461386 and parameters: {'d': 64, 'd_hidden_factor': 4.071943260277661, 'n_layers': 9, 'hidden_dropout': 0.20801626055344982, 'residual_dropout': 0.13929232942287362, 'learning_rate': 0.00048305714100606577, 'batch_size': 128, 'epochs': 135}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:21:15,108] Trial 27 finished with value: 0.9812122421784574 and parameters: {'d': 256, 'd_hidden_factor': 4.717936491685158, 'n_layers': 8, 'hidden_dropout': 0.1276066977640887, 'residual_dropout': 0.29191293149076525, 'learning_rate': 0.0009076463087614984, 'batch_size': 32, 'epochs': 173}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:23:09,907] Trial 28 finished with value: 0.979467498474347 and parameters: {'d': 512, 'd_hidden_factor': 4.258721174942554, 'n_layers': 10, 'hidden_dropout': 0.20205105124801256, 'residual_dropout': 0.2251441399721786, 'learning_rate': 0.00016294788602355532, 'batch_size': 256, 'epochs': 155}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:23:25,764] Trial 29 finished with value: 0.3028656267096979 and parameters: {'d': 64, 'd_hidden_factor': 3.742286520918971, 'n_layers': 1, 'hidden_dropout': 0.49234790898426983, 'residual_dropout': 0.047879453888595935, 'learning_rate': 6.443314140892847e-05, 'batch_size': 128, 'epochs': 112}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:23:58,880] Trial 30 finished with value: 0.9646622732791552 and parameters: {'d': 128, 'd_hidden_factor': 4.664550348006755, 'n_layers': 5, 'hidden_dropout': 0.07823859810434786, 'residual_dropout': 0.19888355280756542, 'learning_rate': 0.0002897488534604902, 'batch_size': 128, 'epochs': 189}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:24:22,526] Trial 31 finished with value: 0.9836923507074262 and parameters: {'d': 128, 'd_hidden_factor': 3.304937393821171, 'n_layers': 7, 'hidden_dropout': 0.0004531295172239823, 'residual_dropout': 0.47815085236112675, 'learning_rate': 0.0005904471945286407, 'batch_size': 256, 'epochs': 190}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:24:37,099] Trial 32 finished with value: 0.9899854800298937 and parameters: {'d': 128, 'd_hidden_factor': 3.6628945105495543, 'n_layers': 6, 'hidden_dropout': 0.030784535158222937, 'residual_dropout': 0.4203251942231575, 'learning_rate': 0.001250742714967113, 'batch_size': 256, 'epochs': 169}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:24:47,986] Trial 33 finished with value: 0.9773318543287131 and parameters: {'d': 128, 'd_hidden_factor': 4.1031348027181105, 'n_layers': 5, 'hidden_dropout': 0.051686682804386916, 'residual_dropout': 0.46153813798296306, 'learning_rate': 0.0015003877168434721, 'batch_size': 256, 'epochs': 173}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:25:37,612] Trial 34 finished with value: 0.9729583692566777 and parameters: {'d': 128, 'd_hidden_factor': 3.6657751222633586, 'n_layers': 8, 'hidden_dropout': 0.03710041056791921, 'residual_dropout': 0.36928854948470624, 'learning_rate': 0.001091007923556028, 'batch_size': 64, 'epochs': 54}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:25:52,605] Trial 35 finished with value: 0.9893265891109803 and parameters: {'d': 128, 'd_hidden_factor': 3.856601091229404, 'n_layers': 6, 'hidden_dropout': 0.09721072977814373, 'residual_dropout': 0.45517898920831934, 'learning_rate': 0.002241649044279459, 'batch_size': 256, 'epochs': 155}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:26:44,761] Trial 36 finished with value: 0.9418680223277764 and parameters: {'d': 128, 'd_hidden_factor': 2.854996623754064, 'n_layers': 6, 'hidden_dropout': 0.1368866871288906, 'residual_dropout': 0.44794784908712204, 'learning_rate': 0.0020067573246561007, 'batch_size': 64, 'epochs': 151}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:28:01,525] Trial 37 finished with value: 0.9704842865145237 and parameters: {'d': 128, 'd_hidden_factor': 3.8192419023103232, 'n_layers': 4, 'hidden_dropout': 0.22781077365923727, 'residual_dropout': 0.4090572457199509, 'learning_rate': 0.0024517841765506992, 'batch_size': 32, 'epochs': 135}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:28:22,466] Trial 38 finished with value: 0.9839072172609777 and parameters: {'d': 128, 'd_hidden_factor': 3.162734078012112, 'n_layers': 6, 'hidden_dropout': 0.10097711220252369, 'residual_dropout': 0.3535641586035513, 'learning_rate': 0.0003916305981775504, 'batch_size': 256, 'epochs': 167}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:28:45,469] Trial 39 finished with value: 0.9854603549691247 and parameters: {'d': 128, 'd_hidden_factor': 3.6327373746080243, 'n_layers': 6, 'hidden_dropout': 0.17462858636987183, 'residual_dropout': 0.4236860526834867, 'learning_rate': 0.00020903420695100994, 'batch_size': 256, 'epochs': 115}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:29:44,723] Trial 40 finished with value: 0.9855272585024943 and parameters: {'d': 256, 'd_hidden_factor': 3.0662197513506957, 'n_layers': 5, 'hidden_dropout': 0.07758932202270474, 'residual_dropout': 0.32239783600486815, 'learning_rate': 0.0011470136768847285, 'batch_size': 32, 'epochs': 37}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:30:47,939] Trial 41 finished with value: 0.9777409777317067 and parameters: {'d': 256, 'd_hidden_factor': 2.651742376033653, 'n_layers': 5, 'hidden_dropout': 0.07354674755596124, 'residual_dropout': 0.4602865132655605, 'learning_rate': 0.0012249129178588368, 'batch_size': 32, 'epochs': 41}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:32:13,283] Trial 42 finished with value: 0.974656610708078 and parameters: {'d': 256, 'd_hidden_factor': 3.9792648501815293, 'n_layers': 4, 'hidden_dropout': 0.12203439067416857, 'residual_dropout': 0.32384174430954066, 'learning_rate': 0.0054643912516118736, 'batch_size': 32, 'epochs': 80}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:33:30,796] Trial 43 finished with value: 0.9673529921549087 and parameters: {'d': 256, 'd_hidden_factor': 3.1488245559467996, 'n_layers': 5, 'hidden_dropout': 0.3602707774251105, 'residual_dropout': 0.4835196240950849, 'learning_rate': 0.0009712701173026258, 'batch_size': 32, 'epochs': 56}. Best is trial 15 with value: 0.9903158466679134.\n",
      "[I 2025-11-27 03:35:22,784] Trial 44 finished with value: 0.9954479613370824 and parameters: {'d': 256, 'd_hidden_factor': 3.008551003500723, 'n_layers': 7, 'hidden_dropout': 0.08861296081028527, 'residual_dropout': 0.4355211012521983, 'learning_rate': 0.0025988067036759746, 'batch_size': 32, 'epochs': 66}. Best is trial 44 with value: 0.9954479613370824.\n",
      "[I 2025-11-27 03:36:10,100] Trial 45 finished with value: 0.9772671110833384 and parameters: {'d': 128, 'd_hidden_factor': 3.523337431556862, 'n_layers': 7, 'hidden_dropout': 0.03050178676502252, 'residual_dropout': 0.428399329403684, 'learning_rate': 0.0028540357282286735, 'batch_size': 64, 'epochs': 66}. Best is trial 44 with value: 0.9954479613370824.\n",
      "[I 2025-11-27 03:37:57,664] Trial 46 finished with value: 0.996634231987948 and parameters: {'d': 256, 'd_hidden_factor': 1.9451734361228792, 'n_layers': 6, 'hidden_dropout': 0.09924485140873582, 'residual_dropout': 0.3971813140181491, 'learning_rate': 0.0019114698762642767, 'batch_size': 32, 'epochs': 100}. Best is trial 46 with value: 0.996634231987948.\n",
      "[I 2025-11-27 03:40:01,091] Trial 47 finished with value: 0.9819143955607466 and parameters: {'d': 256, 'd_hidden_factor': 1.6956147360441225, 'n_layers': 6, 'hidden_dropout': 0.15823576311487356, 'residual_dropout': 0.39487758994044525, 'learning_rate': 0.003658363713440639, 'batch_size': 32, 'epochs': 107}. Best is trial 46 with value: 0.996634231987948.\n",
      "[I 2025-11-27 03:41:33,564] Trial 48 finished with value: 0.9816339885476829 and parameters: {'d': 256, 'd_hidden_factor': 1.0685865460835133, 'n_layers': 6, 'hidden_dropout': 0.09356238825575425, 'residual_dropout': 0.3552786287712475, 'learning_rate': 0.001958543324328008, 'batch_size': 32, 'epochs': 81}. Best is trial 46 with value: 0.996634231987948.\n",
      "[I 2025-11-27 03:43:36,703] Trial 49 finished with value: 0.963104975895307 and parameters: {'d': 256, 'd_hidden_factor': 2.2138120125750747, 'n_layers': 7, 'hidden_dropout': 0.2590059255608431, 'residual_dropout': 0.4536640798404976, 'learning_rate': 0.006295607954020807, 'batch_size': 32, 'epochs': 93}. Best is trial 46 with value: 0.996634231987948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 3397.87s\n",
      "  Best CV G-Mean: 0.9966\n",
      "  Best parameters:\n",
      "    d: 256\n",
      "    d_hidden_factor: 1.9451734361228792\n",
      "    n_layers: 6\n",
      "    hidden_dropout: 0.09924485140873582\n",
      "    residual_dropout: 0.3971813140181491\n",
      "    learning_rate: 0.0019114698762642767\n",
      "    batch_size: 32\n",
      "    epochs: 100\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/100: Train Loss = 0.1083, Val Loss = 0.1574\n",
      "    Epoch 20/100: Train Loss = 0.0748, Val Loss = 0.0376\n",
      "    Epoch 30/100: Train Loss = 0.0362, Val Loss = 0.0298\n",
      "    Epoch 40/100: Train Loss = 0.0297, Val Loss = 0.0210\n",
      "    Epoch 50/100: Train Loss = 0.0288, Val Loss = 0.1084\n",
      "    Epoch 60/100: Train Loss = 0.0181, Val Loss = 0.0422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 03:43:48,170] A new study created in memory with name: no-name-d88bde42-4dc7-4778-adbb-3e5dcd2c3b64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Early stopping at epoch 67\n",
      "✓ Training complete! Time: 11.45s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR car\n",
      "================================================================================\n",
      "Accuracy:        0.9884\n",
      "AUC OVO:         0.9998\n",
      "G-Mean:          0.9713\n",
      "Cross-Entropy:   0.0278\n",
      "================================================================================\n",
      "✓ Saved results for car\n",
      "\n",
      "✓ Completed car (7/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 8/30: vehicle\n",
      "################################################################################\n",
      "Loading processed dataset from cache: vehicle\n",
      "Using device: cuda\n",
      "Dataset: vehicle\n",
      "  Train: (592, 18), Test: (254, 18)\n",
      "  Features: 18, Classes: 4\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: vehicle\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 03:43:55,245] Trial 0 finished with value: 0.7658490401430743 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.7658490401430743.\n",
      "[I 2025-11-27 03:44:13,307] Trial 1 finished with value: 0.8207076658199954 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.8207076658199954.\n",
      "[I 2025-11-27 03:44:29,334] Trial 2 finished with value: 0.8319052730494503 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 2 with value: 0.8319052730494503.\n",
      "[I 2025-11-27 03:46:16,685] Trial 3 finished with value: 0.8345756079093174 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.8345756079093174.\n",
      "[I 2025-11-27 03:46:35,472] Trial 4 finished with value: 0.7874747938642599 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 3 with value: 0.8345756079093174.\n",
      "[I 2025-11-27 03:47:47,953] Trial 5 finished with value: 0.7955865932307892 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 3 with value: 0.8345756079093174.\n",
      "[I 2025-11-27 03:48:42,445] Trial 6 finished with value: 0.7856168846440916 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 3 with value: 0.8345756079093174.\n",
      "[I 2025-11-27 03:48:51,886] Trial 7 finished with value: 0.7924244000184061 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 3 with value: 0.8345756079093174.\n",
      "[I 2025-11-27 03:48:56,350] Trial 8 finished with value: 0.8237540149661502 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 3 with value: 0.8345756079093174.\n",
      "[I 2025-11-27 03:48:59,593] Trial 9 finished with value: 0.8290372063197188 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 3 with value: 0.8345756079093174.\n",
      "[I 2025-11-27 03:51:32,610] Trial 10 finished with value: 0.8459410713867523 and parameters: {'d': 256, 'd_hidden_factor': 4.956401873386991, 'n_layers': 10, 'hidden_dropout': 0.10467358725545478, 'residual_dropout': 0.21319384192877996, 'learning_rate': 1.0455868741494775e-05, 'batch_size': 32, 'epochs': 159}. Best is trial 10 with value: 0.8459410713867523.\n",
      "[I 2025-11-27 03:54:23,647] Trial 11 finished with value: 0.8318103180950034 and parameters: {'d': 256, 'd_hidden_factor': 4.978541460939402, 'n_layers': 10, 'hidden_dropout': 0.08723353405849409, 'residual_dropout': 0.22944464268646939, 'learning_rate': 1.0158320577860581e-05, 'batch_size': 32, 'epochs': 171}. Best is trial 10 with value: 0.8459410713867523.\n",
      "[I 2025-11-27 03:56:04,078] Trial 12 finished with value: 0.8364806450177275 and parameters: {'d': 256, 'd_hidden_factor': 4.700322375404564, 'n_layers': 10, 'hidden_dropout': 0.13399100690564741, 'residual_dropout': 0.22988626022427197, 'learning_rate': 3.551819509547847e-05, 'batch_size': 32, 'epochs': 150}. Best is trial 10 with value: 0.8459410713867523.\n",
      "[I 2025-11-27 03:57:21,925] Trial 13 finished with value: 0.8356402959683782 and parameters: {'d': 256, 'd_hidden_factor': 4.891319939487838, 'n_layers': 8, 'hidden_dropout': 0.10315617108555222, 'residual_dropout': 0.1925086337595997, 'learning_rate': 3.372458017497115e-05, 'batch_size': 32, 'epochs': 153}. Best is trial 10 with value: 0.8459410713867523.\n",
      "[I 2025-11-27 03:57:45,440] Trial 14 finished with value: 0.8196084663807348 and parameters: {'d': 512, 'd_hidden_factor': 4.356442301816642, 'n_layers': 8, 'hidden_dropout': 0.0035697594234744834, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 7.376487017206706e-05, 'batch_size': 128, 'epochs': 152}. Best is trial 10 with value: 0.8459410713867523.\n",
      "[I 2025-11-27 03:59:40,391] Trial 15 finished with value: 0.8508665262523802 and parameters: {'d': 256, 'd_hidden_factor': 4.461226410456492, 'n_layers': 8, 'hidden_dropout': 0.11416813325319607, 'residual_dropout': 0.13086349045080098, 'learning_rate': 1.201880159180346e-05, 'batch_size': 32, 'epochs': 181}. Best is trial 15 with value: 0.8508665262523802.\n",
      "[I 2025-11-27 04:01:33,926] Trial 16 finished with value: 0.8362070149358898 and parameters: {'d': 256, 'd_hidden_factor': 4.319529342708191, 'n_layers': 8, 'hidden_dropout': 0.06158675232741449, 'residual_dropout': 0.12312182169098496, 'learning_rate': 1.000149903440009e-05, 'batch_size': 32, 'epochs': 198}. Best is trial 15 with value: 0.8508665262523802.\n",
      "[I 2025-11-27 04:02:27,674] Trial 17 finished with value: 0.81537312134833 and parameters: {'d': 256, 'd_hidden_factor': 4.389079240651879, 'n_layers': 9, 'hidden_dropout': 0.1924860212067292, 'residual_dropout': 0.04518719890844869, 'learning_rate': 0.0010923680207712567, 'batch_size': 32, 'epochs': 174}. Best is trial 15 with value: 0.8508665262523802.\n",
      "[I 2025-11-27 04:02:51,857] Trial 18 finished with value: 0.8268364742029256 and parameters: {'d': 512, 'd_hidden_factor': 4.409271365671797, 'n_layers': 9, 'hidden_dropout': 0.04870716490212297, 'residual_dropout': 0.12885933660094656, 'learning_rate': 0.0006026117646786481, 'batch_size': 256, 'epochs': 177}. Best is trial 15 with value: 0.8508665262523802.\n",
      "[I 2025-11-27 04:03:22,386] Trial 19 finished with value: 0.6621645148820574 and parameters: {'d': 64, 'd_hidden_factor': 2.30503287083166, 'n_layers': 7, 'hidden_dropout': 0.14033415847871888, 'residual_dropout': 0.2669582138395935, 'learning_rate': 1.662870365429092e-05, 'batch_size': 128, 'epochs': 136}. Best is trial 15 with value: 0.8508665262523802.\n",
      "[I 2025-11-27 04:04:55,650] Trial 20 finished with value: 0.8457965687737353 and parameters: {'d': 256, 'd_hidden_factor': 3.6123411992688865, 'n_layers': 9, 'hidden_dropout': 0.4202138733708044, 'residual_dropout': 0.17633652085266532, 'learning_rate': 7.610613900280256e-05, 'batch_size': 32, 'epochs': 178}. Best is trial 15 with value: 0.8508665262523802.\n",
      "[I 2025-11-27 04:06:22,758] Trial 21 finished with value: 0.8513229095537984 and parameters: {'d': 256, 'd_hidden_factor': 3.5106345126128606, 'n_layers': 9, 'hidden_dropout': 0.4144129056146933, 'residual_dropout': 0.19105411087681695, 'learning_rate': 7.40930135776802e-05, 'batch_size': 32, 'epochs': 184}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:08:14,405] Trial 22 finished with value: 0.8358594203266152 and parameters: {'d': 256, 'd_hidden_factor': 4.0852771300266895, 'n_layers': 9, 'hidden_dropout': 0.4844957098196773, 'residual_dropout': 0.10375434873034042, 'learning_rate': 5.245896102875524e-05, 'batch_size': 32, 'epochs': 188}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:10:19,892] Trial 23 finished with value: 0.8387133029146577 and parameters: {'d': 256, 'd_hidden_factor': 4.795791692711351, 'n_layers': 7, 'hidden_dropout': 0.3757297005347553, 'residual_dropout': 0.2042256322513529, 'learning_rate': 1.8981837480296846e-05, 'batch_size': 32, 'epochs': 161}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:11:30,068] Trial 24 finished with value: 0.8336118970706016 and parameters: {'d': 256, 'd_hidden_factor': 3.5101505768555805, 'n_layers': 10, 'hidden_dropout': 0.21097953620427298, 'residual_dropout': 0.27757682138175754, 'learning_rate': 0.00014485685601361845, 'batch_size': 32, 'epochs': 138}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:14:02,932] Trial 25 finished with value: 0.8333917573743234 and parameters: {'d': 256, 'd_hidden_factor': 4.5054607252958565, 'n_layers': 8, 'hidden_dropout': 0.4148503700694102, 'residual_dropout': 0.07148519157645067, 'learning_rate': 1.4616547193563435e-05, 'batch_size': 32, 'epochs': 187}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:14:58,342] Trial 26 finished with value: 0.8285744353804357 and parameters: {'d': 256, 'd_hidden_factor': 3.9444694589927214, 'n_layers': 7, 'hidden_dropout': 0.10987927877962916, 'residual_dropout': 0.15525591672728312, 'learning_rate': 5.556650903460246e-05, 'batch_size': 32, 'epochs': 157}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:15:24,277] Trial 27 finished with value: 0.8301493382234508 and parameters: {'d': 512, 'd_hidden_factor': 4.6605816276926895, 'n_layers': 9, 'hidden_dropout': 0.17794205149320252, 'residual_dropout': 0.21046920192738727, 'learning_rate': 0.0005493668147985225, 'batch_size': 256, 'epochs': 163}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:16:49,339] Trial 28 finished with value: 0.8070404870390819 and parameters: {'d': 64, 'd_hidden_factor': 2.684512286420324, 'n_layers': 3, 'hidden_dropout': 0.22420518941062137, 'residual_dropout': 0.2512874142131109, 'learning_rate': 4.2019972721958786e-05, 'batch_size': 32, 'epochs': 188}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:16:57,281] Trial 29 finished with value: 0.8162831097260966 and parameters: {'d': 64, 'd_hidden_factor': 3.7837536320076266, 'n_layers': 1, 'hidden_dropout': 0.4941992611798381, 'residual_dropout': 0.15695381838585146, 'learning_rate': 0.0003119454361632236, 'batch_size': 128, 'epochs': 109}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:17:12,035] Trial 30 finished with value: 0.8404158950978202 and parameters: {'d': 256, 'd_hidden_factor': 4.154540718024309, 'n_layers': 10, 'hidden_dropout': 0.04827331863779988, 'residual_dropout': 0.013707820427878964, 'learning_rate': 9.230033803330581e-05, 'batch_size': 128, 'epochs': 142}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:18:20,526] Trial 31 finished with value: 0.8359801240993916 and parameters: {'d': 256, 'd_hidden_factor': 3.481261439326515, 'n_layers': 9, 'hidden_dropout': 0.45035897612396586, 'residual_dropout': 0.18767467380565314, 'learning_rate': 0.00021053976945233826, 'batch_size': 32, 'epochs': 180}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:21:13,992] Trial 32 finished with value: 0.8377027291093455 and parameters: {'d': 256, 'd_hidden_factor': 3.3665076889610095, 'n_layers': 8, 'hidden_dropout': 0.41265026475682953, 'residual_dropout': 0.17436786573374444, 'learning_rate': 1.4797219999249465e-05, 'batch_size': 32, 'epochs': 166}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:22:33,746] Trial 33 finished with value: 0.848111421186935 and parameters: {'d': 256, 'd_hidden_factor': 2.9308330552078896, 'n_layers': 9, 'hidden_dropout': 0.40465149480184437, 'residual_dropout': 0.12165779148078039, 'learning_rate': 7.170727022106389e-05, 'batch_size': 32, 'epochs': 200}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:24:20,119] Trial 34 finished with value: 0.823429104621346 and parameters: {'d': 128, 'd_hidden_factor': 2.9831467121623354, 'n_layers': 10, 'hidden_dropout': 0.3536254582683048, 'residual_dropout': 0.12379107959369597, 'learning_rate': 2.580456584535784e-05, 'batch_size': 64, 'epochs': 200}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:24:59,828] Trial 35 finished with value: 0.8170857230459493 and parameters: {'d': 256, 'd_hidden_factor': 2.43619724413354, 'n_layers': 7, 'hidden_dropout': 0.2470137667663977, 'residual_dropout': 0.08712358631309855, 'learning_rate': 0.00044112631962879486, 'batch_size': 32, 'epochs': 50}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:25:33,884] Trial 36 finished with value: 0.8324441195487635 and parameters: {'d': 256, 'd_hidden_factor': 1.952781506211608, 'n_layers': 9, 'hidden_dropout': 0.3827090132973296, 'residual_dropout': 0.294286904411413, 'learning_rate': 0.0001718066162811106, 'batch_size': 64, 'epochs': 189}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:27:29,383] Trial 37 finished with value: 0.8239556084023902 and parameters: {'d': 128, 'd_hidden_factor': 2.7726966246232987, 'n_layers': 5, 'hidden_dropout': 0.4612660861876555, 'residual_dropout': 0.04475605662477844, 'learning_rate': 2.226157972246252e-05, 'batch_size': 32, 'epochs': 185}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:29:10,695] Trial 38 finished with value: 0.8399695827020024 and parameters: {'d': 256, 'd_hidden_factor': 3.185699427273519, 'n_layers': 10, 'hidden_dropout': 0.33764087692496914, 'residual_dropout': 0.12638016894151916, 'learning_rate': 5.000745042450115e-05, 'batch_size': 32, 'epochs': 168}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:30:28,679] Trial 39 finished with value: 0.7901864262964948 and parameters: {'d': 256, 'd_hidden_factor': 3.132452590784787, 'n_layers': 8, 'hidden_dropout': 0.28252281608986085, 'residual_dropout': 0.3875606768790699, 'learning_rate': 1.2483777866829874e-05, 'batch_size': 32, 'epochs': 70}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:30:48,025] Trial 40 finished with value: 0.8348172550200594 and parameters: {'d': 64, 'd_hidden_factor': 1.9550130026843053, 'n_layers': 7, 'hidden_dropout': 0.1540093860443496, 'residual_dropout': 0.1505794337887787, 'learning_rate': 0.0011470136768847285, 'batch_size': 64, 'epochs': 193}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:32:12,246] Trial 41 finished with value: 0.8342326077174042 and parameters: {'d': 256, 'd_hidden_factor': 3.650180684103452, 'n_layers': 9, 'hidden_dropout': 0.422075785844682, 'residual_dropout': 0.17598193126933948, 'learning_rate': 0.00010814681309043476, 'batch_size': 32, 'epochs': 179}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:33:43,530] Trial 42 finished with value: 0.8383768455283246 and parameters: {'d': 256, 'd_hidden_factor': 4.633104299333299, 'n_layers': 9, 'hidden_dropout': 0.4522616552171718, 'residual_dropout': 0.2211866394583776, 'learning_rate': 7.618078248659067e-05, 'batch_size': 32, 'epochs': 178}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:35:00,911] Trial 43 finished with value: 0.8290450197251596 and parameters: {'d': 256, 'd_hidden_factor': 4.153368994618084, 'n_layers': 10, 'hidden_dropout': 0.38081446787945356, 'residual_dropout': 0.2382826841996601, 'learning_rate': 0.0002549948797819561, 'batch_size': 32, 'epochs': 170}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:37:06,697] Trial 44 finished with value: 0.8375638976159306 and parameters: {'d': 256, 'd_hidden_factor': 2.811899514471631, 'n_layers': 8, 'hidden_dropout': 0.4321607914049669, 'residual_dropout': 0.10298483268767224, 'learning_rate': 2.7974089951325668e-05, 'batch_size': 32, 'epochs': 195}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:37:35,440] Trial 45 finished with value: 0.8313221154336942 and parameters: {'d': 128, 'd_hidden_factor': 4.944660794231339, 'n_layers': 10, 'hidden_dropout': 0.4007017387088896, 'residual_dropout': 0.1455062734006041, 'learning_rate': 6.057166814162022e-05, 'batch_size': 256, 'epochs': 182}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:38:40,140] Trial 46 finished with value: 0.846845603115623 and parameters: {'d': 512, 'd_hidden_factor': 2.5494797443526354, 'n_layers': 4, 'hidden_dropout': 0.3315225850962846, 'residual_dropout': 0.17016527728375225, 'learning_rate': 3.483086563472719e-05, 'batch_size': 32, 'epochs': 146}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:39:40,745] Trial 47 finished with value: 0.8468535768414889 and parameters: {'d': 512, 'd_hidden_factor': 2.5478417876490815, 'n_layers': 4, 'hidden_dropout': 0.334468551426029, 'residual_dropout': 0.06087006461644365, 'learning_rate': 3.728713204026938e-05, 'batch_size': 32, 'epochs': 127}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:40:42,087] Trial 48 finished with value: 0.8401307643150275 and parameters: {'d': 512, 'd_hidden_factor': 2.5292838222314096, 'n_layers': 4, 'hidden_dropout': 0.3167971423515251, 'residual_dropout': 0.05662006689048954, 'learning_rate': 3.972913997016003e-05, 'batch_size': 32, 'epochs': 113}. Best is trial 21 with value: 0.8513229095537984.\n",
      "[I 2025-11-27 04:41:55,419] Trial 49 finished with value: 0.8552907262742171 and parameters: {'d': 512, 'd_hidden_factor': 1.9966673641244546, 'n_layers': 4, 'hidden_dropout': 0.3370324956591667, 'residual_dropout': 0.08425054757256112, 'learning_rate': 2.2706013051919557e-05, 'batch_size': 32, 'epochs': 124}. Best is trial 49 with value: 0.8552907262742171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 3487.25s\n",
      "  Best CV G-Mean: 0.8553\n",
      "  Best parameters:\n",
      "    d: 512\n",
      "    d_hidden_factor: 1.9966673641244546\n",
      "    n_layers: 4\n",
      "    hidden_dropout: 0.3370324956591667\n",
      "    residual_dropout: 0.08425054757256112\n",
      "    learning_rate: 2.2706013051919557e-05\n",
      "    batch_size: 32\n",
      "    epochs: 124\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/124: Train Loss = 0.5753, Val Loss = 0.5208\n",
      "    Epoch 20/124: Train Loss = 0.4113, Val Loss = 0.3697\n",
      "    Epoch 30/124: Train Loss = 0.3482, Val Loss = 0.3292\n",
      "    Epoch 40/124: Train Loss = 0.3212, Val Loss = 0.2939\n",
      "    Epoch 50/124: Train Loss = 0.2637, Val Loss = 0.2730\n",
      "    Epoch 60/124: Train Loss = 0.2416, Val Loss = 0.2531\n",
      "    Epoch 70/124: Train Loss = 0.2395, Val Loss = 0.2444\n",
      "    Epoch 80/124: Train Loss = 0.2086, Val Loss = 0.2399\n",
      "    Epoch 90/124: Train Loss = 0.1887, Val Loss = 0.2146\n",
      "    Epoch 100/124: Train Loss = 0.1619, Val Loss = 0.2073\n",
      "    Epoch 110/124: Train Loss = 0.1794, Val Loss = 0.2103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 04:42:04,911] A new study created in memory with name: no-name-5d144a57-8bbb-4cd8-ab48-44bdce66f768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Early stopping at epoch 114\n",
      "✓ Training complete! Time: 9.48s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR vehicle\n",
      "================================================================================\n",
      "Accuracy:        0.8268\n",
      "AUC OVO:         0.9621\n",
      "G-Mean:          0.8096\n",
      "Cross-Entropy:   0.3877\n",
      "================================================================================\n",
      "✓ Saved results for vehicle\n",
      "\n",
      "✓ Completed vehicle (8/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 9/30: breast-w\n",
      "################################################################################\n",
      "Loading processed dataset from cache: breast-w\n",
      "Using device: cuda\n",
      "Dataset: breast-w\n",
      "  Train: (489, 9), Test: (210, 9)\n",
      "  Features: 9, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: breast-w\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 04:42:10,355] Trial 0 finished with value: 0.9770070294658163 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:42:17,297] Trial 1 finished with value: 0.9632260146518874 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:42:27,760] Trial 2 finished with value: 0.9655452965824537 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:43:19,997] Trial 3 finished with value: 0.9627770770142664 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:43:28,828] Trial 4 finished with value: 0.9724677873339296 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:44:25,663] Trial 5 finished with value: 0.9689479493652027 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:45:08,443] Trial 6 finished with value: 0.9689479493652027 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:45:12,643] Trial 7 finished with value: 0.969430322409311 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:45:15,025] Trial 8 finished with value: 0.9765752248633268 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:45:16,287] Trial 9 finished with value: 0.9675109992105464 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:45:27,139] Trial 10 finished with value: 0.9659621993797358 and parameters: {'d': 64, 'd_hidden_factor': 4.982751445203364, 'n_layers': 9, 'hidden_dropout': 0.4730853252665121, 'residual_dropout': 0.20864544555392683, 'learning_rate': 0.0006039122933759166, 'batch_size': 128, 'epochs': 161}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:45:32,162] Trial 11 finished with value: 0.9720285557169633 and parameters: {'d': 64, 'd_hidden_factor': 4.233138003575574, 'n_layers': 8, 'hidden_dropout': 0.010476594631962113, 'residual_dropout': 0.49630128216301855, 'learning_rate': 0.0006248875912195204, 'batch_size': 256, 'epochs': 198}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:45:40,535] Trial 12 finished with value: 0.9693872273554088 and parameters: {'d': 512, 'd_hidden_factor': 4.576233003303846, 'n_layers': 4, 'hidden_dropout': 0.008038652206972724, 'residual_dropout': 0.40474590114901277, 'learning_rate': 8.012285241153539e-05, 'batch_size': 128, 'epochs': 31}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:45:48,168] Trial 13 finished with value: 0.9657628269997331 and parameters: {'d': 64, 'd_hidden_factor': 3.5353949187885902, 'n_layers': 8, 'hidden_dropout': 0.48342117072785645, 'residual_dropout': 0.264502045419298, 'learning_rate': 0.0004658473533614093, 'batch_size': 256, 'epochs': 197}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:45:51,749] Trial 14 finished with value: 0.9769082919031223 and parameters: {'d': 128, 'd_hidden_factor': 2.3579113600319364, 'n_layers': 4, 'hidden_dropout': 0.09540458565148313, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 0.0018452575073373625, 'batch_size': 128, 'epochs': 157}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:45:54,110] Trial 15 finished with value: 0.9706305835810773 and parameters: {'d': 128, 'd_hidden_factor': 2.0569073695729587, 'n_layers': 1, 'hidden_dropout': 0.12068678595384502, 'residual_dropout': 0.023829386218252563, 'learning_rate': 0.0016427055372210378, 'batch_size': 128, 'epochs': 145}. Best is trial 0 with value: 0.9770070294658163.\n",
      "[I 2025-11-27 04:46:13,521] Trial 16 finished with value: 0.9830255984335322 and parameters: {'d': 64, 'd_hidden_factor': 2.395402113706958, 'n_layers': 4, 'hidden_dropout': 0.39090868317026173, 'residual_dropout': 0.1488236073281246, 'learning_rate': 1.001781929603626e-05, 'batch_size': 128, 'epochs': 170}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:46:26,923] Trial 17 finished with value: 0.8960229505885335 and parameters: {'d': 64, 'd_hidden_factor': 1.8749007169849068, 'n_layers': 3, 'hidden_dropout': 0.40340922847174, 'residual_dropout': 0.14837473819610625, 'learning_rate': 1.1016598219611525e-05, 'batch_size': 128, 'epochs': 177}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:46:37,670] Trial 18 finished with value: 0.9786546132325608 and parameters: {'d': 64, 'd_hidden_factor': 2.58129515325197, 'n_layers': 7, 'hidden_dropout': 0.41724295687608554, 'residual_dropout': 0.22594306843997852, 'learning_rate': 4.86346650401307e-05, 'batch_size': 128, 'epochs': 62}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:46:48,472] Trial 19 finished with value: 0.9770540984625986 and parameters: {'d': 64, 'd_hidden_factor': 2.5863016454901935, 'n_layers': 7, 'hidden_dropout': 0.42762173116430013, 'residual_dropout': 0.18680825356811934, 'learning_rate': 3.797979828396252e-05, 'batch_size': 128, 'epochs': 62}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:47:08,733] Trial 20 finished with value: 0.9570446917834436 and parameters: {'d': 64, 'd_hidden_factor': 1.6872601090384274, 'n_layers': 8, 'hidden_dropout': 0.40702880666937247, 'residual_dropout': 0.10426691307577787, 'learning_rate': 1.1465344738688203e-05, 'batch_size': 128, 'epochs': 114}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:47:19,984] Trial 21 finished with value: 0.9708480854480459 and parameters: {'d': 64, 'd_hidden_factor': 2.6028189993987305, 'n_layers': 7, 'hidden_dropout': 0.4158763838622698, 'residual_dropout': 0.21448001680663442, 'learning_rate': 4.550345196142292e-05, 'batch_size': 128, 'epochs': 65}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:47:30,228] Trial 22 finished with value: 0.973973492110838 and parameters: {'d': 64, 'd_hidden_factor': 2.5737507862780826, 'n_layers': 7, 'hidden_dropout': 0.3640465770302958, 'residual_dropout': 0.18231685868640568, 'learning_rate': 2.3006482425902198e-05, 'batch_size': 128, 'epochs': 59}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:47:43,420] Trial 23 finished with value: 0.975501371062148 and parameters: {'d': 64, 'd_hidden_factor': 2.9480859860131887, 'n_layers': 7, 'hidden_dropout': 0.4402402028393554, 'residual_dropout': 0.24858261413121133, 'learning_rate': 4.263020894342436e-05, 'batch_size': 128, 'epochs': 76}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:48:05,001] Trial 24 finished with value: 0.9690428057314966 and parameters: {'d': 512, 'd_hidden_factor': 1.624942972561098, 'n_layers': 10, 'hidden_dropout': 0.3630612305644981, 'residual_dropout': 0.12151727177651862, 'learning_rate': 1.7374690190060364e-05, 'batch_size': 128, 'epochs': 109}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:48:15,786] Trial 25 finished with value: 0.9740212794803493 and parameters: {'d': 64, 'd_hidden_factor': 2.347028663694919, 'n_layers': 9, 'hidden_dropout': 0.4558270321979455, 'residual_dropout': 0.06814648978191123, 'learning_rate': 6.737597295390749e-05, 'batch_size': 128, 'epochs': 51}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:48:33,091] Trial 26 finished with value: 0.975406514695854 and parameters: {'d': 64, 'd_hidden_factor': 2.05734171018056, 'n_layers': 5, 'hidden_dropout': 0.383227434273095, 'residual_dropout': 0.2348845668144476, 'learning_rate': 0.00014773520282920362, 'batch_size': 128, 'epochs': 135}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:48:50,089] Trial 27 finished with value: 0.9769122194727624 and parameters: {'d': 64, 'd_hidden_factor': 3.2157872792695383, 'n_layers': 3, 'hidden_dropout': 0.2197184264862369, 'residual_dropout': 0.29191293149076525, 'learning_rate': 4.356809699286477e-05, 'batch_size': 128, 'epochs': 181}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:49:44,154] Trial 28 finished with value: 0.9755483936856904 and parameters: {'d': 64, 'd_hidden_factor': 2.7215910354280326, 'n_layers': 7, 'hidden_dropout': 0.4387403163727939, 'residual_dropout': 0.18365882669895467, 'learning_rate': 1.683259181163912e-05, 'batch_size': 32, 'epochs': 79}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:49:49,208] Trial 29 finished with value: 0.9800398484480655 and parameters: {'d': 64, 'd_hidden_factor': 1.2919197370714615, 'n_layers': 5, 'hidden_dropout': 0.49560608860278665, 'residual_dropout': 0.14578328188939782, 'learning_rate': 0.0002909513075674524, 'batch_size': 128, 'epochs': 37}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:49:52,150] Trial 30 finished with value: 0.973581283117414 and parameters: {'d': 256, 'd_hidden_factor': 1.1630434247412822, 'n_layers': 3, 'hidden_dropout': 0.49537181150099807, 'residual_dropout': 0.12897660418092483, 'learning_rate': 0.0002897488534604902, 'batch_size': 128, 'epochs': 32}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:49:57,960] Trial 31 finished with value: 0.9755740068808001 and parameters: {'d': 64, 'd_hidden_factor': 1.3901587913576179, 'n_layers': 5, 'hidden_dropout': 0.49705242576803693, 'residual_dropout': 0.18058115182278553, 'learning_rate': 7.950928621978179e-05, 'batch_size': 128, 'epochs': 43}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:50:05,326] Trial 32 finished with value: 0.9771018858321101 and parameters: {'d': 64, 'd_hidden_factor': 1.988578227720695, 'n_layers': 5, 'hidden_dropout': 0.4354114839112426, 'residual_dropout': 0.07724847962223934, 'learning_rate': 0.00020860010110117244, 'batch_size': 128, 'epochs': 54}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:50:12,668] Trial 33 finished with value: 0.975501371062148 and parameters: {'d': 64, 'd_hidden_factor': 1.7317824179149022, 'n_layers': 5, 'hidden_dropout': 0.4656144053810931, 'residual_dropout': 0.06717636322896312, 'learning_rate': 0.00021109775044977883, 'batch_size': 128, 'epochs': 54}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:50:19,706] Trial 34 finished with value: 0.9692453483655727 and parameters: {'d': 64, 'd_hidden_factor': 1.9257689311878776, 'n_layers': 4, 'hidden_dropout': 0.32631487231592166, 'residual_dropout': 0.03854914973773142, 'learning_rate': 0.0009819735173651556, 'batch_size': 64, 'epochs': 36}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:50:25,553] Trial 35 finished with value: 0.9693872273554088 and parameters: {'d': 512, 'd_hidden_factor': 1.490215053090848, 'n_layers': 6, 'hidden_dropout': 0.3954468324275554, 'residual_dropout': 0.10183089373655207, 'learning_rate': 0.0003455821973027385, 'batch_size': 128, 'epochs': 45}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:50:44,128] Trial 36 finished with value: 0.9784871210476147 and parameters: {'d': 64, 'd_hidden_factor': 1.2422424564991248, 'n_layers': 5, 'hidden_dropout': 0.4542386754433342, 'residual_dropout': 0.13603877214027577, 'learning_rate': 0.00012720132005049497, 'batch_size': 64, 'epochs': 74}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:50:58,566] Trial 37 finished with value: 0.9722213923303846 and parameters: {'d': 256, 'd_hidden_factor': 1.006516672607298, 'n_layers': 6, 'hidden_dropout': 0.3395327492886806, 'residual_dropout': 0.13769384546036142, 'learning_rate': 0.00011065931349557889, 'batch_size': 64, 'epochs': 75}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:51:17,532] Trial 38 finished with value: 0.9802295148074132 and parameters: {'d': 64, 'd_hidden_factor': 1.2678211825927301, 'n_layers': 4, 'hidden_dropout': 0.3784471026748874, 'residual_dropout': 0.1645779243884059, 'learning_rate': 6.168109042224515e-05, 'batch_size': 64, 'epochs': 87}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:51:36,931] Trial 39 finished with value: 0.9770540984625986 and parameters: {'d': 64, 'd_hidden_factor': 2.347931305823011, 'n_layers': 4, 'hidden_dropout': 0.28807775239985467, 'residual_dropout': 0.2902678242723033, 'learning_rate': 2.3699524412434865e-05, 'batch_size': 64, 'epochs': 89}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:51:53,890] Trial 40 finished with value: 0.9659621993797358 and parameters: {'d': 256, 'd_hidden_factor': 1.3010026699318775, 'n_layers': 2, 'hidden_dropout': 0.2574856719881001, 'residual_dropout': 0.21722164035567637, 'learning_rate': 6.277578635224318e-05, 'batch_size': 32, 'epochs': 105}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:52:05,911] Trial 41 finished with value: 0.9816147500229178 and parameters: {'d': 64, 'd_hidden_factor': 1.2973384624309259, 'n_layers': 3, 'hidden_dropout': 0.3768172638938507, 'residual_dropout': 0.15310144274193888, 'learning_rate': 0.0001162615301519748, 'batch_size': 64, 'epochs': 67}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:52:21,266] Trial 42 finished with value: 0.9753117047028003 and parameters: {'d': 64, 'd_hidden_factor': 1.543163618641577, 'n_layers': 3, 'hidden_dropout': 0.3691673067940329, 'residual_dropout': 0.15875614651826103, 'learning_rate': 0.00016089495177097548, 'batch_size': 64, 'epochs': 87}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:52:36,164] Trial 43 finished with value: 0.978629000037451 and parameters: {'d': 64, 'd_hidden_factor': 1.0291893034248942, 'n_layers': 4, 'hidden_dropout': 0.33703602176786385, 'residual_dropout': 0.16138046621106705, 'learning_rate': 9.735321122249785e-05, 'batch_size': 64, 'epochs': 69}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:52:44,411] Trial 44 finished with value: 0.9723729773408758 and parameters: {'d': 128, 'd_hidden_factor': 3.1037498262871135, 'n_layers': 3, 'hidden_dropout': 0.3938718998284394, 'residual_dropout': 0.10283145170016092, 'learning_rate': 0.0003940638945472691, 'batch_size': 64, 'epochs': 98}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:52:50,922] Trial 45 finished with value: 0.9755262195112886 and parameters: {'d': 64, 'd_hidden_factor': 1.7982397547760463, 'n_layers': 2, 'hidden_dropout': 0.3171384545336224, 'residual_dropout': 0.26429012600168933, 'learning_rate': 5.719199893696192e-05, 'batch_size': 64, 'epochs': 45}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:53:01,311] Trial 46 finished with value: 0.970617707306349 and parameters: {'d': 512, 'd_hidden_factor': 3.434741635608068, 'n_layers': 6, 'hidden_dropout': 0.3797594343775795, 'residual_dropout': 0.20286670184035968, 'learning_rate': 3.21748302902315e-05, 'batch_size': 256, 'epochs': 68}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:53:11,781] Trial 47 finished with value: 0.9753117047028003 and parameters: {'d': 64, 'd_hidden_factor': 2.1682802519447426, 'n_layers': 1, 'hidden_dropout': 0.21502041528087443, 'residual_dropout': 0.23084332328863424, 'learning_rate': 0.00020780996791599043, 'batch_size': 64, 'epochs': 129}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:53:22,100] Trial 48 finished with value: 0.9753117047028003 and parameters: {'d': 64, 'd_hidden_factor': 1.2371642562415122, 'n_layers': 4, 'hidden_dropout': 0.46979400805858335, 'residual_dropout': 0.16681867465568906, 'learning_rate': 0.0009252632543184343, 'batch_size': 64, 'epochs': 84}. Best is trial 16 with value: 0.9830255984335322.\n",
      "[I 2025-11-27 04:53:58,390] Trial 49 finished with value: 0.9784871210476147 and parameters: {'d': 128, 'd_hidden_factor': 1.475743188585647, 'n_layers': 4, 'hidden_dropout': 0.41989774709591654, 'residual_dropout': 0.3710206512900029, 'learning_rate': 8.287867540173172e-05, 'batch_size': 32, 'epochs': 95}. Best is trial 16 with value: 0.9830255984335322.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 713.48s\n",
      "  Best CV G-Mean: 0.9830\n",
      "  Best parameters:\n",
      "    d: 64\n",
      "    d_hidden_factor: 2.395402113706958\n",
      "    n_layers: 4\n",
      "    hidden_dropout: 0.39090868317026173\n",
      "    residual_dropout: 0.1488236073281246\n",
      "    learning_rate: 1.001781929603626e-05\n",
      "    batch_size: 128\n",
      "    epochs: 170\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/170: Train Loss = 0.6607, Val Loss = 0.6469\n",
      "    Epoch 20/170: Train Loss = 0.5963, Val Loss = 0.6042\n",
      "    Epoch 30/170: Train Loss = 0.5713, Val Loss = 0.5630\n",
      "    Epoch 40/170: Train Loss = 0.5258, Val Loss = 0.5315\n",
      "    Epoch 50/170: Train Loss = 0.4960, Val Loss = 0.5047\n",
      "    Epoch 60/170: Train Loss = 0.4639, Val Loss = 0.4773\n",
      "    Epoch 70/170: Train Loss = 0.4455, Val Loss = 0.4513\n",
      "    Epoch 80/170: Train Loss = 0.4151, Val Loss = 0.4320\n",
      "    Epoch 90/170: Train Loss = 0.3993, Val Loss = 0.4151\n",
      "    Epoch 100/170: Train Loss = 0.3752, Val Loss = 0.3969\n",
      "    Epoch 110/170: Train Loss = 0.3678, Val Loss = 0.3809\n",
      "    Epoch 120/170: Train Loss = 0.3470, Val Loss = 0.3690\n",
      "    Epoch 130/170: Train Loss = 0.3331, Val Loss = 0.3569\n",
      "    Epoch 140/170: Train Loss = 0.3195, Val Loss = 0.3430\n",
      "    Epoch 150/170: Train Loss = 0.3022, Val Loss = 0.3346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 04:54:00,336] A new study created in memory with name: no-name-290bca94-d4de-4831-9284-b1d76a21f868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 160/170: Train Loss = 0.2983, Val Loss = 0.3252\n",
      "    Epoch 170/170: Train Loss = 0.2846, Val Loss = 0.3191\n",
      "✓ Training complete! Time: 1.94s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR breast-w\n",
      "================================================================================\n",
      "Accuracy:        0.9333\n",
      "AUC OVO:         0.9837\n",
      "G-Mean:          0.9327\n",
      "Cross-Entropy:   0.3193\n",
      "================================================================================\n",
      "✓ Saved results for breast-w\n",
      "\n",
      "✓ Completed breast-w (9/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 10/30: pc4\n",
      "################################################################################\n",
      "Loading processed dataset from cache: pc4\n",
      "Using device: cuda\n",
      "Dataset: pc4\n",
      "  Train: (1020, 37), Test: (438, 37)\n",
      "  Features: 37, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: pc4\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 04:54:12,169] Trial 0 finished with value: 0.6867256126218308 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.6867256126218308.\n",
      "[I 2025-11-27 04:54:31,384] Trial 1 finished with value: 0.7753098403121366 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.7753098403121366.\n",
      "[I 2025-11-27 04:54:56,762] Trial 2 finished with value: 0.7565310163373249 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 1 with value: 0.7753098403121366.\n",
      "[I 2025-11-27 04:57:42,033] Trial 3 finished with value: 0.743836162281117 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 1 with value: 0.7753098403121366.\n",
      "[I 2025-11-27 04:58:09,723] Trial 4 finished with value: 0.8092046164073711 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:00:10,907] Trial 5 finished with value: 0.693668673626832 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:01:39,226] Trial 6 finished with value: 0.739049320970123 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:01:51,867] Trial 7 finished with value: 0.7621983266670698 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:01:58,146] Trial 8 finished with value: 0.779697325205049 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:02:02,049] Trial 9 finished with value: 0.7778907843585455 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:02:24,160] Trial 10 finished with value: 0.7539781799414549 and parameters: {'d': 256, 'd_hidden_factor': 4.979424057639253, 'n_layers': 9, 'hidden_dropout': 0.4492503695658236, 'residual_dropout': 0.20527952505392744, 'learning_rate': 0.0014870022276803282, 'batch_size': 128, 'epochs': 145}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:02:56,383] Trial 11 finished with value: 0.7272072183876981 and parameters: {'d': 512, 'd_hidden_factor': 4.009671866646434, 'n_layers': 8, 'hidden_dropout': 0.010476594631962113, 'residual_dropout': 0.49618334980761697, 'learning_rate': 0.00888036766804695, 'batch_size': 256, 'epochs': 198}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:03:04,245] Trial 12 finished with value: 0.7877822538487828 and parameters: {'d': 256, 'd_hidden_factor': 4.774303166899394, 'n_layers': 7, 'hidden_dropout': 0.008038652206972724, 'residual_dropout': 0.4016871500061354, 'learning_rate': 0.0012085663652817858, 'batch_size': 256, 'epochs': 198}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:03:13,608] Trial 13 finished with value: 0.7662159947201579 and parameters: {'d': 256, 'd_hidden_factor': 4.8817604808111845, 'n_layers': 8, 'hidden_dropout': 0.1282492931447887, 'residual_dropout': 0.2777241836438182, 'learning_rate': 0.0015536971731577726, 'batch_size': 256, 'epochs': 165}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:03:45,726] Trial 14 finished with value: 0.7503068301439488 and parameters: {'d': 256, 'd_hidden_factor': 4.5485373155263735, 'n_layers': 7, 'hidden_dropout': 0.38487357694148944, 'residual_dropout': 0.38285860229640006, 'learning_rate': 0.0006420696104159517, 'batch_size': 64, 'epochs': 165}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:03:50,424] Trial 15 finished with value: 0.7025349083035779 and parameters: {'d': 256, 'd_hidden_factor': 4.273931074142787, 'n_layers': 4, 'hidden_dropout': 0.08247982261357112, 'residual_dropout': 0.2341015213948481, 'learning_rate': 0.0006771971135075193, 'batch_size': 256, 'epochs': 136}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:04:22,783] Trial 16 finished with value: 0.7694566665975148 and parameters: {'d': 256, 'd_hidden_factor': 3.5461782428402997, 'n_layers': 8, 'hidden_dropout': 0.2007753419386864, 'residual_dropout': 0.3768881063764669, 'learning_rate': 0.00273092748407284, 'batch_size': 64, 'epochs': 171}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:04:40,951] Trial 17 finished with value: 0.7398920274882907 and parameters: {'d': 256, 'd_hidden_factor': 2.4993767734880477, 'n_layers': 4, 'hidden_dropout': 0.07436726243220565, 'residual_dropout': 0.14837473819610625, 'learning_rate': 5.941072156885347e-05, 'batch_size': 128, 'epochs': 146}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:05:52,202] Trial 18 finished with value: 0.7374248712477922 and parameters: {'d': 512, 'd_hidden_factor': 4.4787399699524695, 'n_layers': 10, 'hidden_dropout': 0.37776580494923406, 'residual_dropout': 0.013124472293413875, 'learning_rate': 0.0006026117646786481, 'batch_size': 64, 'epochs': 115}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:06:11,969] Trial 19 finished with value: 0.6503145478275945 and parameters: {'d': 64, 'd_hidden_factor': 1.9247082136744789, 'n_layers': 7, 'hidden_dropout': 0.4409732660502871, 'residual_dropout': 0.4277648971557697, 'learning_rate': 1.0094165165701898e-05, 'batch_size': 256, 'epochs': 181}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:06:41,171] Trial 20 finished with value: 0.7689664048458791 and parameters: {'d': 256, 'd_hidden_factor': 3.644874444856415, 'n_layers': 7, 'hidden_dropout': 0.21557195640013874, 'residual_dropout': 0.26681459626650667, 'learning_rate': 0.0027368464775590563, 'batch_size': 64, 'epochs': 64}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:06:46,691] Trial 21 finished with value: 0.7630272606311795 and parameters: {'d': 128, 'd_hidden_factor': 3.2971845550804537, 'n_layers': 6, 'hidden_dropout': 0.008432250931794933, 'residual_dropout': 0.44435385791276627, 'learning_rate': 0.004933537835970938, 'batch_size': 256, 'epochs': 199}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:06:49,469] Trial 22 finished with value: 0.7623675878494727 and parameters: {'d': 128, 'd_hidden_factor': 3.3741439758503073, 'n_layers': 3, 'hidden_dropout': 0.04907204821047028, 'residual_dropout': 0.3737991452901257, 'learning_rate': 0.0059075312878703904, 'batch_size': 256, 'epochs': 183}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:06:54,213] Trial 23 finished with value: 0.7708559028611435 and parameters: {'d': 128, 'd_hidden_factor': 4.301882896439391, 'n_layers': 5, 'hidden_dropout': 0.10796776799958202, 'residual_dropout': 0.47200803691100357, 'learning_rate': 0.001001035187848428, 'batch_size': 256, 'epochs': 187}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:07:00,380] Trial 24 finished with value: 0.7389587470173075 and parameters: {'d': 256, 'd_hidden_factor': 2.8263468170773476, 'n_layers': 7, 'hidden_dropout': 0.03031662500729167, 'residual_dropout': 0.3895436950576574, 'learning_rate': 0.003993095821049685, 'batch_size': 256, 'epochs': 154}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:07:02,437] Trial 25 finished with value: 0.7792137846986242 and parameters: {'d': 128, 'd_hidden_factor': 4.649951798337679, 'n_layers': 1, 'hidden_dropout': 0.1616903793084396, 'residual_dropout': 0.3274789388285387, 'learning_rate': 0.0020870662365828937, 'batch_size': 256, 'epochs': 123}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:07:51,809] Trial 26 finished with value: 0.6960062741921633 and parameters: {'d': 64, 'd_hidden_factor': 3.6581911633053275, 'n_layers': 9, 'hidden_dropout': 0.13355681489083984, 'residual_dropout': 0.4625366236255126, 'learning_rate': 0.006024415547793402, 'batch_size': 32, 'epochs': 174}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:08:16,335] Trial 27 finished with value: 0.7613093016718635 and parameters: {'d': 512, 'd_hidden_factor': 4.170579968301184, 'n_layers': 6, 'hidden_dropout': 0.05824043193757642, 'residual_dropout': 0.42242067006276957, 'learning_rate': 0.0009918422023371073, 'batch_size': 128, 'epochs': 199}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:08:22,844] Trial 28 finished with value: 0.7494892984351438 and parameters: {'d': 256, 'd_hidden_factor': 3.0982741649601575, 'n_layers': 5, 'hidden_dropout': 0.23696406917667417, 'residual_dropout': 0.3570644950659605, 'learning_rate': 0.00036276613350426216, 'batch_size': 256, 'epochs': 160}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:08:38,358] Trial 29 finished with value: 0.7122500645323162 and parameters: {'d': 64, 'd_hidden_factor': 2.4817692594571783, 'n_layers': 8, 'hidden_dropout': 0.49234790898426983, 'residual_dropout': 0.40008820250759525, 'learning_rate': 0.00034966984894653567, 'batch_size': 128, 'epochs': 37}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:09:01,073] Trial 30 finished with value: 0.7036840094104413 and parameters: {'d': 128, 'd_hidden_factor': 3.6819617092586965, 'n_layers': 7, 'hidden_dropout': 0.33428639356143874, 'residual_dropout': 0.3170019136960238, 'learning_rate': 0.0024192302077673997, 'batch_size': 64, 'epochs': 132}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:09:04,216] Trial 31 finished with value: 0.7436507287509753 and parameters: {'d': 128, 'd_hidden_factor': 4.7868010106738295, 'n_layers': 3, 'hidden_dropout': 0.15746884217196666, 'residual_dropout': 0.3004983080559594, 'learning_rate': 0.0017321916168523048, 'batch_size': 256, 'epochs': 109}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:09:09,296] Trial 32 finished with value: 0.7588544452252692 and parameters: {'d': 128, 'd_hidden_factor': 4.727658950011229, 'n_layers': 6, 'hidden_dropout': 0.17164020141757386, 'residual_dropout': 0.3418520244626664, 'learning_rate': 0.0019283166225982121, 'batch_size': 256, 'epochs': 127}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:09:11,813] Trial 33 finished with value: 0.7043985970346356 and parameters: {'d': 128, 'd_hidden_factor': 4.571584221934952, 'n_layers': 1, 'hidden_dropout': 2.86855081537145e-05, 'residual_dropout': 0.22127635774005788, 'learning_rate': 0.0009065704734357072, 'batch_size': 256, 'epochs': 145}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:09:16,119] Trial 34 finished with value: 0.7849268920377562 and parameters: {'d': 128, 'd_hidden_factor': 4.034747313293273, 'n_layers': 5, 'hidden_dropout': 0.2972106977531091, 'residual_dropout': 0.3457010577913038, 'learning_rate': 0.003976864676048114, 'batch_size': 256, 'epochs': 54}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:09:37,433] Trial 35 finished with value: 0.7043232061929969 and parameters: {'d': 128, 'd_hidden_factor': 3.9219614940395586, 'n_layers': 5, 'hidden_dropout': 0.2966337273834223, 'residual_dropout': 0.40893700153078916, 'learning_rate': 0.009825798186998585, 'batch_size': 64, 'epochs': 50}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:10:13,554] Trial 36 finished with value: 0.7215487539385704 and parameters: {'d': 128, 'd_hidden_factor': 3.38743885369968, 'n_layers': 5, 'hidden_dropout': 0.27927819067116755, 'residual_dropout': 0.4640547154967029, 'learning_rate': 0.004014403092150823, 'batch_size': 32, 'epochs': 72}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:10:23,247] Trial 37 finished with value: 0.7502775310632581 and parameters: {'d': 256, 'd_hidden_factor': 4.112436779519875, 'n_layers': 6, 'hidden_dropout': 0.25327302130262097, 'residual_dropout': 0.28462815634285243, 'learning_rate': 0.0002046418645892421, 'batch_size': 256, 'epochs': 59}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:10:40,014] Trial 38 finished with value: 0.7272395490029825 and parameters: {'d': 128, 'd_hidden_factor': 3.1495464408601124, 'n_layers': 4, 'hidden_dropout': 0.3587646058306726, 'residual_dropout': 0.3636905713949219, 'learning_rate': 0.006319776722875768, 'batch_size': 64, 'epochs': 79}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:11:24,665] Trial 39 finished with value: 0.7138886414508909 and parameters: {'d': 256, 'd_hidden_factor': 3.795029763340219, 'n_layers': 5, 'hidden_dropout': 0.41079892875003127, 'residual_dropout': 0.3485478938678155, 'learning_rate': 0.0039888567934246826, 'batch_size': 32, 'epochs': 104}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:11:36,778] Trial 40 finished with value: 0.7818255569578164 and parameters: {'d': 512, 'd_hidden_factor': 4.437111888177475, 'n_layers': 3, 'hidden_dropout': 0.30514501732258265, 'residual_dropout': 0.4987121840724917, 'learning_rate': 0.0012434109747082702, 'batch_size': 256, 'epochs': 187}. Best is trial 4 with value: 0.8092046164073711.\n",
      "[I 2025-11-27 05:11:48,126] Trial 41 finished with value: 0.8152566856795515 and parameters: {'d': 512, 'd_hidden_factor': 4.381464382577794, 'n_layers': 3, 'hidden_dropout': 0.32589678057363464, 'residual_dropout': 0.4848682556407795, 'learning_rate': 0.0013215005467429803, 'batch_size': 256, 'epochs': 189}. Best is trial 41 with value: 0.8152566856795515.\n",
      "[I 2025-11-27 05:11:59,118] Trial 42 finished with value: 0.7789109251237127 and parameters: {'d': 512, 'd_hidden_factor': 4.348933852922984, 'n_layers': 3, 'hidden_dropout': 0.32864273928156784, 'residual_dropout': 0.4540494659267655, 'learning_rate': 0.0011627002076354525, 'batch_size': 256, 'epochs': 190}. Best is trial 41 with value: 0.8152566856795515.\n",
      "[I 2025-11-27 05:12:07,513] Trial 43 finished with value: 0.7842464824645438 and parameters: {'d': 512, 'd_hidden_factor': 4.998100109501281, 'n_layers': 2, 'hidden_dropout': 0.30095323001657076, 'residual_dropout': 0.4860309849803488, 'learning_rate': 0.0005381896470540399, 'batch_size': 256, 'epochs': 176}. Best is trial 41 with value: 0.8152566856795515.\n",
      "[I 2025-11-27 05:12:17,032] Trial 44 finished with value: 0.7882450978754092 and parameters: {'d': 512, 'd_hidden_factor': 4.955896711249972, 'n_layers': 2, 'hidden_dropout': 0.2758525070679688, 'residual_dropout': 0.4141825755824359, 'learning_rate': 0.00044700831581795283, 'batch_size': 256, 'epochs': 87}. Best is trial 41 with value: 0.8152566856795515.\n",
      "[I 2025-11-27 05:12:29,242] Trial 45 finished with value: 0.7641374516337965 and parameters: {'d': 512, 'd_hidden_factor': 4.775772015183648, 'n_layers': 2, 'hidden_dropout': 0.2684143910868047, 'residual_dropout': 0.4101247908833146, 'learning_rate': 0.0001566969713916379, 'batch_size': 256, 'epochs': 91}. Best is trial 41 with value: 0.8152566856795515.\n",
      "[I 2025-11-27 05:12:36,755] Trial 46 finished with value: 0.7748880950176046 and parameters: {'d': 512, 'd_hidden_factor': 4.02907507083902, 'n_layers': 2, 'hidden_dropout': 0.2401765270870536, 'residual_dropout': 0.4395029649807627, 'learning_rate': 0.00043143407218485414, 'batch_size': 256, 'epochs': 48}. Best is trial 41 with value: 0.8152566856795515.\n",
      "[I 2025-11-27 05:12:55,942] Trial 47 finished with value: 0.6958340475533688 and parameters: {'d': 512, 'd_hidden_factor': 4.214961963328089, 'n_layers': 4, 'hidden_dropout': 0.3438313612899596, 'residual_dropout': 0.18928223034236974, 'learning_rate': 0.000796925720573718, 'batch_size': 128, 'epochs': 82}. Best is trial 41 with value: 0.8152566856795515.\n",
      "[I 2025-11-27 05:13:07,674] Trial 48 finished with value: 0.7926122672761359 and parameters: {'d': 512, 'd_hidden_factor': 4.884429572818466, 'n_layers': 1, 'hidden_dropout': 0.3707080597425446, 'residual_dropout': 0.3014000080788957, 'learning_rate': 0.0002827211397419095, 'batch_size': 64, 'epochs': 73}. Best is trial 41 with value: 0.8152566856795515.\n",
      "[I 2025-11-27 05:13:20,420] Trial 49 finished with value: 0.7888490191069126 and parameters: {'d': 512, 'd_hidden_factor': 4.903322654151552, 'n_layers': 1, 'hidden_dropout': 0.41166712852942344, 'residual_dropout': 0.2895961883093063, 'learning_rate': 0.00026459886209949157, 'batch_size': 64, 'epochs': 71}. Best is trial 41 with value: 0.8152566856795515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 1160.09s\n",
      "  Best CV G-Mean: 0.8153\n",
      "  Best parameters:\n",
      "    d: 512\n",
      "    d_hidden_factor: 4.381464382577794\n",
      "    n_layers: 3\n",
      "    hidden_dropout: 0.32589678057363464\n",
      "    residual_dropout: 0.4848682556407795\n",
      "    learning_rate: 0.0013215005467429803\n",
      "    batch_size: 256\n",
      "    epochs: 189\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/189: Train Loss = 0.1892, Val Loss = 0.2428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 05:13:21,079] A new study created in memory with name: no-name-2cb63d05-b099-4bc4-8ee5-81d0768b9107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Early stopping at epoch 18\n",
      "✓ Training complete! Time: 0.65s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR pc4\n",
      "================================================================================\n",
      "Accuracy:        0.8927\n",
      "AUC OVO:         0.9286\n",
      "G-Mean:          0.7914\n",
      "Cross-Entropy:   0.2362\n",
      "================================================================================\n",
      "✓ Saved results for pc4\n",
      "\n",
      "✓ Completed pc4 (10/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 11/30: blood-transfusion-service-center\n",
      "################################################################################\n",
      "Loading processed dataset from cache: blood-transfusion-service-center\n",
      "Using device: cuda\n",
      "Dataset: blood-transfusion-service-center\n",
      "  Train: (523, 4), Test: (225, 4)\n",
      "  Features: 4, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: blood-transfusion-service-center\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 05:13:26,626] Trial 0 finished with value: 0.6232430811980498 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.6232430811980498.\n",
      "[I 2025-11-27 05:13:34,454] Trial 1 finished with value: 0.6187614013659917 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 0 with value: 0.6232430811980498.\n",
      "[I 2025-11-27 05:13:44,683] Trial 2 finished with value: 0.5503161468471659 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: 0.6232430811980498.\n",
      "[I 2025-11-27 05:14:49,480] Trial 3 finished with value: 0.6100353149286942 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 0 with value: 0.6232430811980498.\n",
      "[I 2025-11-27 05:15:00,930] Trial 4 finished with value: 0.5933533673296159 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 0 with value: 0.6232430811980498.\n",
      "[I 2025-11-27 05:15:57,761] Trial 5 finished with value: 0.5981341172679582 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 0 with value: 0.6232430811980498.\n",
      "[I 2025-11-27 05:16:34,984] Trial 6 finished with value: 0.6130758931353493 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 0 with value: 0.6232430811980498.\n",
      "[I 2025-11-27 05:16:40,225] Trial 7 finished with value: 0.622973943949866 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 0 with value: 0.6232430811980498.\n",
      "[I 2025-11-27 05:16:42,099] Trial 8 finished with value: 0.6369425898230814 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 8 with value: 0.6369425898230814.\n",
      "[I 2025-11-27 05:16:43,366] Trial 9 finished with value: 0.6082096751137737 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 8 with value: 0.6369425898230814.\n",
      "[I 2025-11-27 05:16:58,753] Trial 10 finished with value: 0.566920717430985 and parameters: {'d': 512, 'd_hidden_factor': 4.97088426861444, 'n_layers': 9, 'hidden_dropout': 0.004030571702010294, 'residual_dropout': 0.19485930498507747, 'learning_rate': 0.0006550956088886104, 'batch_size': 256, 'epochs': 196}. Best is trial 8 with value: 0.6369425898230814.\n",
      "[I 2025-11-27 05:17:11,188] Trial 11 finished with value: 0.6256551064520783 and parameters: {'d': 64, 'd_hidden_factor': 4.233138003575574, 'n_layers': 8, 'hidden_dropout': 0.4816139361200471, 'residual_dropout': 0.49630128216301855, 'learning_rate': 0.00040957854252747787, 'batch_size': 128, 'epochs': 198}. Best is trial 8 with value: 0.6369425898230814.\n",
      "[I 2025-11-27 05:17:18,548] Trial 12 finished with value: 0.5721517242231916 and parameters: {'d': 64, 'd_hidden_factor': 4.759858348102476, 'n_layers': 8, 'hidden_dropout': 0.008038652206972724, 'residual_dropout': 0.492683461836321, 'learning_rate': 0.0009107444326002176, 'batch_size': 128, 'epochs': 200}. Best is trial 8 with value: 0.6369425898230814.\n",
      "[I 2025-11-27 05:17:33,756] Trial 13 finished with value: 0.6236465196825989 and parameters: {'d': 128, 'd_hidden_factor': 4.365310978586605, 'n_layers': 8, 'hidden_dropout': 0.4404224183783849, 'residual_dropout': 0.42991693404731, 'learning_rate': 0.00010038584476789021, 'batch_size': 128, 'epochs': 159}. Best is trial 8 with value: 0.6369425898230814.\n",
      "[I 2025-11-27 05:17:36,797] Trial 14 finished with value: 0.5646386896304421 and parameters: {'d': 64, 'd_hidden_factor': 3.666349016205557, 'n_layers': 8, 'hidden_dropout': 0.09466648282362448, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 0.009822645763830223, 'batch_size': 256, 'epochs': 170}. Best is trial 8 with value: 0.6369425898230814.\n",
      "[I 2025-11-27 05:17:52,707] Trial 15 finished with value: 0.6336653263913071 and parameters: {'d': 128, 'd_hidden_factor': 4.327856657919818, 'n_layers': 7, 'hidden_dropout': 0.40766446614142565, 'residual_dropout': 0.4016481322227178, 'learning_rate': 5.444462585702138e-05, 'batch_size': 128, 'epochs': 165}. Best is trial 8 with value: 0.6369425898230814.\n",
      "[I 2025-11-27 05:17:58,213] Trial 16 finished with value: 0.639548600787694 and parameters: {'d': 128, 'd_hidden_factor': 2.317943595572068, 'n_layers': 4, 'hidden_dropout': 0.38460743137478004, 'residual_dropout': 0.3940161143608048, 'learning_rate': 1.0033438294973185e-05, 'batch_size': 256, 'epochs': 159}. Best is trial 16 with value: 0.639548600787694.\n",
      "[I 2025-11-27 05:18:02,615] Trial 17 finished with value: 0.5730739685113673 and parameters: {'d': 128, 'd_hidden_factor': 1.9162160728387747, 'n_layers': 4, 'hidden_dropout': 0.0950244092986048, 'residual_dropout': 0.28032217536909576, 'learning_rate': 1.1016598219611525e-05, 'batch_size': 256, 'epochs': 144}. Best is trial 16 with value: 0.639548600787694.\n",
      "[I 2025-11-27 05:18:03,626] Trial 18 finished with value: 0.5707002651087072 and parameters: {'d': 128, 'd_hidden_factor': 2.307472201555157, 'n_layers': 3, 'hidden_dropout': 0.19848602831893403, 'residual_dropout': 0.22594306843997852, 'learning_rate': 0.0028595061805322276, 'batch_size': 256, 'epochs': 181}. Best is trial 16 with value: 0.639548600787694.\n",
      "[I 2025-11-27 05:18:05,534] Trial 19 finished with value: 0.4403999562009531 and parameters: {'d': 128, 'd_hidden_factor': 2.5863016454901935, 'n_layers': 1, 'hidden_dropout': 0.3752520585957436, 'residual_dropout': 0.37502573914082754, 'learning_rate': 1.0094165165701898e-05, 'batch_size': 256, 'epochs': 144}. Best is trial 16 with value: 0.639548600787694.\n",
      "[I 2025-11-27 05:18:14,261] Trial 20 finished with value: 0.6322125557176523 and parameters: {'d': 512, 'd_hidden_factor': 3.3814831963892193, 'n_layers': 4, 'hidden_dropout': 0.07987181441310034, 'residual_dropout': 0.45472441589358303, 'learning_rate': 3.414949267759356e-05, 'batch_size': 256, 'epochs': 148}. Best is trial 16 with value: 0.639548600787694.\n",
      "[I 2025-11-27 05:18:31,209] Trial 21 finished with value: 0.6431026096507584 and parameters: {'d': 128, 'd_hidden_factor': 3.203990650436844, 'n_layers': 7, 'hidden_dropout': 0.3779311208940815, 'residual_dropout': 0.3898356530108389, 'learning_rate': 5.200681273340163e-05, 'batch_size': 128, 'epochs': 177}. Best is trial 21 with value: 0.6431026096507584.\n",
      "[I 2025-11-27 05:18:40,582] Trial 22 finished with value: 0.6471609565354187 and parameters: {'d': 128, 'd_hidden_factor': 3.371171763781775, 'n_layers': 7, 'hidden_dropout': 0.4213813027652381, 'residual_dropout': 0.37921558204166234, 'learning_rate': 7.776665720008474e-05, 'batch_size': 256, 'epochs': 180}. Best is trial 22 with value: 0.6471609565354187.\n",
      "[I 2025-11-27 05:19:04,346] Trial 23 finished with value: 0.6175435187103099 and parameters: {'d': 128, 'd_hidden_factor': 1.7257662403912164, 'n_layers': 7, 'hidden_dropout': 0.43344928117219067, 'residual_dropout': 0.37827446502466894, 'learning_rate': 7.094635701773251e-05, 'batch_size': 128, 'epochs': 181}. Best is trial 22 with value: 0.6471609565354187.\n",
      "[I 2025-11-27 05:19:10,433] Trial 24 finished with value: 0.5895697006570112 and parameters: {'d': 128, 'd_hidden_factor': 2.5226437900724976, 'n_layers': 7, 'hidden_dropout': 0.3630612305644981, 'residual_dropout': 0.27797435038947527, 'learning_rate': 1.760731728298393e-05, 'batch_size': 256, 'epochs': 180}. Best is trial 22 with value: 0.6471609565354187.\n",
      "[I 2025-11-27 05:19:21,107] Trial 25 finished with value: 0.6545747133208009 and parameters: {'d': 128, 'd_hidden_factor': 2.9748649929536692, 'n_layers': 9, 'hidden_dropout': 0.3849583815734307, 'residual_dropout': 0.37267721881125826, 'learning_rate': 5.200743783424938e-05, 'batch_size': 256, 'epochs': 151}. Best is trial 25 with value: 0.6545747133208009.\n",
      "[I 2025-11-27 05:19:43,507] Trial 26 finished with value: 0.628033592294599 and parameters: {'d': 128, 'd_hidden_factor': 2.958185849130562, 'n_layers': 9, 'hidden_dropout': 0.4463747440230569, 'residual_dropout': 0.2517766106031386, 'learning_rate': 4.9498462245458517e-05, 'batch_size': 128, 'epochs': 135}. Best is trial 25 with value: 0.6545747133208009.\n",
      "[I 2025-11-27 05:20:29,740] Trial 27 finished with value: 0.6156446508611482 and parameters: {'d': 128, 'd_hidden_factor': 3.262578584938964, 'n_layers': 10, 'hidden_dropout': 0.4078833054665969, 'residual_dropout': 0.3587083133379423, 'learning_rate': 0.00014212067580745592, 'batch_size': 32, 'epochs': 175}. Best is trial 25 with value: 0.6545747133208009.\n",
      "[I 2025-11-27 05:20:44,304] Trial 28 finished with value: 0.606855972612003 and parameters: {'d': 512, 'd_hidden_factor': 3.47338902617036, 'n_layers': 9, 'hidden_dropout': 0.33868328032838985, 'residual_dropout': 0.3072013294579661, 'learning_rate': 6.669914198180745e-05, 'batch_size': 256, 'epochs': 154}. Best is trial 25 with value: 0.6545747133208009.\n",
      "[I 2025-11-27 05:20:52,222] Trial 29 finished with value: 0.5896531818358064 and parameters: {'d': 256, 'd_hidden_factor': 3.941844782753206, 'n_layers': 7, 'hidden_dropout': 0.49269880541141453, 'residual_dropout': 0.3344921104575649, 'learning_rate': 0.0002599760419770974, 'batch_size': 128, 'epochs': 111}. Best is trial 25 with value: 0.6545747133208009.\n",
      "[I 2025-11-27 05:20:58,300] Trial 30 finished with value: 0.6229120843381317 and parameters: {'d': 128, 'd_hidden_factor': 2.925571607460417, 'n_layers': 5, 'hidden_dropout': 0.4612933495376838, 'residual_dropout': 0.44938949173315745, 'learning_rate': 0.00034606259242429463, 'batch_size': 128, 'epochs': 186}. Best is trial 25 with value: 0.6545747133208009.\n",
      "[I 2025-11-27 05:21:08,073] Trial 31 finished with value: 0.555132599139638 and parameters: {'d': 128, 'd_hidden_factor': 2.2562700133253495, 'n_layers': 9, 'hidden_dropout': 0.39609595562835187, 'residual_dropout': 0.39102496844841317, 'learning_rate': 1.5923717437245686e-05, 'batch_size': 256, 'epochs': 164}. Best is trial 25 with value: 0.6545747133208009.\n",
      "[I 2025-11-27 05:21:13,059] Trial 32 finished with value: 0.6057652000895484 and parameters: {'d': 128, 'd_hidden_factor': 2.634463984219935, 'n_layers': 3, 'hidden_dropout': 0.3883626507887891, 'residual_dropout': 0.408994934353403, 'learning_rate': 3.686084114169761e-05, 'batch_size': 256, 'epochs': 157}. Best is trial 25 with value: 0.6545747133208009.\n",
      "[I 2025-11-27 05:21:20,583] Trial 33 finished with value: 0.6362077018670889 and parameters: {'d': 128, 'd_hidden_factor': 1.9939542383673572, 'n_layers': 5, 'hidden_dropout': 0.3309986841928302, 'residual_dropout': 0.36345328769388885, 'learning_rate': 8.425164009923734e-05, 'batch_size': 256, 'epochs': 188}. Best is trial 25 with value: 0.6545747133208009.\n",
      "[I 2025-11-27 05:21:34,656] Trial 34 finished with value: 0.6146248771099467 and parameters: {'d': 128, 'd_hidden_factor': 2.9971941193055613, 'n_layers': 6, 'hidden_dropout': 0.41919769248306027, 'residual_dropout': 0.3156996123569353, 'learning_rate': 0.00017423131788129012, 'batch_size': 64, 'epochs': 134}. Best is trial 25 with value: 0.6545747133208009.\n",
      "[I 2025-11-27 05:21:37,919] Trial 35 finished with value: 0.6619119423625298 and parameters: {'d': 128, 'd_hidden_factor': 3.6466299244357834, 'n_layers': 7, 'hidden_dropout': 0.24311479239076444, 'residual_dropout': 0.44734305485368936, 'learning_rate': 2.1438904108630895e-05, 'batch_size': 256, 'epochs': 50}. Best is trial 35 with value: 0.6619119423625298.\n",
      "[I 2025-11-27 05:21:50,775] Trial 36 finished with value: 0.6514793971431794 and parameters: {'d': 256, 'd_hidden_factor': 3.625720961191435, 'n_layers': 7, 'hidden_dropout': 0.23530041140946217, 'residual_dropout': 0.44794784908712204, 'learning_rate': 2.0447626199482556e-05, 'batch_size': 64, 'epochs': 30}. Best is trial 35 with value: 0.6619119423625298.\n",
      "[I 2025-11-27 05:22:10,424] Trial 37 finished with value: 0.627953660239625 and parameters: {'d': 256, 'd_hidden_factor': 3.6349186363549006, 'n_layers': 8, 'hidden_dropout': 0.22144839530532615, 'residual_dropout': 0.45449964699805834, 'learning_rate': 2.164183417753864e-05, 'batch_size': 64, 'epochs': 40}. Best is trial 35 with value: 0.6619119423625298.\n",
      "[I 2025-11-27 05:22:43,240] Trial 38 finished with value: 0.6425571559437322 and parameters: {'d': 256, 'd_hidden_factor': 4.132318499489253, 'n_layers': 10, 'hidden_dropout': 0.26987245873863186, 'residual_dropout': 0.46611384417612034, 'learning_rate': 3.861482393131474e-05, 'batch_size': 64, 'epochs': 56}. Best is trial 35 with value: 0.6619119423625298.\n",
      "[I 2025-11-27 05:22:55,524] Trial 39 finished with value: 0.64605790883192 and parameters: {'d': 256, 'd_hidden_factor': 3.6157589862337174, 'n_layers': 6, 'hidden_dropout': 0.17462858636987183, 'residual_dropout': 0.42137007215271194, 'learning_rate': 2.5064490905321363e-05, 'batch_size': 64, 'epochs': 33}. Best is trial 35 with value: 0.6619119423625298.\n",
      "[I 2025-11-27 05:23:43,980] Trial 40 finished with value: 0.6003217972934708 and parameters: {'d': 256, 'd_hidden_factor': 3.828592022859613, 'n_layers': 7, 'hidden_dropout': 0.24421161308095435, 'residual_dropout': 0.1505794337887787, 'learning_rate': 1.5024845181085107e-05, 'batch_size': 32, 'epochs': 65}. Best is trial 35 with value: 0.6619119423625298.\n",
      "[I 2025-11-27 05:23:57,554] Trial 41 finished with value: 0.6215304935938921 and parameters: {'d': 256, 'd_hidden_factor': 3.5097732446475436, 'n_layers': 6, 'hidden_dropout': 0.17047976745844318, 'residual_dropout': 0.417779659012842, 'learning_rate': 2.2268431045781318e-05, 'batch_size': 64, 'epochs': 33}. Best is trial 35 with value: 0.6619119423625298.\n",
      "[I 2025-11-27 05:24:13,723] Trial 42 finished with value: 0.6156118708420747 and parameters: {'d': 256, 'd_hidden_factor': 3.1633580786651003, 'n_layers': 5, 'hidden_dropout': 0.13983723612936294, 'residual_dropout': 0.4683577028217047, 'learning_rate': 2.6012469564374452e-05, 'batch_size': 64, 'epochs': 47}. Best is trial 35 with value: 0.6619119423625298.\n",
      "[I 2025-11-27 05:24:41,436] Trial 43 finished with value: 0.612773474732242 and parameters: {'d': 256, 'd_hidden_factor': 3.8202389756817774, 'n_layers': 6, 'hidden_dropout': 0.2975922480271585, 'residual_dropout': 0.4276446417144502, 'learning_rate': 3.308133862516297e-05, 'batch_size': 64, 'epochs': 72}. Best is trial 35 with value: 0.6619119423625298.\n",
      "[I 2025-11-27 05:25:01,430] Trial 44 finished with value: 0.6222975674287475 and parameters: {'d': 256, 'd_hidden_factor': 2.8297260078232536, 'n_layers': 8, 'hidden_dropout': 0.23582149863428276, 'residual_dropout': 0.3480023285750037, 'learning_rate': 4.4799017712088356e-05, 'batch_size': 64, 'epochs': 41}. Best is trial 35 with value: 0.6619119423625298.\n",
      "[I 2025-11-27 05:25:22,334] Trial 45 finished with value: 0.6525977862653647 and parameters: {'d': 256, 'd_hidden_factor': 4.580161669161176, 'n_layers': 7, 'hidden_dropout': 0.1846860471003407, 'residual_dropout': 0.47878859480374875, 'learning_rate': 1.5132138933240433e-05, 'batch_size': 64, 'epochs': 49}. Best is trial 35 with value: 0.6619119423625298.\n",
      "[I 2025-11-27 05:25:45,287] Trial 46 finished with value: 0.6600384273063115 and parameters: {'d': 64, 'd_hidden_factor': 4.63739579772876, 'n_layers': 9, 'hidden_dropout': 0.20493361837720656, 'residual_dropout': 0.48123022341641575, 'learning_rate': 1.4992980701098517e-05, 'batch_size': 64, 'epochs': 57}. Best is trial 35 with value: 0.6619119423625298.\n",
      "[I 2025-11-27 05:26:07,122] Trial 47 finished with value: 0.6693864882881108 and parameters: {'d': 64, 'd_hidden_factor': 4.608687320984796, 'n_layers': 10, 'hidden_dropout': 0.1421723920289982, 'residual_dropout': 0.48044060656136567, 'learning_rate': 1.4058607575030626e-05, 'batch_size': 64, 'epochs': 57}. Best is trial 47 with value: 0.6693864882881108.\n",
      "[I 2025-11-27 05:26:39,124] Trial 48 finished with value: 0.6375955811433782 and parameters: {'d': 64, 'd_hidden_factor': 4.583895223093078, 'n_layers': 9, 'hidden_dropout': 0.14757368852579866, 'residual_dropout': 0.4779342258519922, 'learning_rate': 1.3710791866672226e-05, 'batch_size': 64, 'epochs': 80}. Best is trial 47 with value: 0.6693864882881108.\n",
      "[I 2025-11-27 05:27:05,263] Trial 49 finished with value: 0.6620153222049534 and parameters: {'d': 64, 'd_hidden_factor': 4.911426231068123, 'n_layers': 10, 'hidden_dropout': 0.1963668183578984, 'residual_dropout': 0.49996032491415804, 'learning_rate': 1.3029084753329196e-05, 'batch_size': 64, 'epochs': 57}. Best is trial 47 with value: 0.6693864882881108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 824.19s\n",
      "  Best CV G-Mean: 0.6694\n",
      "  Best parameters:\n",
      "    d: 64\n",
      "    d_hidden_factor: 4.608687320984796\n",
      "    n_layers: 10\n",
      "    hidden_dropout: 0.1421723920289982\n",
      "    residual_dropout: 0.48044060656136567\n",
      "    learning_rate: 1.4058607575030626e-05\n",
      "    batch_size: 64\n",
      "    epochs: 57\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/57: Train Loss = 0.7246, Val Loss = 0.6935\n",
      "    Epoch 20/57: Train Loss = 0.6932, Val Loss = 0.6711\n",
      "    Epoch 30/57: Train Loss = 0.6606, Val Loss = 0.6553\n",
      "    Epoch 40/57: Train Loss = 0.6574, Val Loss = 0.6424\n",
      "    Epoch 50/57: Train Loss = 0.6256, Val Loss = 0.6284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 05:27:08,196] A new study created in memory with name: no-name-4af7f7a7-025c-4c7a-840c-574cb68ac1db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training complete! Time: 2.92s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR blood-transfusion-service-center\n",
      "================================================================================\n",
      "Accuracy:        0.6044\n",
      "AUC OVO:         0.7173\n",
      "G-Mean:          0.6539\n",
      "Cross-Entropy:   0.6810\n",
      "================================================================================\n",
      "✓ Saved results for blood-transfusion-service-center\n",
      "\n",
      "✓ Completed blood-transfusion-service-center (11/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 12/30: vowel\n",
      "################################################################################\n",
      "Loading processed dataset from cache: vowel\n",
      "Using device: cuda\n",
      "Dataset: vowel\n",
      "  Train: (693, 27), Test: (297, 27)\n",
      "  Features: 27, Classes: 11\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: vowel\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 05:27:15,326] Trial 0 finished with value: 0.38681356691016516 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.38681356691016516.\n",
      "[I 2025-11-27 05:27:43,404] Trial 1 finished with value: 0.9715803877381827 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.9715803877381827.\n",
      "[I 2025-11-27 05:28:02,011] Trial 2 finished with value: 0.97918806590052 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 2 with value: 0.97918806590052.\n",
      "[I 2025-11-27 05:30:12,012] Trial 3 finished with value: 0.9630396499971864 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 2 with value: 0.97918806590052.\n",
      "[I 2025-11-27 05:30:48,680] Trial 4 finished with value: 0.9645298057795622 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 2 with value: 0.97918806590052.\n",
      "[I 2025-11-27 05:32:12,643] Trial 5 finished with value: 0.8435979926697342 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 2 with value: 0.97918806590052.\n",
      "[I 2025-11-27 05:33:16,849] Trial 6 finished with value: 0.8170530594407414 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 2 with value: 0.97918806590052.\n",
      "[I 2025-11-27 05:33:31,119] Trial 7 finished with value: 0.95780841762746 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 2 with value: 0.97918806590052.\n",
      "[I 2025-11-27 05:33:37,064] Trial 8 finished with value: 0.9529562370069808 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 2 with value: 0.97918806590052.\n",
      "[I 2025-11-27 05:33:40,268] Trial 9 finished with value: 0.9593140811459039 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 2 with value: 0.97918806590052.\n",
      "[I 2025-11-27 05:34:26,286] Trial 10 finished with value: 0.9495860280454964 and parameters: {'d': 512, 'd_hidden_factor': 4.944801428233171, 'n_layers': 9, 'hidden_dropout': 0.11443328154761422, 'residual_dropout': 0.12302794125503497, 'learning_rate': 0.0006785909050951757, 'batch_size': 128, 'epochs': 161}. Best is trial 2 with value: 0.97918806590052.\n",
      "[I 2025-11-27 05:34:49,207] Trial 11 finished with value: 0.96976169179127 and parameters: {'d': 128, 'd_hidden_factor': 2.546528993889768, 'n_layers': 8, 'hidden_dropout': 0.404612932718377, 'residual_dropout': 0.1906752818537771, 'learning_rate': 0.0008564161872354258, 'batch_size': 64, 'epochs': 43}. Best is trial 2 with value: 0.97918806590052.\n",
      "[I 2025-11-27 05:35:10,718] Trial 12 finished with value: 0.9803045751371557 and parameters: {'d': 128, 'd_hidden_factor': 1.990247787249071, 'n_layers': 4, 'hidden_dropout': 0.1737867956397079, 'residual_dropout': 0.0025078789307216576, 'learning_rate': 9.788416868601095e-05, 'batch_size': 64, 'epochs': 67}. Best is trial 12 with value: 0.9803045751371557.\n",
      "[I 2025-11-27 05:35:29,565] Trial 13 finished with value: 0.9711466333739395 and parameters: {'d': 128, 'd_hidden_factor': 1.8931215170697901, 'n_layers': 4, 'hidden_dropout': 0.1787607593913219, 'residual_dropout': 0.02737273360314285, 'learning_rate': 0.00010038584476789021, 'batch_size': 64, 'epochs': 59}. Best is trial 12 with value: 0.9803045751371557.\n",
      "[I 2025-11-27 05:35:34,379] Trial 14 finished with value: 0.657142268895514 and parameters: {'d': 128, 'd_hidden_factor': 1.9093526074195712, 'n_layers': 1, 'hidden_dropout': 0.06719516568462386, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 8.578692449256666e-05, 'batch_size': 64, 'epochs': 30}. Best is trial 12 with value: 0.9803045751371557.\n",
      "[I 2025-11-27 05:35:53,092] Trial 15 finished with value: 0.13990781401271582 and parameters: {'d': 128, 'd_hidden_factor': 2.579214768039189, 'n_layers': 4, 'hidden_dropout': 0.20012966712249788, 'residual_dropout': 0.18244984576708526, 'learning_rate': 1.201880159180346e-05, 'batch_size': 64, 'epochs': 57}. Best is trial 12 with value: 0.9803045751371557.\n",
      "[I 2025-11-27 05:36:49,441] Trial 16 finished with value: 0.9790402407963763 and parameters: {'d': 128, 'd_hidden_factor': 1.5976963396059134, 'n_layers': 8, 'hidden_dropout': 0.2184439005029862, 'residual_dropout': 0.10353343904995015, 'learning_rate': 0.0002482047565102992, 'batch_size': 64, 'epochs': 142}. Best is trial 12 with value: 0.9803045751371557.\n",
      "[I 2025-11-27 05:37:06,599] Trial 17 finished with value: 0.9786818974533968 and parameters: {'d': 512, 'd_hidden_factor': 4.426874031416949, 'n_layers': 3, 'hidden_dropout': 0.10172247541026468, 'residual_dropout': 0.20742130729324743, 'learning_rate': 5.1110159054601836e-05, 'batch_size': 256, 'epochs': 74}. Best is trial 12 with value: 0.9803045751371557.\n",
      "[I 2025-11-27 05:37:18,530] Trial 18 finished with value: 0.9366382145601679 and parameters: {'d': 64, 'd_hidden_factor': 2.4578693164060286, 'n_layers': 7, 'hidden_dropout': 0.15715851220391644, 'residual_dropout': 0.05759556320281581, 'learning_rate': 0.00020303109326557034, 'batch_size': 128, 'epochs': 53}. Best is trial 12 with value: 0.9803045751371557.\n",
      "[I 2025-11-27 05:37:41,869] Trial 19 finished with value: 0.9766781122470605 and parameters: {'d': 128, 'd_hidden_factor': 2.7956418011888484, 'n_layers': 5, 'hidden_dropout': 0.035324338427074026, 'residual_dropout': 0.15156870090272612, 'learning_rate': 0.0006441943583327288, 'batch_size': 64, 'epochs': 106}. Best is trial 12 with value: 0.9803045751371557.\n",
      "[I 2025-11-27 05:38:00,664] Trial 20 finished with value: 0.6218117642527596 and parameters: {'d': 128, 'd_hidden_factor': 2.1456801213221706, 'n_layers': 3, 'hidden_dropout': 0.22936282415760678, 'residual_dropout': 0.26681459626650667, 'learning_rate': 4.753765465024489e-05, 'batch_size': 64, 'epochs': 70}. Best is trial 12 with value: 0.9803045751371557.\n",
      "[I 2025-11-27 05:39:03,952] Trial 21 finished with value: 0.988849048258184 and parameters: {'d': 128, 'd_hidden_factor': 1.625456027147176, 'n_layers': 8, 'hidden_dropout': 0.22655084009096174, 'residual_dropout': 0.10208867112358627, 'learning_rate': 0.00018615011033483667, 'batch_size': 64, 'epochs': 147}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:40:04,715] Trial 22 finished with value: 0.9826396556448633 and parameters: {'d': 128, 'd_hidden_factor': 1.1968292553568365, 'n_layers': 7, 'hidden_dropout': 0.1265006063960022, 'residual_dropout': 0.04923202381762696, 'learning_rate': 0.00015609802108463897, 'batch_size': 64, 'epochs': 165}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:40:41,874] Trial 23 finished with value: 0.9802584001026364 and parameters: {'d': 128, 'd_hidden_factor': 1.141933987103829, 'n_layers': 8, 'hidden_dropout': 0.10796776799958202, 'residual_dropout': 0.0488945145964474, 'learning_rate': 0.000540646644984854, 'batch_size': 64, 'epochs': 173}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:41:47,391] Trial 24 finished with value: 0.9866632316254897 and parameters: {'d': 128, 'd_hidden_factor': 1.4883942925166809, 'n_layers': 7, 'hidden_dropout': 0.14919087399648465, 'residual_dropout': 0.004890599490638807, 'learning_rate': 0.00011706810345398778, 'batch_size': 64, 'epochs': 148}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:42:28,228] Trial 25 finished with value: 0.983757894115608 and parameters: {'d': 128, 'd_hidden_factor': 1.445023114555651, 'n_layers': 7, 'hidden_dropout': 0.13337031401822683, 'residual_dropout': 0.10039298723109209, 'learning_rate': 0.00043288984431979756, 'batch_size': 64, 'epochs': 151}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:42:50,050] Trial 26 finished with value: 0.9873768329271793 and parameters: {'d': 64, 'd_hidden_factor': 1.5693627950759796, 'n_layers': 9, 'hidden_dropout': 0.24379979686925224, 'residual_dropout': 0.1080183667580806, 'learning_rate': 0.00041095860351295115, 'batch_size': 256, 'epochs': 147}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:43:08,855] Trial 27 finished with value: 0.9698586933879134 and parameters: {'d': 64, 'd_hidden_factor': 1.6736915053570134, 'n_layers': 10, 'hidden_dropout': 0.3492120013622937, 'residual_dropout': 0.23867286345287483, 'learning_rate': 0.0016995855330999038, 'batch_size': 256, 'epochs': 182}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:43:29,229] Trial 28 finished with value: 0.971158050354016 and parameters: {'d': 64, 'd_hidden_factor': 1.348663965313548, 'n_layers': 9, 'hidden_dropout': 0.2603212802244698, 'residual_dropout': 0.13861379132476254, 'learning_rate': 0.00036403999257669285, 'batch_size': 256, 'epochs': 138}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:43:58,451] Trial 29 finished with value: 0.968552009620187 and parameters: {'d': 64, 'd_hidden_factor': 1.6315075251745095, 'n_layers': 9, 'hidden_dropout': 0.49234790898426983, 'residual_dropout': 0.08602035951740912, 'learning_rate': 0.0013265541727701035, 'batch_size': 128, 'epochs': 114}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:44:18,495] Trial 30 finished with value: 0.961608018078645 and parameters: {'d': 64, 'd_hidden_factor': 2.3137345630092496, 'n_layers': 8, 'hidden_dropout': 0.41455784685580704, 'residual_dropout': 0.026181852821924465, 'learning_rate': 0.0002913694519169661, 'batch_size': 256, 'epochs': 149}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:44:36,873] Trial 31 finished with value: 0.9759215799544487 and parameters: {'d': 64, 'd_hidden_factor': 1.39827940321072, 'n_layers': 7, 'hidden_dropout': 0.14139691530738097, 'residual_dropout': 0.11430866275971867, 'learning_rate': 0.00042265272555479277, 'batch_size': 256, 'epochs': 153}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:46:10,004] Trial 32 finished with value: 0.9802529506196415 and parameters: {'d': 256, 'd_hidden_factor': 1.7304688251494236, 'n_layers': 7, 'hidden_dropout': 0.08370557708950926, 'residual_dropout': 0.07221601038988965, 'learning_rate': 6.04633955884909e-05, 'batch_size': 32, 'epochs': 132}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:46:54,101] Trial 33 finished with value: 0.9731682546323277 and parameters: {'d': 128, 'd_hidden_factor': 1.0494356686698134, 'n_layers': 9, 'hidden_dropout': 0.23930319212648402, 'residual_dropout': 0.16295365152664532, 'learning_rate': 0.0009874806884682013, 'batch_size': 64, 'epochs': 189}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:47:26,729] Trial 34 finished with value: 0.987178663114191 and parameters: {'d': 512, 'd_hidden_factor': 1.3274271206050805, 'n_layers': 10, 'hidden_dropout': 0.19653834025026268, 'residual_dropout': 0.2284600298758853, 'learning_rate': 0.00015875707852181905, 'batch_size': 128, 'epochs': 159}. Best is trial 21 with value: 0.988849048258184.\n",
      "[I 2025-11-27 05:48:07,418] Trial 35 finished with value: 0.9923082577141157 and parameters: {'d': 512, 'd_hidden_factor': 1.9998262957693116, 'n_layers': 10, 'hidden_dropout': 0.19766733059471134, 'residual_dropout': 0.2769147976227846, 'learning_rate': 0.00015447176259137893, 'batch_size': 128, 'epochs': 170}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 05:48:47,102] Trial 36 finished with value: 0.9779358079313287 and parameters: {'d': 512, 'd_hidden_factor': 2.0470783270139763, 'n_layers': 10, 'hidden_dropout': 0.19585937415852983, 'residual_dropout': 0.2799019978992617, 'learning_rate': 0.00017165588568179147, 'batch_size': 128, 'epochs': 173}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 05:50:05,212] Trial 37 finished with value: 0.9872093858763344 and parameters: {'d': 512, 'd_hidden_factor': 1.8717220740628755, 'n_layers': 10, 'hidden_dropout': 0.2802261183817993, 'residual_dropout': 0.21937559855644287, 'learning_rate': 3.183778549759833e-05, 'batch_size': 128, 'epochs': 163}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 05:51:58,397] Trial 38 finished with value: 0.986915443550543 and parameters: {'d': 512, 'd_hidden_factor': 3.1635081826041622, 'n_layers': 9, 'hidden_dropout': 0.2740569790979641, 'residual_dropout': 0.3840249112046693, 'learning_rate': 2.9425300392158143e-05, 'batch_size': 128, 'epochs': 169}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 05:53:28,713] Trial 39 finished with value: 0.9212294254856213 and parameters: {'d': 512, 'd_hidden_factor': 1.8191629781208112, 'n_layers': 10, 'hidden_dropout': 0.33890902373544285, 'residual_dropout': 0.2902678242723033, 'learning_rate': 1.0405412968169131e-05, 'batch_size': 128, 'epochs': 182}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 05:55:17,876] Trial 40 finished with value: 0.9759631057960668 and parameters: {'d': 512, 'd_hidden_factor': 2.189131416815062, 'n_layers': 10, 'hidden_dropout': 0.288555338349491, 'residual_dropout': 0.3713465174808227, 'learning_rate': 1.7733208304851152e-05, 'batch_size': 128, 'epochs': 200}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 05:55:44,706] Trial 41 finished with value: 0.970615275262101 and parameters: {'d': 512, 'd_hidden_factor': 1.2791453951062457, 'n_layers': 10, 'hidden_dropout': 0.24820523530678687, 'residual_dropout': 0.2341799178775131, 'learning_rate': 0.00025552143557915085, 'batch_size': 128, 'epochs': 156}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 05:56:45,927] Trial 42 finished with value: 0.9855238472132839 and parameters: {'d': 512, 'd_hidden_factor': 2.376015123305429, 'n_layers': 9, 'hidden_dropout': 0.3252931580781712, 'residual_dropout': 0.21041242549070757, 'learning_rate': 6.63689654933128e-05, 'batch_size': 128, 'epochs': 140}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 05:57:48,250] Trial 43 finished with value: 0.9869383187261128 and parameters: {'d': 512, 'd_hidden_factor': 1.012034236515234, 'n_layers': 10, 'hidden_dropout': 0.20977225470823244, 'residual_dropout': 0.2547180274583274, 'learning_rate': 3.252528015627141e-05, 'batch_size': 128, 'epochs': 161}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 05:58:27,024] Trial 44 finished with value: 0.9858101338867018 and parameters: {'d': 512, 'd_hidden_factor': 1.8182020700072221, 'n_layers': 9, 'hidden_dropout': 0.2605866395224141, 'residual_dropout': 0.317988224878344, 'learning_rate': 0.00016283629836689242, 'batch_size': 128, 'epochs': 127}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 06:01:10,499] Trial 45 finished with value: 0.9823724857811762 and parameters: {'d': 256, 'd_hidden_factor': 2.024973679759434, 'n_layers': 10, 'hidden_dropout': 0.3743018967091659, 'residual_dropout': 0.21636829195323717, 'learning_rate': 0.0001232418250282004, 'batch_size': 32, 'epochs': 182}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 06:02:21,151] Trial 46 finished with value: 0.9840641481527262 and parameters: {'d': 512, 'd_hidden_factor': 3.482331312679303, 'n_layers': 8, 'hidden_dropout': 0.3021351836083238, 'residual_dropout': 0.17087243454497553, 'learning_rate': 7.705339685805172e-05, 'batch_size': 128, 'epochs': 120}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 06:03:30,506] Trial 47 finished with value: 0.9852342553270754 and parameters: {'d': 512, 'd_hidden_factor': 1.564923236436688, 'n_layers': 9, 'hidden_dropout': 0.23119736191909757, 'residual_dropout': 0.13883725616311496, 'learning_rate': 3.70331151527305e-05, 'batch_size': 128, 'epochs': 174}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 06:04:24,489] Trial 48 finished with value: 0.9681438731611536 and parameters: {'d': 512, 'd_hidden_factor': 1.2642089996019783, 'n_layers': 10, 'hidden_dropout': 0.20339872388764815, 'residual_dropout': 0.29685203226118057, 'learning_rate': 1.988061388863866e-05, 'batch_size': 256, 'epochs': 192}. Best is trial 35 with value: 0.9923082577141157.\n",
      "[I 2025-11-27 06:05:56,235] Trial 49 finished with value: 0.9510335841896799 and parameters: {'d': 256, 'd_hidden_factor': 2.725601159574068, 'n_layers': 9, 'hidden_dropout': 0.19212338237668863, 'residual_dropout': 0.3645248788686157, 'learning_rate': 0.0022163007656047563, 'batch_size': 32, 'epochs': 158}. Best is trial 35 with value: 0.9923082577141157.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 2328.04s\n",
      "  Best CV G-Mean: 0.9923\n",
      "  Best parameters:\n",
      "    d: 512\n",
      "    d_hidden_factor: 1.9998262957693116\n",
      "    n_layers: 10\n",
      "    hidden_dropout: 0.19766733059471134\n",
      "    residual_dropout: 0.2769147976227846\n",
      "    learning_rate: 0.00015447176259137893\n",
      "    batch_size: 128\n",
      "    epochs: 170\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/170: Train Loss = 0.5046, Val Loss = 0.4654\n",
      "    Epoch 20/170: Train Loss = 0.1569, Val Loss = 0.2062\n",
      "    Epoch 30/170: Train Loss = 0.0860, Val Loss = 0.0995\n",
      "    Epoch 40/170: Train Loss = 0.0619, Val Loss = 0.1226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 06:05:58,647] A new study created in memory with name: no-name-d053f468-1442-4bb0-b559-f03345312ffe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Early stopping at epoch 45\n",
      "✓ Training complete! Time: 2.35s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR vowel\n",
      "================================================================================\n",
      "Accuracy:        0.9697\n",
      "AUC OVO:         0.9990\n",
      "G-Mean:          0.9684\n",
      "Cross-Entropy:   0.0999\n",
      "================================================================================\n",
      "✓ Saved results for vowel\n",
      "\n",
      "✓ Completed vowel (12/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 13/30: semeion\n",
      "################################################################################\n",
      "Loading processed dataset from cache: semeion\n",
      "Using device: cuda\n",
      "Dataset: semeion\n",
      "  Train: (1115, 256), Test: (478, 256)\n",
      "  Features: 256, Classes: 10\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: semeion\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 06:06:10,400] Trial 0 finished with value: 0.9145440530542276 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.9145440530542276.\n",
      "[I 2025-11-27 06:06:32,860] Trial 1 finished with value: 0.9170983560125634 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.9170983560125634.\n",
      "[I 2025-11-27 06:07:02,442] Trial 2 finished with value: 0.9271567796022543 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 2 with value: 0.9271567796022543.\n",
      "[I 2025-11-27 06:10:33,083] Trial 3 finished with value: 0.9352878673307273 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.9352878673307273.\n",
      "[I 2025-11-27 06:10:55,141] Trial 4 finished with value: 0.9024587162700645 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 3 with value: 0.9352878673307273.\n",
      "[I 2025-11-27 06:13:13,629] Trial 5 finished with value: 0.9312708273801725 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 3 with value: 0.9352878673307273.\n",
      "[I 2025-11-27 06:14:57,708] Trial 6 finished with value: 0.9232000082243873 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 3 with value: 0.9352878673307273.\n",
      "[I 2025-11-27 06:15:08,128] Trial 7 finished with value: 0.8995565369628983 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 3 with value: 0.9352878673307273.\n",
      "[I 2025-11-27 06:15:13,609] Trial 8 finished with value: 0.9260512850405835 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 3 with value: 0.9352878673307273.\n",
      "[I 2025-11-27 06:15:16,985] Trial 9 finished with value: 0.91763775249799 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 3 with value: 0.9352878673307273.\n",
      "[I 2025-11-27 06:22:27,882] Trial 10 finished with value: 0.936925776951019 and parameters: {'d': 256, 'd_hidden_factor': 4.956401873386991, 'n_layers': 10, 'hidden_dropout': 0.10467358725545478, 'residual_dropout': 0.21319384192877996, 'learning_rate': 1.0455868741494775e-05, 'batch_size': 32, 'epochs': 159}. Best is trial 10 with value: 0.936925776951019.\n",
      "[I 2025-11-27 06:29:30,415] Trial 11 finished with value: 0.932314167705567 and parameters: {'d': 256, 'd_hidden_factor': 4.978541460939402, 'n_layers': 10, 'hidden_dropout': 0.08723353405849409, 'residual_dropout': 0.22944464268646939, 'learning_rate': 1.0158320577860581e-05, 'batch_size': 32, 'epochs': 171}. Best is trial 10 with value: 0.936925776951019.\n",
      "[I 2025-11-27 06:33:43,217] Trial 12 finished with value: 0.9378933901896582 and parameters: {'d': 256, 'd_hidden_factor': 4.700322375404564, 'n_layers': 10, 'hidden_dropout': 0.13399100690564741, 'residual_dropout': 0.22988626022427197, 'learning_rate': 3.551819509547847e-05, 'batch_size': 32, 'epochs': 150}. Best is trial 12 with value: 0.9378933901896582.\n",
      "[I 2025-11-27 06:37:12,382] Trial 13 finished with value: 0.9264967062985215 and parameters: {'d': 256, 'd_hidden_factor': 4.891319939487838, 'n_layers': 8, 'hidden_dropout': 0.10315617108555222, 'residual_dropout': 0.1925086337595997, 'learning_rate': 3.372458017497115e-05, 'batch_size': 32, 'epochs': 153}. Best is trial 12 with value: 0.9378933901896582.\n",
      "[I 2025-11-27 06:39:12,393] Trial 14 finished with value: 0.9360675770369307 and parameters: {'d': 512, 'd_hidden_factor': 4.356442301816642, 'n_layers': 8, 'hidden_dropout': 0.0035697594234744834, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 7.376487017206706e-05, 'batch_size': 128, 'epochs': 152}. Best is trial 12 with value: 0.9378933901896582.\n",
      "[I 2025-11-27 06:45:09,285] Trial 15 finished with value: 0.9375481928961366 and parameters: {'d': 256, 'd_hidden_factor': 4.461226410456492, 'n_layers': 8, 'hidden_dropout': 0.11416813325319607, 'residual_dropout': 0.13086349045080098, 'learning_rate': 1.201880159180346e-05, 'batch_size': 32, 'epochs': 181}. Best is trial 12 with value: 0.9378933901896582.\n",
      "[I 2025-11-27 06:46:24,647] Trial 16 finished with value: 0.9210975705514676 and parameters: {'d': 256, 'd_hidden_factor': 4.382903887816198, 'n_layers': 8, 'hidden_dropout': 0.17263473991737327, 'residual_dropout': 0.12312182169098496, 'learning_rate': 0.0011801142500613441, 'batch_size': 32, 'epochs': 198}. Best is trial 12 with value: 0.9378933901896582.\n",
      "[I 2025-11-27 06:49:09,869] Trial 17 finished with value: 0.9414451973375971 and parameters: {'d': 256, 'd_hidden_factor': 4.389079240651879, 'n_layers': 9, 'hidden_dropout': 0.05738300113511413, 'residual_dropout': 0.04518719890844869, 'learning_rate': 5.941072156885347e-05, 'batch_size': 32, 'epochs': 180}. Best is trial 17 with value: 0.9414451973375971.\n",
      "[I 2025-11-27 06:51:09,269] Trial 18 finished with value: 0.9377739631586124 and parameters: {'d': 512, 'd_hidden_factor': 4.3119311825053135, 'n_layers': 9, 'hidden_dropout': 0.05015607210844162, 'residual_dropout': 0.0001566610793570719, 'learning_rate': 5.8665624377100175e-05, 'batch_size': 256, 'epochs': 136}. Best is trial 17 with value: 0.9414451973375971.\n",
      "[I 2025-11-27 06:51:44,607] Trial 19 finished with value: 0.9235126750003937 and parameters: {'d': 64, 'd_hidden_factor': 2.4203523509970757, 'n_layers': 9, 'hidden_dropout': 0.1753103272587606, 'residual_dropout': 0.06824137211824358, 'learning_rate': 0.0006441943583327288, 'batch_size': 128, 'epochs': 180}. Best is trial 17 with value: 0.9414451973375971.\n",
      "[I 2025-11-27 06:53:31,046] Trial 20 finished with value: 0.9367794819962821 and parameters: {'d': 256, 'd_hidden_factor': 3.517501708717406, 'n_layers': 7, 'hidden_dropout': 0.05401065308038827, 'residual_dropout': 0.26681459626650667, 'learning_rate': 0.00012233906574506825, 'batch_size': 32, 'epochs': 143}. Best is trial 17 with value: 0.9414451973375971.\n",
      "[I 2025-11-27 06:55:11,724] Trial 21 finished with value: 0.9429281895182079 and parameters: {'d': 512, 'd_hidden_factor': 4.1618833622338185, 'n_layers': 9, 'hidden_dropout': 0.04479753738858415, 'residual_dropout': 0.0007919504138159814, 'learning_rate': 5.5253268815671174e-05, 'batch_size': 256, 'epochs': 136}. Best is trial 21 with value: 0.9429281895182079.\n",
      "[I 2025-11-27 06:56:46,253] Trial 22 finished with value: 0.9337570869129033 and parameters: {'d': 512, 'd_hidden_factor': 4.104772915744336, 'n_layers': 9, 'hidden_dropout': 0.049246252951718, 'residual_dropout': 0.062471577958076535, 'learning_rate': 5.852691478580625e-05, 'batch_size': 256, 'epochs': 110}. Best is trial 21 with value: 0.9429281895182079.\n",
      "[I 2025-11-27 06:59:43,599] Trial 23 finished with value: 0.9426571385838038 and parameters: {'d': 512, 'd_hidden_factor': 4.5592689040966095, 'n_layers': 10, 'hidden_dropout': 0.14838827402273658, 'residual_dropout': 0.035027938967892656, 'learning_rate': 2.056297025848026e-05, 'batch_size': 256, 'epochs': 167}. Best is trial 21 with value: 0.9429281895182079.\n",
      "[I 2025-11-27 07:02:25,528] Trial 24 finished with value: 0.9416437509725182 and parameters: {'d': 512, 'd_hidden_factor': 4.652976245310039, 'n_layers': 9, 'hidden_dropout': 0.2202462855673122, 'residual_dropout': 0.04463186825052213, 'learning_rate': 1.9898564880200705e-05, 'batch_size': 256, 'epochs': 169}. Best is trial 21 with value: 0.9429281895182079.\n",
      "[I 2025-11-27 07:04:43,898] Trial 25 finished with value: 0.9351236844604106 and parameters: {'d': 512, 'd_hidden_factor': 4.6977046208200415, 'n_layers': 7, 'hidden_dropout': 0.3781215351225058, 'residual_dropout': 0.028200563236574744, 'learning_rate': 1.8492532570458584e-05, 'batch_size': 256, 'epochs': 165}. Best is trial 21 with value: 0.9429281895182079.\n",
      "[I 2025-11-27 07:06:28,665] Trial 26 finished with value: 0.9406620940692113 and parameters: {'d': 512, 'd_hidden_factor': 4.049819944922053, 'n_layers': 7, 'hidden_dropout': 0.21425775261939672, 'residual_dropout': 0.1019379545006362, 'learning_rate': 2.003402194526896e-05, 'batch_size': 256, 'epochs': 135}. Best is trial 21 with value: 0.9429281895182079.\n",
      "[I 2025-11-27 07:06:40,837] Trial 27 finished with value: 0.9331734476634965 and parameters: {'d': 512, 'd_hidden_factor': 3.608313847766137, 'n_layers': 1, 'hidden_dropout': 0.2197184264862369, 'residual_dropout': 0.17689361094067702, 'learning_rate': 0.0001068884695278032, 'batch_size': 256, 'epochs': 112}. Best is trial 21 with value: 0.9429281895182079.\n",
      "[I 2025-11-27 07:09:08,680] Trial 28 finished with value: 0.9487083733969198 and parameters: {'d': 512, 'd_hidden_factor': 4.635623977297499, 'n_layers': 9, 'hidden_dropout': 0.14728268549306744, 'residual_dropout': 0.022776439070110174, 'learning_rate': 3.6930431163502905e-05, 'batch_size': 256, 'epochs': 170}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:10:00,800] Trial 29 finished with value: 0.940414020063427 and parameters: {'d': 512, 'd_hidden_factor': 4.119898907477469, 'n_layers': 10, 'hidden_dropout': 0.49234790898426983, 'residual_dropout': 0.0987678880159879, 'learning_rate': 0.00020686405069202316, 'batch_size': 256, 'epochs': 189}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:10:41,296] Trial 30 finished with value: 0.9394047155545605 and parameters: {'d': 512, 'd_hidden_factor': 3.806761742272638, 'n_layers': 8, 'hidden_dropout': 0.1415259371303105, 'residual_dropout': 0.019073134767089873, 'learning_rate': 0.00046522982338512614, 'batch_size': 256, 'epochs': 139}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:13:02,501] Trial 31 finished with value: 0.9473155409401628 and parameters: {'d': 512, 'd_hidden_factor': 4.558034990044767, 'n_layers': 9, 'hidden_dropout': 0.20476893779351202, 'residual_dropout': 0.04898594155358152, 'learning_rate': 4.398807980931292e-05, 'batch_size': 256, 'epochs': 167}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:15:12,604] Trial 32 finished with value: 0.939724920191968 and parameters: {'d': 512, 'd_hidden_factor': 4.21138744016814, 'n_layers': 9, 'hidden_dropout': 0.41265026475682953, 'residual_dropout': 0.07600837012216004, 'learning_rate': 3.460778829326872e-05, 'batch_size': 256, 'epochs': 160}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:16:24,275] Trial 33 finished with value: 0.9361083254086123 and parameters: {'d': 512, 'd_hidden_factor': 4.670039519223752, 'n_layers': 4, 'hidden_dropout': 0.17969276559805075, 'residual_dropout': 0.030815068588768393, 'learning_rate': 4.7276971783179906e-05, 'batch_size': 256, 'epochs': 172}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:17:25,041] Trial 34 finished with value: 0.9384011781653158 and parameters: {'d': 512, 'd_hidden_factor': 4.600233689553908, 'n_layers': 10, 'hidden_dropout': 0.2507103480532538, 'residual_dropout': 0.1426500677147022, 'learning_rate': 8.97301745052303e-05, 'batch_size': 256, 'epochs': 54}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:18:06,488] Trial 35 finished with value: 0.9168068433837838 and parameters: {'d': 64, 'd_hidden_factor': 3.276095442199144, 'n_layers': 7, 'hidden_dropout': 0.13795325540708567, 'residual_dropout': 0.10212191417451738, 'learning_rate': 0.00027744495647196956, 'batch_size': 128, 'epochs': 122}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:19:05,063] Trial 36 finished with value: 0.9375492719927754 and parameters: {'d': 512, 'd_hidden_factor': 4.026355710796464, 'n_layers': 9, 'hidden_dropout': 0.19544195628028022, 'residual_dropout': 0.007097950722946764, 'learning_rate': 0.00017695761870861764, 'batch_size': 256, 'epochs': 187}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:21:40,988] Trial 37 finished with value: 0.9288129469362953 and parameters: {'d': 128, 'd_hidden_factor': 2.8038024917355537, 'n_layers': 10, 'hidden_dropout': 0.07589392630375186, 'residual_dropout': 0.04705827999078657, 'learning_rate': 1.481536004760651e-05, 'batch_size': 64, 'epochs': 146}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:23:04,305] Trial 38 finished with value: 0.9405062435077205 and parameters: {'d': 512, 'd_hidden_factor': 3.825087046205361, 'n_layers': 5, 'hidden_dropout': 0.02533161325029884, 'residual_dropout': 0.37804696085070166, 'learning_rate': 2.7885075722294088e-05, 'batch_size': 256, 'epochs': 161}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:25:37,601] Trial 39 finished with value: 0.94207281334679 and parameters: {'d': 512, 'd_hidden_factor': 4.809409650825624, 'n_layers': 8, 'hidden_dropout': 0.26729262166614404, 'residual_dropout': 0.08942519575397047, 'learning_rate': 4.302374664661286e-05, 'batch_size': 64, 'epochs': 70}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:26:08,039] Trial 40 finished with value: 0.9241234999837029 and parameters: {'d': 64, 'd_hidden_factor': 1.8277464279658528, 'n_layers': 10, 'hidden_dropout': 0.23695344575754443, 'residual_dropout': 0.0585527062402542, 'learning_rate': 0.00016749725734566093, 'batch_size': 256, 'epochs': 131}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:28:43,333] Trial 41 finished with value: 0.9394758621515267 and parameters: {'d': 512, 'd_hidden_factor': 4.81945932282525, 'n_layers': 8, 'hidden_dropout': 0.2809443799437287, 'residual_dropout': 0.09654099518409642, 'learning_rate': 5.02121861634056e-05, 'batch_size': 64, 'epochs': 70}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:31:48,353] Trial 42 finished with value: 0.9467290908532426 and parameters: {'d': 512, 'd_hidden_factor': 4.544521593028488, 'n_layers': 9, 'hidden_dropout': 0.34039247191276684, 'residual_dropout': 0.02355195979073277, 'learning_rate': 3.90556996943729e-05, 'batch_size': 64, 'epochs': 78}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:33:10,142] Trial 43 finished with value: 0.9254268960968455 and parameters: {'d': 128, 'd_hidden_factor': 4.512469421603873, 'n_layers': 9, 'hidden_dropout': 0.4443581966893785, 'residual_dropout': 0.022033634281246793, 'learning_rate': 2.5234866757579283e-05, 'batch_size': 64, 'epochs': 82}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:38:10,370] Trial 44 finished with value: 0.9411497789519535 and parameters: {'d': 512, 'd_hidden_factor': 4.233361311656778, 'n_layers': 10, 'hidden_dropout': 0.29500821212254624, 'residual_dropout': 0.035292784383662186, 'learning_rate': 1.5905343024653554e-05, 'batch_size': 64, 'epochs': 118}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:39:06,978] Trial 45 finished with value: 0.942452029244498 and parameters: {'d': 512, 'd_hidden_factor': 4.481102964369957, 'n_layers': 9, 'hidden_dropout': 0.33607042300089374, 'residual_dropout': 0.2928812667446751, 'learning_rate': 8.010940401006323e-05, 'batch_size': 256, 'epochs': 55}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:42:35,982] Trial 46 finished with value: 0.9447571872541045 and parameters: {'d': 512, 'd_hidden_factor': 4.950511809423037, 'n_layers': 10, 'hidden_dropout': 0.3670046893359715, 'residual_dropout': 0.1622322613182275, 'learning_rate': 3.9111939175025976e-05, 'batch_size': 64, 'epochs': 101}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:43:36,633] Trial 47 finished with value: 0.9366427620109269 and parameters: {'d': 512, 'd_hidden_factor': 4.97749886576765, 'n_layers': 4, 'hidden_dropout': 0.36762386514426443, 'residual_dropout': 0.16569939058634092, 'learning_rate': 0.00013068510511890302, 'batch_size': 64, 'epochs': 107}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:44:19,827] Trial 48 finished with value: 0.9292594064433397 and parameters: {'d': 128, 'd_hidden_factor': 4.8131005124954935, 'n_layers': 3, 'hidden_dropout': 0.3923912729763645, 'residual_dropout': 0.14425203929115987, 'learning_rate': 4.1623374812281626e-05, 'batch_size': 64, 'epochs': 97}. Best is trial 28 with value: 0.9487083733969198.\n",
      "[I 2025-11-27 07:46:33,849] Trial 49 finished with value: 0.9391017423220742 and parameters: {'d': 512, 'd_hidden_factor': 3.0891581245527275, 'n_layers': 8, 'hidden_dropout': 0.3342396422174273, 'residual_dropout': 0.11845110691285185, 'learning_rate': 2.7526932887064476e-05, 'batch_size': 64, 'epochs': 78}. Best is trial 28 with value: 0.9487083733969198.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 6035.20s\n",
      "  Best CV G-Mean: 0.9487\n",
      "  Best parameters:\n",
      "    d: 512\n",
      "    d_hidden_factor: 4.635623977297499\n",
      "    n_layers: 9\n",
      "    hidden_dropout: 0.14728268549306744\n",
      "    residual_dropout: 0.022776439070110174\n",
      "    learning_rate: 3.6930431163502905e-05\n",
      "    batch_size: 256\n",
      "    epochs: 170\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/170: Train Loss = 0.3291, Val Loss = 0.4738\n",
      "    Epoch 20/170: Train Loss = 0.1093, Val Loss = 0.3726\n",
      "    Epoch 30/170: Train Loss = 0.0541, Val Loss = 0.3325\n",
      "    Epoch 40/170: Train Loss = 0.0347, Val Loss = 0.3228\n",
      "    Epoch 50/170: Train Loss = 0.0244, Val Loss = 0.3247\n",
      "    Epoch 60/170: Train Loss = 0.0196, Val Loss = 0.3151\n",
      "    Epoch 70/170: Train Loss = 0.0150, Val Loss = 0.3119\n",
      "    Epoch 80/170: Train Loss = 0.0133, Val Loss = 0.3126\n",
      "    Epoch 90/170: Train Loss = 0.0110, Val Loss = 0.3109\n",
      "    Epoch 100/170: Train Loss = 0.0099, Val Loss = 0.3092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 07:46:45,484] A new study created in memory with name: no-name-92226afa-b39d-4334-9efa-3bbc1a0b029f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 110/170: Train Loss = 0.0085, Val Loss = 0.3120\n",
      "    Early stopping at epoch 111\n",
      "✓ Training complete! Time: 11.57s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR semeion\n",
      "================================================================================\n",
      "Accuracy:        0.9289\n",
      "AUC OVO:         0.9968\n",
      "G-Mean:          0.9268\n",
      "Cross-Entropy:   0.2291\n",
      "================================================================================\n",
      "✓ Saved results for semeion\n",
      "\n",
      "✓ Completed semeion (13/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 14/30: credit-g\n",
      "################################################################################\n",
      "Loading processed dataset from cache: credit-g\n",
      "Using device: cuda\n",
      "Dataset: credit-g\n",
      "  Train: (700, 61), Test: (300, 61)\n",
      "  Features: 61, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: credit-g\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 07:46:52,116] Trial 0 finished with value: 0.6818661095184958 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.6818661095184958.\n",
      "[I 2025-11-27 07:46:59,857] Trial 1 finished with value: 0.6535302669534927 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 0 with value: 0.6818661095184958.\n",
      "[I 2025-11-27 07:47:09,507] Trial 2 finished with value: 0.6776187314759733 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: 0.6818661095184958.\n",
      "[I 2025-11-27 07:48:13,654] Trial 3 finished with value: 0.6859302922010874 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.6859302922010874.\n",
      "[I 2025-11-27 07:48:23,454] Trial 4 finished with value: 0.6425404723679866 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 3 with value: 0.6859302922010874.\n",
      "[I 2025-11-27 07:49:28,556] Trial 5 finished with value: 0.6823890035879459 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 3 with value: 0.6859302922010874.\n",
      "[I 2025-11-27 07:50:06,155] Trial 6 finished with value: 0.6657014023183558 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 3 with value: 0.6859302922010874.\n",
      "[I 2025-11-27 07:50:10,731] Trial 7 finished with value: 0.6652519478975774 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 3 with value: 0.6859302922010874.\n",
      "[I 2025-11-27 07:50:12,818] Trial 8 finished with value: 0.6594403337829415 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 3 with value: 0.6859302922010874.\n",
      "[I 2025-11-27 07:50:14,099] Trial 9 finished with value: 0.6558511309558304 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 3 with value: 0.6859302922010874.\n",
      "[I 2025-11-27 07:51:29,317] Trial 10 finished with value: 0.6771641595302023 and parameters: {'d': 256, 'd_hidden_factor': 4.956401873386991, 'n_layers': 10, 'hidden_dropout': 0.10467358725545478, 'residual_dropout': 0.21319384192877996, 'learning_rate': 1.0455868741494775e-05, 'batch_size': 32, 'epochs': 159}. Best is trial 3 with value: 0.6859302922010874.\n",
      "[I 2025-11-27 07:52:22,241] Trial 11 finished with value: 0.6783523408542751 and parameters: {'d': 512, 'd_hidden_factor': 1.0737622521709098, 'n_layers': 10, 'hidden_dropout': 0.404612932718377, 'residual_dropout': 0.01001667026169617, 'learning_rate': 1.9787885460395214e-05, 'batch_size': 32, 'epochs': 81}. Best is trial 3 with value: 0.6859302922010874.\n",
      "[I 2025-11-27 07:52:50,311] Trial 12 finished with value: 0.6666871893594326 and parameters: {'d': 256, 'd_hidden_factor': 1.9759011853202546, 'n_layers': 8, 'hidden_dropout': 0.21706128432830413, 'residual_dropout': 0.07879794445440898, 'learning_rate': 5.375248322425842e-05, 'batch_size': 32, 'epochs': 146}. Best is trial 3 with value: 0.6859302922010874.\n",
      "[I 2025-11-27 07:53:29,071] Trial 13 finished with value: 0.6782114043987579 and parameters: {'d': 128, 'd_hidden_factor': 4.876886679033238, 'n_layers': 8, 'hidden_dropout': 0.1282492931447887, 'residual_dropout': 0.25198618623335556, 'learning_rate': 4.2159052605757004e-05, 'batch_size': 32, 'epochs': 65}. Best is trial 3 with value: 0.6859302922010874.\n",
      "[I 2025-11-27 07:53:49,689] Trial 14 finished with value: 0.6963376795642453 and parameters: {'d': 128, 'd_hidden_factor': 1.8754473333938573, 'n_layers': 8, 'hidden_dropout': 0.3883364508224467, 'residual_dropout': 0.1350780224757651, 'learning_rate': 4.7705452676408644e-05, 'batch_size': 128, 'epochs': 106}. Best is trial 14 with value: 0.6963376795642453.\n",
      "[I 2025-11-27 07:54:00,718] Trial 15 finished with value: 0.6818541559805802 and parameters: {'d': 256, 'd_hidden_factor': 2.354360303467315, 'n_layers': 8, 'hidden_dropout': 0.40766446614142565, 'residual_dropout': 0.23659149841168892, 'learning_rate': 7.705055411258324e-05, 'batch_size': 128, 'epochs': 112}. Best is trial 14 with value: 0.6963376795642453.\n",
      "[I 2025-11-27 07:54:26,475] Trial 16 finished with value: 0.4476458384538916 and parameters: {'d': 64, 'd_hidden_factor': 1.6957885468052785, 'n_layers': 9, 'hidden_dropout': 0.4968914220485446, 'residual_dropout': 0.1558458336460516, 'learning_rate': 1.0002260286338051e-05, 'batch_size': 128, 'epochs': 146}. Best is trial 14 with value: 0.6963376795642453.\n",
      "[I 2025-11-27 07:54:37,478] Trial 17 finished with value: 0.6387418273547012 and parameters: {'d': 512, 'd_hidden_factor': 2.6515911380646466, 'n_layers': 9, 'hidden_dropout': 0.39623393981351757, 'residual_dropout': 0.2983859656728279, 'learning_rate': 0.000615123069912769, 'batch_size': 128, 'epochs': 58}. Best is trial 14 with value: 0.6963376795642453.\n",
      "[I 2025-11-27 07:54:44,242] Trial 18 finished with value: 0.639525720338077 and parameters: {'d': 256, 'd_hidden_factor': 4.372859491854227, 'n_layers': 9, 'hidden_dropout': 0.23538106848873544, 'residual_dropout': 0.1595333870470549, 'learning_rate': 0.0006026117646786481, 'batch_size': 128, 'epochs': 110}. Best is trial 14 with value: 0.6963376795642453.\n",
      "[I 2025-11-27 07:55:03,334] Trial 19 finished with value: 0.686312086749226 and parameters: {'d': 128, 'd_hidden_factor': 2.765403996605672, 'n_layers': 7, 'hidden_dropout': 0.4383113318528582, 'residual_dropout': 0.09099604586667143, 'learning_rate': 2.3906293977172207e-05, 'batch_size': 256, 'epochs': 178}. Best is trial 14 with value: 0.6963376795642453.\n",
      "[I 2025-11-27 07:55:11,692] Trial 20 finished with value: 0.6799334144968384 and parameters: {'d': 128, 'd_hidden_factor': 1.849506166891156, 'n_layers': 7, 'hidden_dropout': 0.43996309693905, 'residual_dropout': 0.06366504222380678, 'learning_rate': 0.00012309463511380543, 'batch_size': 256, 'epochs': 190}. Best is trial 14 with value: 0.6963376795642453.\n",
      "[I 2025-11-27 07:55:26,892] Trial 21 finished with value: 0.6519849822506859 and parameters: {'d': 128, 'd_hidden_factor': 2.7332689330179556, 'n_layers': 7, 'hidden_dropout': 0.3642689957352939, 'residual_dropout': 0.0019418731272534268, 'learning_rate': 1.958882188362764e-05, 'batch_size': 256, 'epochs': 179}. Best is trial 14 with value: 0.6963376795642453.\n",
      "[I 2025-11-27 07:55:45,340] Trial 22 finished with value: 0.7063014409573877 and parameters: {'d': 128, 'd_hidden_factor': 3.4282967029760893, 'n_layers': 10, 'hidden_dropout': 0.4335802349981082, 'residual_dropout': 0.11983399820305649, 'learning_rate': 3.229598195393756e-05, 'batch_size': 256, 'epochs': 136}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:55:57,672] Trial 23 finished with value: 0.6676642759003472 and parameters: {'d': 128, 'd_hidden_factor': 3.5645908413841, 'n_layers': 7, 'hidden_dropout': 0.4587318440971021, 'residual_dropout': 0.11816981714099124, 'learning_rate': 5.45441289594886e-05, 'batch_size': 256, 'epochs': 169}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:56:16,147] Trial 24 finished with value: 0.6721880657147736 and parameters: {'d': 128, 'd_hidden_factor': 2.366244470240689, 'n_layers': 9, 'hidden_dropout': 0.4471485135625279, 'residual_dropout': 0.19606330649022624, 'learning_rate': 2.9145221813345865e-05, 'batch_size': 256, 'epochs': 147}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:56:24,177] Trial 25 finished with value: 0.6937078365574874 and parameters: {'d': 128, 'd_hidden_factor': 3.217126898232256, 'n_layers': 8, 'hidden_dropout': 0.3613892884892181, 'residual_dropout': 0.11395909890584209, 'learning_rate': 9.344885923605896e-05, 'batch_size': 256, 'epochs': 132}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:56:30,515] Trial 26 finished with value: 0.6756614263164946 and parameters: {'d': 128, 'd_hidden_factor': 4.290250726131771, 'n_layers': 8, 'hidden_dropout': 0.3577869886182469, 'residual_dropout': 0.04138309739633603, 'learning_rate': 9.871796834513397e-05, 'batch_size': 256, 'epochs': 135}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:56:38,918] Trial 27 finished with value: 0.6521605281553468 and parameters: {'d': 128, 'd_hidden_factor': 3.286655810595004, 'n_layers': 10, 'hidden_dropout': 0.3666039395545966, 'residual_dropout': 0.13262416150717524, 'learning_rate': 0.00024655959835348566, 'batch_size': 128, 'epochs': 132}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:56:40,855] Trial 28 finished with value: 0.6826885435062919 and parameters: {'d': 128, 'd_hidden_factor': 3.512220627801011, 'n_layers': 3, 'hidden_dropout': 0.3376261707095033, 'residual_dropout': 0.19078078349687952, 'learning_rate': 0.0005194607827995685, 'batch_size': 256, 'epochs': 109}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:56:43,561] Trial 29 finished with value: 0.6844894263761534 and parameters: {'d': 64, 'd_hidden_factor': 3.9872383747535225, 'n_layers': 1, 'hidden_dropout': 0.48989091465288465, 'residual_dropout': 0.11583386472079095, 'learning_rate': 0.00017989092679202985, 'batch_size': 128, 'epochs': 37}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:56:49,159] Trial 30 finished with value: 0.671047362265272 and parameters: {'d': 128, 'd_hidden_factor': 4.250256154529138, 'n_layers': 9, 'hidden_dropout': 0.39450962587174204, 'residual_dropout': 0.2574042015496574, 'learning_rate': 0.0003396010126803056, 'batch_size': 256, 'epochs': 157}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:57:05,300] Trial 31 finished with value: 0.6962660495921607 and parameters: {'d': 128, 'd_hidden_factor': 3.1224922586045243, 'n_layers': 7, 'hidden_dropout': 0.42533001446514646, 'residual_dropout': 0.09999546098278642, 'learning_rate': 4.01363303975786e-05, 'batch_size': 256, 'epochs': 176}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:57:19,773] Trial 32 finished with value: 0.7058182431003848 and parameters: {'d': 128, 'd_hidden_factor': 2.98639711900071, 'n_layers': 8, 'hidden_dropout': 0.4669363245558004, 'residual_dropout': 0.044141082912260626, 'learning_rate': 4.398322981016769e-05, 'batch_size': 256, 'epochs': 120}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:57:28,802] Trial 33 finished with value: 0.6603660104440936 and parameters: {'d': 128, 'd_hidden_factor': 2.9420417245990103, 'n_layers': 5, 'hidden_dropout': 0.47123907031565554, 'residual_dropout': 0.04043188787915929, 'learning_rate': 4.0596938857242915e-05, 'batch_size': 256, 'epochs': 119}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:57:38,515] Trial 34 finished with value: 0.6878695107596691 and parameters: {'d': 128, 'd_hidden_factor': 3.0232852022830614, 'n_layers': 7, 'hidden_dropout': 0.423478303811484, 'residual_dropout': 0.046562840758665444, 'learning_rate': 6.242222025765377e-05, 'batch_size': 256, 'epochs': 103}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:58:18,780] Trial 35 finished with value: 0.6589952185252754 and parameters: {'d': 128, 'd_hidden_factor': 2.558360955436603, 'n_layers': 8, 'hidden_dropout': 0.4539727876037238, 'residual_dropout': 0.16138890936589023, 'learning_rate': 1.4963848246083405e-05, 'batch_size': 64, 'epochs': 75}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:58:34,384] Trial 36 finished with value: 0.6970316757842032 and parameters: {'d': 512, 'd_hidden_factor': 3.7135523152193395, 'n_layers': 5, 'hidden_dropout': 0.4782242814168058, 'residual_dropout': 0.09307077607467121, 'learning_rate': 3.6782757447517395e-05, 'batch_size': 128, 'epochs': 140}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:58:44,225] Trial 37 finished with value: 0.6775927122286324 and parameters: {'d': 512, 'd_hidden_factor': 3.6930965078651306, 'n_layers': 5, 'hidden_dropout': 0.4775989821842703, 'residual_dropout': 0.01983548766172391, 'learning_rate': 0.00016845898080479092, 'batch_size': 128, 'epochs': 137}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:58:52,990] Trial 38 finished with value: 0.6353895160343365 and parameters: {'d': 512, 'd_hidden_factor': 4.094802328531287, 'n_layers': 5, 'hidden_dropout': 0.49790722025110745, 'residual_dropout': 0.13788159464024827, 'learning_rate': 0.0011363728982725055, 'batch_size': 128, 'epochs': 124}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:59:13,395] Trial 39 finished with value: 0.699888654655654 and parameters: {'d': 512, 'd_hidden_factor': 3.781485980555075, 'n_layers': 4, 'hidden_dropout': 0.3888033330229178, 'residual_dropout': 0.07273131967432314, 'learning_rate': 1.4824364683451852e-05, 'batch_size': 128, 'epochs': 94}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:59:38,302] Trial 40 finished with value: 0.6894971325468948 and parameters: {'d': 512, 'd_hidden_factor': 4.642802229071034, 'n_layers': 4, 'hidden_dropout': 0.2846939533438214, 'residual_dropout': 0.06405990795370682, 'learning_rate': 1.4804425073747498e-05, 'batch_size': 64, 'epochs': 93}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 07:59:50,663] Trial 41 finished with value: 0.6797328527430324 and parameters: {'d': 512, 'd_hidden_factor': 3.7851347308131063, 'n_layers': 4, 'hidden_dropout': 0.324836351565967, 'residual_dropout': 0.0671512758439231, 'learning_rate': 3.2397252227016246e-05, 'batch_size': 128, 'epochs': 106}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 08:00:05,094] Trial 42 finished with value: 0.6976523215583261 and parameters: {'d': 512, 'd_hidden_factor': 3.4606383698514946, 'n_layers': 3, 'hidden_dropout': 0.41779637347710913, 'residual_dropout': 0.03031382656747412, 'learning_rate': 1.502570456118905e-05, 'batch_size': 128, 'epochs': 87}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 08:00:19,797] Trial 43 finished with value: 0.6949832239092639 and parameters: {'d': 512, 'd_hidden_factor': 3.4096501468942657, 'n_layers': 3, 'hidden_dropout': 0.4620204479770374, 'residual_dropout': 0.02658375660010083, 'learning_rate': 1.527334618329508e-05, 'batch_size': 128, 'epochs': 87}. Best is trial 22 with value: 0.7063014409573877.\n",
      "[I 2025-11-27 08:00:31,935] Trial 44 finished with value: 0.7090721278786112 and parameters: {'d': 512, 'd_hidden_factor': 3.531048947593829, 'n_layers': 3, 'hidden_dropout': 0.4290806649523898, 'residual_dropout': 0.08855270546440934, 'learning_rate': 2.280785114165716e-05, 'batch_size': 128, 'epochs': 77}. Best is trial 44 with value: 0.7090721278786112.\n",
      "[I 2025-11-27 08:00:45,920] Trial 45 finished with value: 0.7081923093276006 and parameters: {'d': 512, 'd_hidden_factor': 3.4683213171709233, 'n_layers': 3, 'hidden_dropout': 0.4195296117695254, 'residual_dropout': 0.05044358010032395, 'learning_rate': 1.3572030804213397e-05, 'batch_size': 128, 'epochs': 57}. Best is trial 44 with value: 0.7090721278786112.\n",
      "[I 2025-11-27 08:00:58,665] Trial 46 finished with value: 0.6971039429328802 and parameters: {'d': 512, 'd_hidden_factor': 3.9387815080326005, 'n_layers': 2, 'hidden_dropout': 0.3775685814187552, 'residual_dropout': 0.05457831485130438, 'learning_rate': 2.3236709259899475e-05, 'batch_size': 64, 'epochs': 48}. Best is trial 44 with value: 0.7090721278786112.\n",
      "[I 2025-11-27 08:01:18,582] Trial 47 finished with value: 0.6917234437705589 and parameters: {'d': 512, 'd_hidden_factor': 3.083116283307022, 'n_layers': 4, 'hidden_dropout': 0.4309859213940208, 'residual_dropout': 0.37949087807772763, 'learning_rate': 1.1810030422930858e-05, 'batch_size': 128, 'epochs': 66}. Best is trial 44 with value: 0.7090721278786112.\n",
      "[I 2025-11-27 08:01:23,852] Trial 48 finished with value: 0.48868841868401225 and parameters: {'d': 64, 'd_hidden_factor': 2.87251020203955, 'n_layers': 3, 'hidden_dropout': 0.01590098806945847, 'residual_dropout': 0.002068256411407815, 'learning_rate': 1.8438334272599386e-05, 'batch_size': 128, 'epochs': 54}. Best is trial 44 with value: 0.7090721278786112.\n",
      "[I 2025-11-27 08:01:41,604] Trial 49 finished with value: 0.6859286047332341 and parameters: {'d': 512, 'd_hidden_factor': 3.310089228881079, 'n_layers': 2, 'hidden_dropout': 0.34135139773850465, 'residual_dropout': 0.07606290812142133, 'learning_rate': 2.8005016776142982e-05, 'batch_size': 32, 'epochs': 77}. Best is trial 44 with value: 0.7090721278786112.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 896.12s\n",
      "  Best CV G-Mean: 0.7091\n",
      "  Best parameters:\n",
      "    d: 512\n",
      "    d_hidden_factor: 3.531048947593829\n",
      "    n_layers: 3\n",
      "    hidden_dropout: 0.4290806649523898\n",
      "    residual_dropout: 0.08855270546440934\n",
      "    learning_rate: 2.280785114165716e-05\n",
      "    batch_size: 128\n",
      "    epochs: 77\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/77: Train Loss = 0.5384, Val Loss = 0.5792\n",
      "    Epoch 20/77: Train Loss = 0.4330, Val Loss = 0.5505\n",
      "    Epoch 30/77: Train Loss = 0.3631, Val Loss = 0.5486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 08:01:42,796] A new study created in memory with name: no-name-9f1a5ddc-cb8f-4690-942d-b2b2cd2ba6c7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 40/77: Train Loss = 0.3234, Val Loss = 0.5755\n",
      "    Early stopping at epoch 44\n",
      "✓ Training complete! Time: 1.18s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR credit-g\n",
      "================================================================================\n",
      "Accuracy:        0.7267\n",
      "AUC OVO:         0.7611\n",
      "G-Mean:          0.6667\n",
      "Cross-Entropy:   0.5552\n",
      "================================================================================\n",
      "✓ Saved results for credit-g\n",
      "\n",
      "✓ Completed credit-g (14/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 15/30: kc2\n",
      "################################################################################\n",
      "Loading processed dataset from cache: kc2\n",
      "Using device: cuda\n",
      "Dataset: kc2\n",
      "  Train: (365, 21), Test: (157, 21)\n",
      "  Features: 21, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: kc2\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 08:01:46,606] Trial 0 finished with value: 0.6577220711028889 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.6577220711028889.\n",
      "[I 2025-11-27 08:01:53,617] Trial 1 finished with value: 0.7045497150818978 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.7045497150818978.\n",
      "[I 2025-11-27 08:02:02,107] Trial 2 finished with value: 0.6559714502120249 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 1 with value: 0.7045497150818978.\n",
      "[I 2025-11-27 08:03:07,135] Trial 3 finished with value: 0.681582139011569 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 1 with value: 0.7045497150818978.\n",
      "[I 2025-11-27 08:03:16,118] Trial 4 finished with value: 0.5922846404442618 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 1 with value: 0.7045497150818978.\n",
      "[I 2025-11-27 08:04:01,841] Trial 5 finished with value: 0.6479505439040162 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 1 with value: 0.7045497150818978.\n",
      "[I 2025-11-27 08:04:32,683] Trial 6 finished with value: 0.6667154384231214 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 1 with value: 0.7045497150818978.\n",
      "[I 2025-11-27 08:04:37,385] Trial 7 finished with value: 0.6971856066035123 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 1 with value: 0.7045497150818978.\n",
      "[I 2025-11-27 08:04:39,526] Trial 8 finished with value: 0.7257182140440882 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 8 with value: 0.7257182140440882.\n",
      "[I 2025-11-27 08:04:41,157] Trial 9 finished with value: 0.6534570183793488 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 8 with value: 0.7257182140440882.\n",
      "[I 2025-11-27 08:04:55,510] Trial 10 finished with value: 0.6525110911025684 and parameters: {'d': 512, 'd_hidden_factor': 4.97088426861444, 'n_layers': 9, 'hidden_dropout': 0.004030571702010294, 'residual_dropout': 0.19485930498507747, 'learning_rate': 0.0006550956088886104, 'batch_size': 256, 'epochs': 196}. Best is trial 8 with value: 0.7257182140440882.\n",
      "[I 2025-11-27 08:04:58,759] Trial 11 finished with value: 0.6678881331969351 and parameters: {'d': 128, 'd_hidden_factor': 3.433479527615626, 'n_layers': 8, 'hidden_dropout': 0.010476594631962113, 'residual_dropout': 0.4969301789589967, 'learning_rate': 0.0011974395640696877, 'batch_size': 256, 'epochs': 198}. Best is trial 8 with value: 0.7257182140440882.\n",
      "[I 2025-11-27 08:05:06,131] Trial 12 finished with value: 0.6733852673267717 and parameters: {'d': 128, 'd_hidden_factor': 4.557293615555584, 'n_layers': 7, 'hidden_dropout': 0.10855842435218023, 'residual_dropout': 0.42108019748878983, 'learning_rate': 0.002077629888696532, 'batch_size': 64, 'epochs': 150}. Best is trial 8 with value: 0.7257182140440882.\n",
      "[I 2025-11-27 08:05:09,234] Trial 13 finished with value: 0.6692495611913026 and parameters: {'d': 128, 'd_hidden_factor': 2.2848503025755864, 'n_layers': 4, 'hidden_dropout': 0.4176131729439718, 'residual_dropout': 0.42991693404731, 'learning_rate': 0.0059603821026817366, 'batch_size': 128, 'epochs': 160}. Best is trial 8 with value: 0.7257182140440882.\n",
      "[I 2025-11-27 08:05:11,690] Trial 14 finished with value: 0.6372255483370154 and parameters: {'d': 128, 'd_hidden_factor': 3.1738468098733206, 'n_layers': 8, 'hidden_dropout': 0.09540458565148313, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 0.0010846482594561778, 'batch_size': 256, 'epochs': 61}. Best is trial 8 with value: 0.7257182140440882.\n",
      "[I 2025-11-27 08:05:18,270] Trial 15 finished with value: 0.6603502784525169 and parameters: {'d': 128, 'd_hidden_factor': 2.2868713574602975, 'n_layers': 3, 'hidden_dropout': 0.39905833976278837, 'residual_dropout': 0.4007579702939271, 'learning_rate': 0.0005991231927915775, 'batch_size': 64, 'epochs': 169}. Best is trial 8 with value: 0.7257182140440882.\n",
      "[I 2025-11-27 08:05:23,209] Trial 16 finished with value: 0.658992098003141 and parameters: {'d': 128, 'd_hidden_factor': 4.172115350258904, 'n_layers': 7, 'hidden_dropout': 0.20237408722988723, 'residual_dropout': 0.24781459104208328, 'learning_rate': 7.3282410454558e-05, 'batch_size': 256, 'epochs': 67}. Best is trial 8 with value: 0.7257182140440882.\n",
      "[I 2025-11-27 08:05:32,144] Trial 17 finished with value: 0.6511187479551506 and parameters: {'d': 512, 'd_hidden_factor': 2.7071954100982487, 'n_layers': 7, 'hidden_dropout': 0.07436726243220565, 'residual_dropout': 0.4824565450499687, 'learning_rate': 0.002303549361777716, 'batch_size': 128, 'epochs': 138}. Best is trial 8 with value: 0.7257182140440882.\n",
      "[I 2025-11-27 08:05:37,093] Trial 18 finished with value: 0.6874791525326439 and parameters: {'d': 64, 'd_hidden_factor': 1.8747705522934435, 'n_layers': 4, 'hidden_dropout': 0.49381875884984056, 'residual_dropout': 0.38948092915391613, 'learning_rate': 0.008992812122184286, 'batch_size': 64, 'epochs': 108}. Best is trial 8 with value: 0.7257182140440882.\n",
      "[I 2025-11-27 08:05:51,816] Trial 19 finished with value: 0.7357362247294306 and parameters: {'d': 128, 'd_hidden_factor': 3.3948420775052592, 'n_layers': 10, 'hidden_dropout': 0.15646996140556554, 'residual_dropout': 0.2661232901198054, 'learning_rate': 1.0094165165701898e-05, 'batch_size': 256, 'epochs': 173}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:06:07,440] Trial 20 finished with value: 0.7036859544208196 and parameters: {'d': 128, 'd_hidden_factor': 3.5095002326416913, 'n_layers': 10, 'hidden_dropout': 0.15511652727764583, 'residual_dropout': 0.2624506419206136, 'learning_rate': 1.1465344738688203e-05, 'batch_size': 256, 'epochs': 183}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:06:08,769] Trial 21 finished with value: 0.611021497372289 and parameters: {'d': 128, 'd_hidden_factor': 3.15464140928765, 'n_layers': 1, 'hidden_dropout': 0.03503297721282038, 'residual_dropout': 0.1399651253204974, 'learning_rate': 0.0004924591330727932, 'batch_size': 256, 'epochs': 173}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:06:11,869] Trial 22 finished with value: 0.6897750600164758 and parameters: {'d': 128, 'd_hidden_factor': 4.277930675430194, 'n_layers': 9, 'hidden_dropout': 0.2175093150290944, 'residual_dropout': 0.4549992390111969, 'learning_rate': 0.0014973673962958402, 'batch_size': 256, 'epochs': 185}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:06:14,616] Trial 23 finished with value: 0.7139678210397512 and parameters: {'d': 128, 'd_hidden_factor': 3.2145938556672213, 'n_layers': 8, 'hidden_dropout': 0.14838827402273658, 'residual_dropout': 0.37827446502466894, 'learning_rate': 0.004157033286903162, 'batch_size': 256, 'epochs': 151}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:06:18,568] Trial 24 finished with value: 0.722232206734763 and parameters: {'d': 128, 'd_hidden_factor': 3.4572491142900774, 'n_layers': 9, 'hidden_dropout': 0.12230633472735289, 'residual_dropout': 0.27797435038947527, 'learning_rate': 0.004733796352795816, 'batch_size': 256, 'epochs': 147}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:06:29,385] Trial 25 finished with value: 0.7009393176404306 and parameters: {'d': 128, 'd_hidden_factor': 2.6766202405650845, 'n_layers': 9, 'hidden_dropout': 0.061247185475818866, 'residual_dropout': 0.26808604711020423, 'learning_rate': 5.200743783424938e-05, 'batch_size': 256, 'epochs': 140}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:06:32,551] Trial 26 finished with value: 0.7275211140534681 and parameters: {'d': 64, 'd_hidden_factor': 3.6518017056644947, 'n_layers': 10, 'hidden_dropout': 0.12772910274433477, 'residual_dropout': 0.20754245293346701, 'learning_rate': 0.006024415547793402, 'batch_size': 256, 'epochs': 181}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:06:46,998] Trial 27 finished with value: 0.654199559861874 and parameters: {'d': 64, 'd_hidden_factor': 4.491698804446547, 'n_layers': 10, 'hidden_dropout': 0.047661396840268655, 'residual_dropout': 0.19535392567306287, 'learning_rate': 1.1118158771024512e-05, 'batch_size': 256, 'epochs': 182}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:06:55,119] Trial 28 finished with value: 0.6560057178364676 and parameters: {'d': 64, 'd_hidden_factor': 3.8033641001915384, 'n_layers': 10, 'hidden_dropout': 0.19395942615914347, 'residual_dropout': 0.10558953545680921, 'learning_rate': 0.00018054527651276256, 'batch_size': 256, 'epochs': 166}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:07:02,517] Trial 29 finished with value: 0.6473411479656447 and parameters: {'d': 64, 'd_hidden_factor': 4.032041731735757, 'n_layers': 8, 'hidden_dropout': 0.1300609836593448, 'residual_dropout': 0.21319874761731072, 'learning_rate': 0.00032729230035969146, 'batch_size': 128, 'epochs': 198}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:07:05,505] Trial 30 finished with value: 0.7316107675815897 and parameters: {'d': 64, 'd_hidden_factor': 4.778481100829484, 'n_layers': 9, 'hidden_dropout': 0.09148587679888995, 'residual_dropout': 0.013707820427878964, 'learning_rate': 0.00648084656244344, 'batch_size': 256, 'epochs': 179}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:07:08,762] Trial 31 finished with value: 0.6831985728831367 and parameters: {'d': 64, 'd_hidden_factor': 4.822503954703341, 'n_layers': 10, 'hidden_dropout': 0.03270908301639943, 'residual_dropout': 0.030990888036334152, 'learning_rate': 0.005778638889717042, 'batch_size': 256, 'epochs': 180}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:07:11,424] Trial 32 finished with value: 0.6659407978631918 and parameters: {'d': 64, 'd_hidden_factor': 4.402184192924118, 'n_layers': 9, 'hidden_dropout': 0.08565485460269245, 'residual_dropout': 0.06627634503368834, 'learning_rate': 0.0024070580530738636, 'batch_size': 256, 'epochs': 189}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:07:14,860] Trial 33 finished with value: 0.6994354988758947 and parameters: {'d': 64, 'd_hidden_factor': 3.651391056062028, 'n_layers': 10, 'hidden_dropout': 0.16092361789587456, 'residual_dropout': 0.15067470184253928, 'learning_rate': 0.009715280903289679, 'batch_size': 256, 'epochs': 159}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:07:31,837] Trial 34 finished with value: 0.5982123027835455 and parameters: {'d': 64, 'd_hidden_factor': 2.8871390317772923, 'n_layers': 9, 'hidden_dropout': 0.08459622587494897, 'residual_dropout': 0.2250190955704393, 'learning_rate': 0.006565087317525385, 'batch_size': 32, 'epochs': 172}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:07:34,408] Trial 35 finished with value: 0.6912766285607624 and parameters: {'d': 256, 'd_hidden_factor': 4.7156950176626555, 'n_layers': 5, 'hidden_dropout': 0.18298906325413253, 'residual_dropout': 0.36131441368654027, 'learning_rate': 0.0008845419293911511, 'batch_size': 256, 'epochs': 200}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:07:38,232] Trial 36 finished with value: 0.6732438495032831 and parameters: {'d': 64, 'd_hidden_factor': 4.105977916815012, 'n_layers': 7, 'hidden_dropout': 0.23978640188308317, 'residual_dropout': 0.2946748762309366, 'learning_rate': 0.0029671451929589635, 'batch_size': 128, 'epochs': 160}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:08:05,061] Trial 37 finished with value: 0.6437509884089608 and parameters: {'d': 512, 'd_hidden_factor': 2.4706841391214356, 'n_layers': 6, 'hidden_dropout': 0.12643052895333529, 'residual_dropout': 0.11244646217413153, 'learning_rate': 0.0017768698961129663, 'batch_size': 32, 'epochs': 191}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:08:11,332] Trial 38 finished with value: 0.6366991277491147 and parameters: {'d': 256, 'd_hidden_factor': 3.341836464937393, 'n_layers': 10, 'hidden_dropout': 0.02457165755955057, 'residual_dropout': 0.04018141772924819, 'learning_rate': 4.513141332902167e-05, 'batch_size': 256, 'epochs': 175}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:08:18,180] Trial 39 finished with value: 0.6391210980631424 and parameters: {'d': 64, 'd_hidden_factor': 2.920610185116974, 'n_layers': 8, 'hidden_dropout': 0.05756335734407622, 'residual_dropout': 0.3109997065663854, 'learning_rate': 1.9541387029711094e-05, 'batch_size': 256, 'epochs': 126}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:08:42,473] Trial 40 finished with value: 0.6141287581265941 and parameters: {'d': 64, 'd_hidden_factor': 3.7741596524385668, 'n_layers': 9, 'hidden_dropout': 0.2413404425569834, 'residual_dropout': 0.17858496807636476, 'learning_rate': 0.0001112659308881196, 'batch_size': 32, 'epochs': 37}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:08:45,943] Trial 41 finished with value: 0.6391142213401187 and parameters: {'d': 128, 'd_hidden_factor': 3.5427031006568943, 'n_layers': 9, 'hidden_dropout': 0.1178160644136133, 'residual_dropout': 0.28016999942503307, 'learning_rate': 0.0045230780190745395, 'batch_size': 256, 'epochs': 147}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:08:50,523] Trial 42 finished with value: 0.6767584617456277 and parameters: {'d': 128, 'd_hidden_factor': 3.368629825472383, 'n_layers': 9, 'hidden_dropout': 0.13738132333867686, 'residual_dropout': 0.3267902150060745, 'learning_rate': 0.005126278889557207, 'batch_size': 256, 'epochs': 188}. Best is trial 19 with value: 0.7357362247294306.\n",
      "[I 2025-11-27 08:08:54,636] Trial 43 finished with value: 0.7402278145386172 and parameters: {'d': 128, 'd_hidden_factor': 3.9221800273414082, 'n_layers': 10, 'hidden_dropout': 0.10670355338042883, 'residual_dropout': 0.23525010738364932, 'learning_rate': 0.003514908764779207, 'batch_size': 256, 'epochs': 137}. Best is trial 43 with value: 0.7402278145386172.\n",
      "[I 2025-11-27 08:09:10,621] Trial 44 finished with value: 0.6721008561554711 and parameters: {'d': 512, 'd_hidden_factor': 3.925522401337377, 'n_layers': 10, 'hidden_dropout': 0.17672300782859662, 'residual_dropout': 0.24450759347771667, 'learning_rate': 0.007216177442990688, 'batch_size': 256, 'epochs': 135}. Best is trial 43 with value: 0.7402278145386172.\n",
      "[I 2025-11-27 08:09:15,906] Trial 45 finished with value: 0.6208831539191872 and parameters: {'d': 256, 'd_hidden_factor': 3.0032267128584254, 'n_layers': 10, 'hidden_dropout': 0.10647121107000583, 'residual_dropout': 0.16935100999561692, 'learning_rate': 0.003508186045672757, 'batch_size': 256, 'epochs': 115}. Best is trial 43 with value: 0.7402278145386172.\n",
      "[I 2025-11-27 08:09:17,667] Trial 46 finished with value: 0.6621102189149363 and parameters: {'d': 128, 'd_hidden_factor': 3.6649985757805714, 'n_layers': 6, 'hidden_dropout': 0.061503512154551146, 'residual_dropout': 0.131919992816882, 'learning_rate': 0.002883879979938879, 'batch_size': 256, 'epochs': 162}. Best is trial 43 with value: 0.7402278145386172.\n",
      "[I 2025-11-27 08:09:26,264] Trial 47 finished with value: 0.6493529730722072 and parameters: {'d': 128, 'd_hidden_factor': 4.687769797809761, 'n_layers': 8, 'hidden_dropout': 0.28167506704066064, 'residual_dropout': 0.22009119226146565, 'learning_rate': 0.007096799651558686, 'batch_size': 64, 'epochs': 82}. Best is trial 43 with value: 0.7402278145386172.\n",
      "[I 2025-11-27 08:09:29,058] Trial 48 finished with value: 0.6393158564982109 and parameters: {'d': 128, 'd_hidden_factor': 4.295272910834568, 'n_layers': 5, 'hidden_dropout': 0.007350342876942639, 'residual_dropout': 0.3560684095288379, 'learning_rate': 0.0003523301323600266, 'batch_size': 256, 'epochs': 193}. Best is trial 43 with value: 0.7402278145386172.\n",
      "[I 2025-11-27 08:09:33,726] Trial 49 finished with value: 0.6983207993847875 and parameters: {'d': 64, 'd_hidden_factor': 3.883768599942023, 'n_layers': 10, 'hidden_dropout': 0.21989335499468593, 'residual_dropout': 0.0015028268842607953, 'learning_rate': 0.003801500594267818, 'batch_size': 128, 'epochs': 177}. Best is trial 43 with value: 0.7402278145386172.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 470.93s\n",
      "  Best CV G-Mean: 0.7402\n",
      "  Best parameters:\n",
      "    d: 128\n",
      "    d_hidden_factor: 3.9221800273414082\n",
      "    n_layers: 10\n",
      "    hidden_dropout: 0.10670355338042883\n",
      "    residual_dropout: 0.23525010738364932\n",
      "    learning_rate: 0.003514908764779207\n",
      "    batch_size: 256\n",
      "    epochs: 137\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/137: Train Loss = 0.3574, Val Loss = 0.2481\n",
      "    Epoch 20/137: Train Loss = 0.3039, Val Loss = 0.2617\n",
      "    Epoch 30/137: Train Loss = 0.2512, Val Loss = 0.3258\n",
      "    Epoch 40/137: Train Loss = 0.2206, Val Loss = 0.3252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 08:09:34,146] A new study created in memory with name: no-name-39c0dd9b-4bab-4520-895e-75b14d29ff0f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Early stopping at epoch 41\n",
      "✓ Training complete! Time: 0.41s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR kc2\n",
      "================================================================================\n",
      "Accuracy:        0.8344\n",
      "AUC OVO:         0.7981\n",
      "G-Mean:          0.6782\n",
      "Cross-Entropy:   0.5290\n",
      "================================================================================\n",
      "✓ Saved results for kc2\n",
      "\n",
      "✓ Completed kc2 (15/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 16/30: tic-tac-toe\n",
      "################################################################################\n",
      "Loading processed dataset from cache: tic-tac-toe\n",
      "Using device: cuda\n",
      "Dataset: tic-tac-toe\n",
      "  Train: (670, 27), Test: (288, 27)\n",
      "  Features: 27, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: tic-tac-toe\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 08:09:41,104] Trial 0 finished with value: 0.9018663654372185 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.9018663654372185.\n",
      "[I 2025-11-27 08:09:59,190] Trial 1 finished with value: 0.9766105645113601 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.9766105645113601.\n",
      "[I 2025-11-27 08:10:17,749] Trial 2 finished with value: 0.9734200262800025 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 1 with value: 0.9766105645113601.\n",
      "[I 2025-11-27 08:12:21,129] Trial 3 finished with value: 0.9680921809288282 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 1 with value: 0.9766105645113601.\n",
      "[I 2025-11-27 08:12:40,191] Trial 4 finished with value: 0.9723845448901536 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 1 with value: 0.9766105645113601.\n",
      "[I 2025-11-27 08:14:00,655] Trial 5 finished with value: 0.9680007584406024 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 1 with value: 0.9766105645113601.\n",
      "[I 2025-11-27 08:15:01,097] Trial 6 finished with value: 0.9758126945246287 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 1 with value: 0.9766105645113601.\n",
      "[I 2025-11-27 08:15:10,882] Trial 7 finished with value: 0.9811744541396991 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 7 with value: 0.9811744541396991.\n",
      "[I 2025-11-27 08:15:14,796] Trial 8 finished with value: 0.9709203924022838 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 7 with value: 0.9811744541396991.\n",
      "[I 2025-11-27 08:15:17,597] Trial 9 finished with value: 0.975612383205867 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 7 with value: 0.9811744541396991.\n",
      "[I 2025-11-27 08:15:24,320] Trial 10 finished with value: 0.9845124053342772 and parameters: {'d': 512, 'd_hidden_factor': 4.869886258753025, 'n_layers': 1, 'hidden_dropout': 0.10467358725545478, 'residual_dropout': 0.20327186961400082, 'learning_rate': 0.001484521852630656, 'batch_size': 128, 'epochs': 161}. Best is trial 10 with value: 0.9845124053342772.\n",
      "[I 2025-11-27 08:15:36,726] Trial 11 finished with value: 0.9891022185747167 and parameters: {'d': 512, 'd_hidden_factor': 4.967466318765, 'n_layers': 2, 'hidden_dropout': 0.10750079366386665, 'residual_dropout': 0.1906752818537771, 'learning_rate': 0.0009031472349418137, 'batch_size': 128, 'epochs': 159}. Best is trial 11 with value: 0.9891022185747167.\n",
      "[I 2025-11-27 08:15:44,620] Trial 12 finished with value: 0.9889085465655469 and parameters: {'d': 512, 'd_hidden_factor': 4.95198333292941, 'n_layers': 1, 'hidden_dropout': 0.07807795724638916, 'residual_dropout': 0.188916471547488, 'learning_rate': 0.0008629604188668137, 'batch_size': 128, 'epochs': 161}. Best is trial 11 with value: 0.9891022185747167.\n",
      "[I 2025-11-27 08:16:09,303] Trial 13 finished with value: 0.9913002891903515 and parameters: {'d': 512, 'd_hidden_factor': 4.892228722678056, 'n_layers': 3, 'hidden_dropout': 0.04557881882413451, 'residual_dropout': 0.03936207928860028, 'learning_rate': 0.0008021706379699085, 'batch_size': 128, 'epochs': 159}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:16:29,804] Trial 14 finished with value: 0.9801452018137485 and parameters: {'d': 512, 'd_hidden_factor': 4.34772285542914, 'n_layers': 3, 'hidden_dropout': 0.0035697594234744834, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 7.804038230785136e-05, 'batch_size': 128, 'epochs': 158}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:16:47,759] Trial 15 finished with value: 0.9890516683965773 and parameters: {'d': 512, 'd_hidden_factor': 4.464780863946147, 'n_layers': 3, 'hidden_dropout': 0.08359643589733032, 'residual_dropout': 0.09422981531813088, 'learning_rate': 0.0005800064267062714, 'batch_size': 128, 'epochs': 183}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:17:19,711] Trial 16 finished with value: 0.9690912614395636 and parameters: {'d': 512, 'd_hidden_factor': 4.476549255525704, 'n_layers': 8, 'hidden_dropout': 0.14879370766399524, 'residual_dropout': 0.06596520422785265, 'learning_rate': 0.0004544039227900941, 'batch_size': 128, 'epochs': 141}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:17:36,315] Trial 17 finished with value: 0.9833861166491342 and parameters: {'d': 512, 'd_hidden_factor': 4.936907784521712, 'n_layers': 3, 'hidden_dropout': 0.04901601714154919, 'residual_dropout': 0.2564865250484077, 'learning_rate': 0.0011613355523477714, 'batch_size': 128, 'epochs': 179}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:17:52,945] Trial 18 finished with value: 0.9801700526245171 and parameters: {'d': 512, 'd_hidden_factor': 2.4391969110817824, 'n_layers': 4, 'hidden_dropout': 0.17240044223419534, 'residual_dropout': 0.00013140446784273146, 'learning_rate': 5.843971237496471e-05, 'batch_size': 128, 'epochs': 146}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:18:00,786] Trial 19 finished with value: 0.648873754504782 and parameters: {'d': 64, 'd_hidden_factor': 4.255590551887648, 'n_layers': 2, 'hidden_dropout': 0.1229345622888072, 'residual_dropout': 0.13756393395877103, 'learning_rate': 1.0094165165701898e-05, 'batch_size': 256, 'epochs': 197}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:18:28,180] Trial 20 finished with value: 0.9735005161520377 and parameters: {'d': 512, 'd_hidden_factor': 3.4587227938399017, 'n_layers': 8, 'hidden_dropout': 0.4202138733708044, 'residual_dropout': 0.26681459626650667, 'learning_rate': 0.0021687424852762627, 'batch_size': 128, 'epochs': 111}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:18:42,512] Trial 21 finished with value: 0.986803047602803 and parameters: {'d': 512, 'd_hidden_factor': 4.561688579660044, 'n_layers': 3, 'hidden_dropout': 0.05786463860953324, 'residual_dropout': 0.08083954483869535, 'learning_rate': 0.0006251667495905682, 'batch_size': 128, 'epochs': 180}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:19:02,168] Trial 22 finished with value: 0.9823274094214002 and parameters: {'d': 512, 'd_hidden_factor': 4.116596236695052, 'n_layers': 4, 'hidden_dropout': 0.2175093150290944, 'residual_dropout': 0.11649776448875836, 'learning_rate': 0.0003727677916070205, 'batch_size': 128, 'epochs': 179}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:19:10,147] Trial 23 finished with value: 0.9846049769871682 and parameters: {'d': 512, 'd_hidden_factor': 4.654812600693264, 'n_layers': 1, 'hidden_dropout': 0.03829904514895263, 'residual_dropout': 0.035315370763900865, 'learning_rate': 0.0007457828965128802, 'batch_size': 128, 'epochs': 142}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:19:23,691] Trial 24 finished with value: 0.9846555271653076 and parameters: {'d': 512, 'd_hidden_factor': 4.663975578294444, 'n_layers': 3, 'hidden_dropout': 0.10849671987895021, 'residual_dropout': 0.1999883415329734, 'learning_rate': 0.0002022902094290803, 'batch_size': 128, 'epochs': 173}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:19:32,700] Trial 25 finished with value: 0.9867910006734851 and parameters: {'d': 512, 'd_hidden_factor': 4.09002729555346, 'n_layers': 2, 'hidden_dropout': 0.20044661360875282, 'residual_dropout': 0.11360496922169519, 'learning_rate': 0.00046705423257234284, 'batch_size': 128, 'epochs': 192}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:19:49,621] Trial 26 finished with value: 0.979001518219893 and parameters: {'d': 512, 'd_hidden_factor': 4.67467858994564, 'n_layers': 4, 'hidden_dropout': 0.08538657529927636, 'residual_dropout': 0.16752021605823292, 'learning_rate': 0.001992623018109364, 'batch_size': 128, 'epochs': 152}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:19:54,513] Trial 27 finished with value: 0.9745012494699509 and parameters: {'d': 64, 'd_hidden_factor': 3.6687943649199286, 'n_layers': 2, 'hidden_dropout': 0.032047841446165196, 'residual_dropout': 0.04203382162918823, 'learning_rate': 0.0008235665038374765, 'batch_size': 256, 'epochs': 170}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:20:27,914] Trial 28 finished with value: 0.9778017673601923 and parameters: {'d': 256, 'd_hidden_factor': 4.340821829103268, 'n_layers': 3, 'hidden_dropout': 0.13834432957277062, 'residual_dropout': 0.23008869527481557, 'learning_rate': 0.0002483913790450667, 'batch_size': 32, 'epochs': 132}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:20:47,486] Trial 29 finished with value: 0.9668569854196607 and parameters: {'d': 64, 'd_hidden_factor': 3.8254430917033044, 'n_layers': 5, 'hidden_dropout': 0.49234790898426983, 'residual_dropout': 0.10421970940801006, 'learning_rate': 0.00012004867992754371, 'batch_size': 128, 'epochs': 112}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:21:15,436] Trial 30 finished with value: 0.9890516683965773 and parameters: {'d': 512, 'd_hidden_factor': 4.866512840577771, 'n_layers': 5, 'hidden_dropout': 0.07611480743184618, 'residual_dropout': 0.05221808978896422, 'learning_rate': 0.0003396010126803056, 'batch_size': 128, 'epochs': 186}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:21:44,258] Trial 31 finished with value: 0.9846555271653076 and parameters: {'d': 512, 'd_hidden_factor': 4.961773395220345, 'n_layers': 5, 'hidden_dropout': 0.08674197877174837, 'residual_dropout': 0.05111898891459918, 'learning_rate': 0.0003243638604393211, 'batch_size': 128, 'epochs': 186}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:22:21,674] Trial 32 finished with value: 0.986803047602803 and parameters: {'d': 512, 'd_hidden_factor': 4.711480967865948, 'n_layers': 7, 'hidden_dropout': 0.06379718943466056, 'residual_dropout': 0.029366297740766018, 'learning_rate': 0.0005609831541701164, 'batch_size': 128, 'epochs': 168}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:22:41,077] Trial 33 finished with value: 0.974737886523368 and parameters: {'d': 512, 'd_hidden_factor': 4.476232107578004, 'n_layers': 4, 'hidden_dropout': 0.02424941755040357, 'residual_dropout': 0.1460743135360396, 'learning_rate': 0.0011677720338605982, 'batch_size': 128, 'epochs': 188}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:23:00,864] Trial 34 finished with value: 0.9779353550901032 and parameters: {'d': 128, 'd_hidden_factor': 4.991051051931293, 'n_layers': 5, 'hidden_dropout': 0.1143308506551467, 'residual_dropout': 0.09004868580513327, 'learning_rate': 0.00015875707852181905, 'batch_size': 64, 'epochs': 54}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:23:08,764] Trial 35 finished with value: 0.9846049769871682 and parameters: {'d': 512, 'd_hidden_factor': 4.029100777688582, 'n_layers': 1, 'hidden_dropout': 0.18519017942216948, 'residual_dropout': 0.13395526503208874, 'learning_rate': 0.00029222469292411083, 'batch_size': 128, 'epochs': 200}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:23:43,298] Trial 36 finished with value: 0.9745578017261135 and parameters: {'d': 256, 'd_hidden_factor': 4.763966368006258, 'n_layers': 10, 'hidden_dropout': 0.22918196551416603, 'residual_dropout': 0.29241742935813464, 'learning_rate': 0.00253596093258368, 'batch_size': 64, 'epochs': 155}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:24:01,664] Trial 37 finished with value: 0.9746073150695602 and parameters: {'d': 128, 'd_hidden_factor': 4.245168135934863, 'n_layers': 3, 'hidden_dropout': 0.08731156040695517, 'residual_dropout': 0.16902141634424273, 'learning_rate': 0.0011199163548325525, 'batch_size': 32, 'epochs': 135}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:24:34,574] Trial 38 finished with value: 0.9557978316238696 and parameters: {'d': 512, 'd_hidden_factor': 4.476235310158982, 'n_layers': 7, 'hidden_dropout': 0.141303937372479, 'residual_dropout': 0.016849551822337133, 'learning_rate': 0.0016452775446645013, 'batch_size': 128, 'epochs': 168}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:24:58,563] Trial 39 finished with value: 0.9701059510461805 and parameters: {'d': 512, 'd_hidden_factor': 3.1496097878319476, 'n_layers': 2, 'hidden_dropout': 0.24936363706577488, 'residual_dropout': 0.05698112738920582, 'learning_rate': 0.003753279801082981, 'batch_size': 32, 'epochs': 185}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:25:10,043] Trial 40 finished with value: 0.9724720000527174 and parameters: {'d': 64, 'd_hidden_factor': 1.9105412083383158, 'n_layers': 4, 'hidden_dropout': 0.4203922058097438, 'residual_dropout': 0.08885245875604636, 'learning_rate': 0.00037285570039203333, 'batch_size': 64, 'epochs': 37}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:25:19,871] Trial 41 finished with value: 0.9911571673593211 and parameters: {'d': 512, 'd_hidden_factor': 4.820771527739731, 'n_layers': 1, 'hidden_dropout': 0.0655341295094759, 'residual_dropout': 0.23660968638914182, 'learning_rate': 0.0008269650252650403, 'batch_size': 128, 'epochs': 162}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:25:29,522] Trial 42 finished with value: 0.9889085465655469 and parameters: {'d': 512, 'd_hidden_factor': 4.78055356979256, 'n_layers': 1, 'hidden_dropout': 0.02110829194431671, 'residual_dropout': 0.22899585737225975, 'learning_rate': 0.0006378257528253485, 'batch_size': 128, 'epochs': 176}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:25:41,977] Trial 43 finished with value: 0.9754909060745567 and parameters: {'d': 512, 'd_hidden_factor': 4.998426113447052, 'n_layers': 2, 'hidden_dropout': 0.061935662310102994, 'residual_dropout': 0.3740731011713474, 'learning_rate': 0.0009855658668795491, 'batch_size': 128, 'epochs': 167}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:25:47,828] Trial 44 finished with value: 0.9832922242764903 and parameters: {'d': 256, 'd_hidden_factor': 4.482451924497423, 'n_layers': 1, 'hidden_dropout': 0.1266607234383472, 'residual_dropout': 0.317988224878344, 'learning_rate': 0.0004731316024992111, 'batch_size': 128, 'epochs': 151}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:25:51,747] Trial 45 finished with value: 0.9801077353996197 and parameters: {'d': 128, 'd_hidden_factor': 4.826755257043617, 'n_layers': 2, 'hidden_dropout': 0.08980733441577557, 'residual_dropout': 0.2928812667446751, 'learning_rate': 0.0015654358374284994, 'batch_size': 256, 'epochs': 121}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:26:02,511] Trial 46 finished with value: 0.9789886546981116 and parameters: {'d': 512, 'd_hidden_factor': 2.820221863547094, 'n_layers': 3, 'hidden_dropout': 0.01964379418916938, 'residual_dropout': 0.2280213953889534, 'learning_rate': 0.00022440755895793146, 'batch_size': 128, 'epochs': 162}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:26:34,075] Trial 47 finished with value: 0.9824199810742911 and parameters: {'d': 512, 'd_hidden_factor': 4.244047940245997, 'n_layers': 6, 'hidden_dropout': 0.16156407834455605, 'residual_dropout': 0.37949087807772763, 'learning_rate': 0.00014837437591417717, 'batch_size': 128, 'epochs': 79}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:26:39,645] Trial 48 finished with value: 0.9844113180417515 and parameters: {'d': 512, 'd_hidden_factor': 4.584646197787301, 'n_layers': 1, 'hidden_dropout': 0.003409226049908197, 'residual_dropout': 0.18451879345816977, 'learning_rate': 0.0049627977894147, 'batch_size': 128, 'epochs': 193}. Best is trial 13 with value: 0.9913002891903515.\n",
      "[I 2025-11-27 08:26:50,989] Trial 49 finished with value: 0.9824069063715333 and parameters: {'d': 512, 'd_hidden_factor': 3.7047154741902397, 'n_layers': 3, 'hidden_dropout': 0.06474433837350155, 'residual_dropout': 0.06617177106680408, 'learning_rate': 0.000749571767010046, 'batch_size': 128, 'epochs': 104}. Best is trial 13 with value: 0.9913002891903515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 1036.84s\n",
      "  Best CV G-Mean: 0.9913\n",
      "  Best parameters:\n",
      "    d: 512\n",
      "    d_hidden_factor: 4.892228722678056\n",
      "    n_layers: 3\n",
      "    hidden_dropout: 0.04557881882413451\n",
      "    residual_dropout: 0.03936207928860028\n",
      "    learning_rate: 0.0008021706379699085\n",
      "    batch_size: 128\n",
      "    epochs: 159\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/159: Train Loss = 0.0108, Val Loss = 0.0666\n",
      "    Epoch 20/159: Train Loss = 0.0012, Val Loss = 0.0239\n",
      "    Epoch 30/159: Train Loss = 0.0005, Val Loss = 0.0164\n",
      "    Epoch 40/159: Train Loss = 0.0003, Val Loss = 0.0117\n",
      "    Epoch 50/159: Train Loss = 0.0003, Val Loss = 0.0082\n",
      "    Epoch 60/159: Train Loss = 0.0002, Val Loss = 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 08:26:53,440] A new study created in memory with name: no-name-f052cb9f-4821-4b22-aa73-0519d84ead30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 70/159: Train Loss = 0.0001, Val Loss = 0.0097\n",
      "    Early stopping at epoch 70\n",
      "✓ Training complete! Time: 2.44s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR tic-tac-toe\n",
      "================================================================================\n",
      "Accuracy:        0.9965\n",
      "AUC OVO:         0.9999\n",
      "G-Mean:          0.9950\n",
      "Cross-Entropy:   0.0145\n",
      "================================================================================\n",
      "✓ Saved results for tic-tac-toe\n",
      "\n",
      "✓ Completed tic-tac-toe (16/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 17/30: credit-approval\n",
      "################################################################################\n",
      "Loading processed dataset from cache: credit-approval\n",
      "Using device: cuda\n",
      "Dataset: credit-approval\n",
      "  Train: (483, 46), Test: (207, 46)\n",
      "  Features: 46, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: credit-approval\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 08:26:58,850] Trial 0 finished with value: 0.8658239465250965 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.8658239465250965.\n",
      "[I 2025-11-27 08:27:04,788] Trial 1 finished with value: 0.8572721186486936 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 0 with value: 0.8658239465250965.\n",
      "[I 2025-11-27 08:27:12,865] Trial 2 finished with value: 0.8565016239703278 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: 0.8658239465250965.\n",
      "[I 2025-11-27 08:27:58,669] Trial 3 finished with value: 0.8776567979207174 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:28:06,371] Trial 4 finished with value: 0.8495116074665876 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:28:51,285] Trial 5 finished with value: 0.8661115584173464 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:29:23,389] Trial 6 finished with value: 0.8644145086595698 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:29:27,079] Trial 7 finished with value: 0.8374692644142699 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:29:28,350] Trial 8 finished with value: 0.8451533374367527 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:29:29,348] Trial 9 finished with value: 0.8486581324097464 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:30:19,174] Trial 10 finished with value: 0.8544275762455598 and parameters: {'d': 256, 'd_hidden_factor': 4.956401873386991, 'n_layers': 10, 'hidden_dropout': 0.10467358725545478, 'residual_dropout': 0.21319384192877996, 'learning_rate': 1.0455868741494775e-05, 'batch_size': 32, 'epochs': 159}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:31:01,333] Trial 11 finished with value: 0.8701205707584206 and parameters: {'d': 512, 'd_hidden_factor': 1.0737622521709098, 'n_layers': 10, 'hidden_dropout': 0.404612932718377, 'residual_dropout': 0.01001667026169617, 'learning_rate': 1.9787885460395214e-05, 'batch_size': 32, 'epochs': 81}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:31:38,106] Trial 12 finished with value: 0.8398264858763872 and parameters: {'d': 512, 'd_hidden_factor': 1.9747380855581826, 'n_layers': 10, 'hidden_dropout': 0.42746214746379146, 'residual_dropout': 0.0012448449065346444, 'learning_rate': 4.733657178031299e-05, 'batch_size': 32, 'epochs': 60}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:32:47,475] Trial 13 finished with value: 0.8585757328278957 and parameters: {'d': 512, 'd_hidden_factor': 4.876886679033238, 'n_layers': 8, 'hidden_dropout': 0.40068056585205547, 'residual_dropout': 0.25198618623335556, 'learning_rate': 1.0156421711796782e-05, 'batch_size': 32, 'epochs': 77}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:32:55,625] Trial 14 finished with value: 0.8600664365371461 and parameters: {'d': 512, 'd_hidden_factor': 1.8744704698723795, 'n_layers': 8, 'hidden_dropout': 0.22628862778338357, 'residual_dropout': 0.12542763917257305, 'learning_rate': 4.7705452676408725e-05, 'batch_size': 128, 'epochs': 30}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:33:13,122] Trial 15 finished with value: 0.8549342014638798 and parameters: {'d': 256, 'd_hidden_factor': 2.610838014106784, 'n_layers': 8, 'hidden_dropout': 0.47905477030956045, 'residual_dropout': 0.23659149841168892, 'learning_rate': 0.0007072646067119463, 'batch_size': 32, 'epochs': 136}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:33:58,670] Trial 16 finished with value: 0.8547056622344364 and parameters: {'d': 512, 'd_hidden_factor': 4.3589777276718, 'n_layers': 9, 'hidden_dropout': 0.3876780168383647, 'residual_dropout': 0.27854098294465185, 'learning_rate': 2.4178436279266157e-05, 'batch_size': 32, 'epochs': 146}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:34:17,366] Trial 17 finished with value: 0.8368780731159194 and parameters: {'d': 256, 'd_hidden_factor': 1.4005344274017066, 'n_layers': 9, 'hidden_dropout': 0.14888886338659357, 'residual_dropout': 0.0347568883505528, 'learning_rate': 0.00013197369140128358, 'batch_size': 32, 'epochs': 105}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:34:24,939] Trial 18 finished with value: 0.8345736187194278 and parameters: {'d': 64, 'd_hidden_factor': 2.526026248326988, 'n_layers': 10, 'hidden_dropout': 0.43653859603260703, 'residual_dropout': 0.1616630705650625, 'learning_rate': 7.929180926251164e-05, 'batch_size': 256, 'epochs': 80}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:34:29,236] Trial 19 finished with value: 0.8220055403799655 and parameters: {'d': 512, 'd_hidden_factor': 1.0435269641675855, 'n_layers': 7, 'hidden_dropout': 0.04472069034974646, 'residual_dropout': 0.08812974602509167, 'learning_rate': 0.0006441943583327288, 'batch_size': 128, 'epochs': 59}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:35:23,803] Trial 20 finished with value: 0.8699459877036817 and parameters: {'d': 256, 'd_hidden_factor': 1.6261955379265378, 'n_layers': 9, 'hidden_dropout': 0.3478967470452088, 'residual_dropout': 0.39392787696399834, 'learning_rate': 2.1896218641064433e-05, 'batch_size': 32, 'epochs': 114}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:36:19,124] Trial 21 finished with value: 0.8581017804427009 and parameters: {'d': 256, 'd_hidden_factor': 1.5871556641800553, 'n_layers': 9, 'hidden_dropout': 0.36154963529606504, 'residual_dropout': 0.3889229670995974, 'learning_rate': 2.1869634130896875e-05, 'batch_size': 32, 'epochs': 105}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:37:15,795] Trial 22 finished with value: 0.870660280285928 and parameters: {'d': 256, 'd_hidden_factor': 1.760528126752359, 'n_layers': 10, 'hidden_dropout': 0.2518695882706262, 'residual_dropout': 0.2928667377365025, 'learning_rate': 1.5052255010078611e-05, 'batch_size': 32, 'epochs': 114}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:37:47,327] Trial 23 finished with value: 0.8622359389753692 and parameters: {'d': 256, 'd_hidden_factor': 2.334452061730278, 'n_layers': 10, 'hidden_dropout': 0.26532675471259143, 'residual_dropout': 0.292555153867005, 'learning_rate': 5.04576578116625e-05, 'batch_size': 32, 'epochs': 160}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:38:27,576] Trial 24 finished with value: 0.8733976271969691 and parameters: {'d': 256, 'd_hidden_factor': 1.885474030513121, 'n_layers': 8, 'hidden_dropout': 0.20055318000215794, 'residual_dropout': 0.19348379777019373, 'learning_rate': 1.3461246195310966e-05, 'batch_size': 32, 'epochs': 84}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:39:02,096] Trial 25 finished with value: 0.8573121013738932 and parameters: {'d': 256, 'd_hidden_factor': 2.8608386560433168, 'n_layers': 7, 'hidden_dropout': 0.1932768633102075, 'residual_dropout': 0.20232158685049068, 'learning_rate': 1.396904431724606e-05, 'batch_size': 32, 'epochs': 87}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:39:30,485] Trial 26 finished with value: 0.8565320689501383 and parameters: {'d': 256, 'd_hidden_factor': 2.1276121953680005, 'n_layers': 8, 'hidden_dropout': 0.24384985252287047, 'residual_dropout': 0.2984534839111768, 'learning_rate': 3.879331019252066e-05, 'batch_size': 32, 'epochs': 116}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:39:42,668] Trial 27 finished with value: 0.8557210751151972 and parameters: {'d': 256, 'd_hidden_factor': 3.3143324903635634, 'n_layers': 9, 'hidden_dropout': 0.12019852082979199, 'residual_dropout': 0.19535392567306287, 'learning_rate': 1.4874915983817228e-05, 'batch_size': 128, 'epochs': 67}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:39:47,362] Trial 28 finished with value: 0.8666123318983125 and parameters: {'d': 256, 'd_hidden_factor': 1.6795043624274704, 'n_layers': 7, 'hidden_dropout': 0.18691778393594347, 'residual_dropout': 0.27906746628308343, 'learning_rate': 6.006855816991345e-05, 'batch_size': 256, 'epochs': 138}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:39:53,272] Trial 29 finished with value: 0.799981160362568 and parameters: {'d': 64, 'd_hidden_factor': 2.476872816281279, 'n_layers': 4, 'hidden_dropout': 0.08686812442984668, 'residual_dropout': 0.3704827928313841, 'learning_rate': 3.089164113876756e-05, 'batch_size': 128, 'epochs': 51}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:40:12,502] Trial 30 finished with value: 0.837065369323952 and parameters: {'d': 256, 'd_hidden_factor': 3.6594145108506715, 'n_layers': 9, 'hidden_dropout': 0.2663287142442751, 'residual_dropout': 0.24875087331190524, 'learning_rate': 0.0003396010126803056, 'batch_size': 32, 'epochs': 186}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:41:24,383] Trial 31 finished with value: 0.8564249487544282 and parameters: {'d': 512, 'd_hidden_factor': 1.1966732792692985, 'n_layers': 10, 'hidden_dropout': 0.49221723306006654, 'residual_dropout': 0.31382537313430137, 'learning_rate': 1.6387868079963663e-05, 'batch_size': 32, 'epochs': 79}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:41:50,887] Trial 32 finished with value: 0.8355338644024604 and parameters: {'d': 256, 'd_hidden_factor': 1.8938062576253891, 'n_layers': 10, 'hidden_dropout': 0.1631563098360277, 'residual_dropout': 0.35929210940662915, 'learning_rate': 8.751984330103317e-05, 'batch_size': 32, 'epochs': 71}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:42:53,584] Trial 33 finished with value: 0.871080457565222 and parameters: {'d': 128, 'd_hidden_factor': 3.0062574596404055, 'n_layers': 10, 'hidden_dropout': 0.23041547084150188, 'residual_dropout': 0.16932125750064814, 'learning_rate': 1.7565525175472275e-05, 'batch_size': 32, 'epochs': 106}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:43:27,271] Trial 34 finished with value: 0.8565692841041302 and parameters: {'d': 128, 'd_hidden_factor': 3.0282375091403075, 'n_layers': 8, 'hidden_dropout': 0.22233070085582876, 'residual_dropout': 0.1658180796279177, 'learning_rate': 1.4512160523614826e-05, 'batch_size': 64, 'epochs': 108}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:44:02,390] Trial 35 finished with value: 0.8602386605272244 and parameters: {'d': 128, 'd_hidden_factor': 3.276095442199144, 'n_layers': 9, 'hidden_dropout': 0.1993768434450957, 'residual_dropout': 0.11355709479031331, 'learning_rate': 2.9072794813766847e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:44:09,995] Trial 36 finished with value: 0.8570371750662937 and parameters: {'d': 128, 'd_hidden_factor': 2.7618845204260065, 'n_layers': 5, 'hidden_dropout': 0.2872034765969525, 'residual_dropout': 0.13082374684040043, 'learning_rate': 0.00021917513567907366, 'batch_size': 64, 'epochs': 124}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:44:47,348] Trial 37 finished with value: 0.8585834194616323 and parameters: {'d': 128, 'd_hidden_factor': 3.639531866874135, 'n_layers': 7, 'hidden_dropout': 0.24886559183743076, 'residual_dropout': 0.21937559855644287, 'learning_rate': 3.382861097007123e-05, 'batch_size': 32, 'epochs': 91}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:46:19,574] Trial 38 finished with value: 0.8657732194751742 and parameters: {'d': 64, 'd_hidden_factor': 4.054326870939036, 'n_layers': 10, 'hidden_dropout': 0.30984582544579264, 'residual_dropout': 0.17320824768529922, 'learning_rate': 1.0855260575014633e-05, 'batch_size': 32, 'epochs': 101}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:46:34,823] Trial 39 finished with value: 0.8607533752752813 and parameters: {'d': 128, 'd_hidden_factor': 2.1503499707463964, 'n_layers': 9, 'hidden_dropout': 0.225449566753369, 'residual_dropout': 0.260992235671617, 'learning_rate': 6.202301991596491e-05, 'batch_size': 64, 'epochs': 40}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:46:36,305] Trial 40 finished with value: 0.8660857664128994 and parameters: {'d': 256, 'd_hidden_factor': 2.940542623346682, 'n_layers': 1, 'hidden_dropout': 0.31865085264196974, 'residual_dropout': 0.32666867186160276, 'learning_rate': 0.00013170718398731904, 'batch_size': 256, 'epochs': 116}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:47:35,468] Trial 41 finished with value: 0.8689744048444925 and parameters: {'d': 128, 'd_hidden_factor': 1.2973384624309259, 'n_layers': 10, 'hidden_dropout': 0.1395465625876976, 'residual_dropout': 0.047761295204955284, 'learning_rate': 1.8388792047121894e-05, 'batch_size': 32, 'epochs': 86}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:48:12,629] Trial 42 finished with value: 0.8616141923218382 and parameters: {'d': 512, 'd_hidden_factor': 2.34277552936453, 'n_layers': 10, 'hidden_dropout': 0.17269120215842837, 'residual_dropout': 0.08900192452099943, 'learning_rate': 2.0806433015355066e-05, 'batch_size': 32, 'epochs': 68}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:49:32,265] Trial 43 finished with value: 0.860837415881759 and parameters: {'d': 256, 'd_hidden_factor': 3.1920751289897376, 'n_layers': 10, 'hidden_dropout': 0.3385680367124344, 'residual_dropout': 0.4453003529505716, 'learning_rate': 1.1688779409139026e-05, 'batch_size': 32, 'epochs': 93}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:50:07,477] Trial 44 finished with value: 0.8595002319438285 and parameters: {'d': 512, 'd_hidden_factor': 3.511466388938188, 'n_layers': 8, 'hidden_dropout': 0.281772843387301, 'residual_dropout': 0.2272115982155445, 'learning_rate': 3.527934135137849e-05, 'batch_size': 32, 'epochs': 81}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:50:56,902] Trial 45 finished with value: 0.839719683647316 and parameters: {'d': 64, 'd_hidden_factor': 1.1791118887698733, 'n_layers': 9, 'hidden_dropout': 0.2432593887072112, 'residual_dropout': 0.17910718105398724, 'learning_rate': 1.7572786766987457e-05, 'batch_size': 32, 'epochs': 59}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:51:07,026] Trial 46 finished with value: 0.8515309515561473 and parameters: {'d': 128, 'd_hidden_factor': 1.7500876183958554, 'n_layers': 4, 'hidden_dropout': 0.3775685814187552, 'residual_dropout': 0.016199106999897184, 'learning_rate': 0.001784274728966719, 'batch_size': 32, 'epochs': 131}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:52:02,481] Trial 47 finished with value: 0.8616954810388335 and parameters: {'d': 256, 'd_hidden_factor': 1.433652656774911, 'n_layers': 10, 'hidden_dropout': 0.45412144164851204, 'residual_dropout': 0.13883725616311496, 'learning_rate': 2.8041753660426223e-05, 'batch_size': 32, 'epochs': 74}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:53:01,073] Trial 48 finished with value: 0.8619191531515431 and parameters: {'d': 512, 'd_hidden_factor': 1.9921514776733091, 'n_layers': 9, 'hidden_dropout': 0.20880778358645524, 'residual_dropout': 0.3503756417058492, 'learning_rate': 1.0316052789181557e-05, 'batch_size': 32, 'epochs': 113}. Best is trial 3 with value: 0.8776567979207174.\n",
      "[I 2025-11-27 08:53:10,860] Trial 49 finished with value: 0.8726679918726463 and parameters: {'d': 256, 'd_hidden_factor': 2.7454972011135297, 'n_layers': 8, 'hidden_dropout': 0.29803792543065877, 'residual_dropout': 0.2726901396495646, 'learning_rate': 4.040618018454688e-05, 'batch_size': 128, 'epochs': 101}. Best is trial 3 with value: 0.8776567979207174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 1577.42s\n",
      "  Best CV G-Mean: 0.8777\n",
      "  Best parameters:\n",
      "    d: 256\n",
      "    d_hidden_factor: 2.9321370570508174\n",
      "    n_layers: 10\n",
      "    hidden_dropout: 0.25974255962990467\n",
      "    residual_dropout: 0.30644726288148383\n",
      "    learning_rate: 2.300837769659881e-05\n",
      "    batch_size: 32\n",
      "    epochs: 82\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/82: Train Loss = 0.3486, Val Loss = 0.3393\n",
      "    Epoch 20/82: Train Loss = 0.3226, Val Loss = 0.2894\n",
      "    Epoch 30/82: Train Loss = 0.2430, Val Loss = 0.2555\n",
      "    Epoch 40/82: Train Loss = 0.2738, Val Loss = 0.2233\n",
      "    Epoch 50/82: Train Loss = 0.2371, Val Loss = 0.2125\n",
      "    Epoch 60/82: Train Loss = 0.2059, Val Loss = 0.2060\n",
      "    Epoch 70/82: Train Loss = 0.2042, Val Loss = 0.1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 08:53:18,902] A new study created in memory with name: no-name-42a1d912-872e-4086-971c-057476ce1380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Early stopping at epoch 73\n",
      "✓ Training complete! Time: 8.03s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR credit-approval\n",
      "================================================================================\n",
      "Accuracy:        0.8357\n",
      "AUC OVO:         0.9169\n",
      "G-Mean:          0.8335\n",
      "Cross-Entropy:   0.3980\n",
      "================================================================================\n",
      "✓ Saved results for credit-approval\n",
      "\n",
      "✓ Completed credit-approval (17/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 18/30: mfeat-factors\n",
      "################################################################################\n",
      "Loading processed dataset from cache: mfeat-factors\n",
      "Using device: cuda\n",
      "Dataset: mfeat-factors\n",
      "  Train: (1400, 216), Test: (600, 216)\n",
      "  Features: 216, Classes: 10\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: mfeat-factors\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 08:53:33,948] Trial 0 finished with value: 0.9708687531957221 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.9708687531957221.\n",
      "[I 2025-11-27 08:54:06,373] Trial 1 finished with value: 0.9763552709512002 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.9763552709512002.\n",
      "[I 2025-11-27 08:54:44,763] Trial 2 finished with value: 0.981542869426416 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 2 with value: 0.981542869426416.\n",
      "[I 2025-11-27 08:59:07,980] Trial 3 finished with value: 0.9837552712725908 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 08:59:46,269] Trial 4 finished with value: 0.973069472305044 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:02:40,016] Trial 5 finished with value: 0.9777299151194055 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:04:50,605] Trial 6 finished with value: 0.9777584615617899 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:05:09,655] Trial 7 finished with value: 0.9727166519210796 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:05:15,160] Trial 8 finished with value: 0.9711225141676578 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:05:19,349] Trial 9 finished with value: 0.9697137123225318 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:13:20,458] Trial 10 finished with value: 0.9815321288597134 and parameters: {'d': 256, 'd_hidden_factor': 4.956401873386991, 'n_layers': 10, 'hidden_dropout': 0.10467358725545478, 'residual_dropout': 0.21319384192877996, 'learning_rate': 1.0455868741494775e-05, 'batch_size': 32, 'epochs': 159}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:14:06,916] Trial 11 finished with value: 0.9814244817945502 and parameters: {'d': 512, 'd_hidden_factor': 2.2542909629835357, 'n_layers': 10, 'hidden_dropout': 0.17777888929140795, 'residual_dropout': 0.17610959048550465, 'learning_rate': 8.265581713864315e-05, 'batch_size': 128, 'epochs': 38}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:14:59,352] Trial 12 finished with value: 0.9792088868890891 and parameters: {'d': 128, 'd_hidden_factor': 2.507861502703489, 'n_layers': 8, 'hidden_dropout': 0.4065623125080101, 'residual_dropout': 0.11369606960054551, 'learning_rate': 0.0005562360969902414, 'batch_size': 64, 'epochs': 61}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:18:00,381] Trial 13 finished with value: 0.9815785975671742 and parameters: {'d': 256, 'd_hidden_factor': 2.5384430924528028, 'n_layers': 8, 'hidden_dropout': 0.22720821206340103, 'residual_dropout': 0.27277417719399266, 'learning_rate': 2.9131010629070215e-05, 'batch_size': 32, 'epochs': 69}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:21:12,542] Trial 14 finished with value: 0.9822543489407518 and parameters: {'d': 256, 'd_hidden_factor': 1.8469210739089723, 'n_layers': 8, 'hidden_dropout': 0.09752730303763973, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 3.1679560298630096e-05, 'batch_size': 32, 'epochs': 78}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:26:42,994] Trial 15 finished with value: 0.9823528897371595 and parameters: {'d': 256, 'd_hidden_factor': 1.7667063807315986, 'n_layers': 8, 'hidden_dropout': 0.0705752936278858, 'residual_dropout': 0.023829386218252563, 'learning_rate': 1.201880159180346e-05, 'batch_size': 32, 'epochs': 136}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:33:13,733] Trial 16 finished with value: 0.9815210007305598 and parameters: {'d': 256, 'd_hidden_factor': 1.644473301657777, 'n_layers': 9, 'hidden_dropout': 0.0035358527794586286, 'residual_dropout': 0.2706232722254871, 'learning_rate': 1.0002880795949656e-05, 'batch_size': 32, 'epochs': 146}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:36:21,733] Trial 17 finished with value: 0.977765368650992 and parameters: {'d': 256, 'd_hidden_factor': 4.426874031416949, 'n_layers': 9, 'hidden_dropout': 0.09467237243510315, 'residual_dropout': 0.03462459124041628, 'learning_rate': 5.941072156885347e-05, 'batch_size': 32, 'epochs': 167}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:41:20,487] Trial 18 finished with value: 0.9786220954903475 and parameters: {'d': 256, 'd_hidden_factor': 2.019335218198994, 'n_layers': 9, 'hidden_dropout': 0.4281197922513106, 'residual_dropout': 0.22594306843997852, 'learning_rate': 1.6947637298346798e-05, 'batch_size': 32, 'epochs': 109}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:41:36,224] Trial 19 finished with value: 0.9777960762696114 and parameters: {'d': 512, 'd_hidden_factor': 1.0738340759352232, 'n_layers': 7, 'hidden_dropout': 0.053251014036756084, 'residual_dropout': 0.10151590965262432, 'learning_rate': 0.0006441943583327288, 'batch_size': 256, 'epochs': 140}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:43:30,834] Trial 20 finished with value: 0.9775712670978569 and parameters: {'d': 64, 'd_hidden_factor': 3.3671063449870244, 'n_layers': 10, 'hidden_dropout': 0.19204317416908012, 'residual_dropout': 0.39392787696399834, 'learning_rate': 4.687114540611464e-05, 'batch_size': 128, 'epochs': 179}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:46:38,210] Trial 21 finished with value: 0.9807215221266861 and parameters: {'d': 256, 'd_hidden_factor': 1.7525599770751288, 'n_layers': 8, 'hidden_dropout': 0.12893075038624574, 'residual_dropout': 0.0018855796755865538, 'learning_rate': 2.5064817136221733e-05, 'batch_size': 32, 'epochs': 79}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:50:37,718] Trial 22 finished with value: 0.9830281819302156 and parameters: {'d': 256, 'd_hidden_factor': 2.8004687488188957, 'n_layers': 7, 'hidden_dropout': 0.05938525437874316, 'residual_dropout': 0.04850897951513364, 'learning_rate': 1.6403286027646655e-05, 'batch_size': 32, 'epochs': 109}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:54:37,291] Trial 23 finished with value: 0.9816718806314506 and parameters: {'d': 256, 'd_hidden_factor': 2.7569427321095032, 'n_layers': 7, 'hidden_dropout': 0.049724805694436686, 'residual_dropout': 0.062252228916001164, 'learning_rate': 1.6276492211558117e-05, 'batch_size': 32, 'epochs': 109}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 09:56:30,690] Trial 24 finished with value: 0.9822315507272805 and parameters: {'d': 256, 'd_hidden_factor': 3.074411996087749, 'n_layers': 7, 'hidden_dropout': 0.2527198349483732, 'residual_dropout': 0.1373851530652252, 'learning_rate': 0.00013255157002891522, 'batch_size': 32, 'epochs': 136}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 10:00:05,671] Trial 25 finished with value: 0.981460168022212 and parameters: {'d': 256, 'd_hidden_factor': 2.8438985248137167, 'n_layers': 9, 'hidden_dropout': 0.1513045368322924, 'residual_dropout': 0.2997844623786969, 'learning_rate': 5.200743783424938e-05, 'batch_size': 32, 'epochs': 119}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 10:03:28,550] Trial 26 finished with value: 0.983703168724305 and parameters: {'d': 256, 'd_hidden_factor': 2.3108407369139354, 'n_layers': 4, 'hidden_dropout': 0.056005811449557366, 'residual_dropout': 0.19074688086227115, 'learning_rate': 1.7831447465785937e-05, 'batch_size': 32, 'epochs': 156}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 10:06:22,363] Trial 27 finished with value: 0.980071762016873 and parameters: {'d': 256, 'd_hidden_factor': 2.361786030314555, 'n_layers': 3, 'hidden_dropout': 0.03713757995087619, 'residual_dropout': 0.19535392567306287, 'learning_rate': 1.5889181349305083e-05, 'batch_size': 32, 'epochs': 155}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 10:06:35,541] Trial 28 finished with value: 0.9685960108114896 and parameters: {'d': 64, 'd_hidden_factor': 3.4602908599662188, 'n_layers': 1, 'hidden_dropout': 0.1304231382113626, 'residual_dropout': 0.3867768863229287, 'learning_rate': 7.130780101196532e-05, 'batch_size': 256, 'epochs': 176}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 10:08:12,690] Trial 29 finished with value: 0.9782811254086387 and parameters: {'d': 512, 'd_hidden_factor': 3.897100203263083, 'n_layers': 4, 'hidden_dropout': 0.49234790898426983, 'residual_dropout': 0.2439670191240666, 'learning_rate': 4.5302617575408565e-05, 'batch_size': 128, 'epochs': 195}. Best is trial 3 with value: 0.9837552712725908.\n",
      "[I 2025-11-27 10:08:45,608] Trial 30 finished with value: 0.9838129911342357 and parameters: {'d': 64, 'd_hidden_factor': 2.9247039326229696, 'n_layers': 5, 'hidden_dropout': 0.39755589042756995, 'residual_dropout': 0.30421476423636545, 'learning_rate': 0.0003396010126803056, 'batch_size': 128, 'epochs': 88}. Best is trial 30 with value: 0.9838129911342357.\n",
      "[I 2025-11-27 10:09:10,713] Trial 31 finished with value: 0.9786160323171815 and parameters: {'d': 64, 'd_hidden_factor': 2.9588269447835502, 'n_layers': 4, 'hidden_dropout': 0.42518794588977626, 'residual_dropout': 0.31258523412962747, 'learning_rate': 0.0006439671317529887, 'batch_size': 128, 'epochs': 86}. Best is trial 30 with value: 0.9838129911342357.\n",
      "[I 2025-11-27 10:09:31,477] Trial 32 finished with value: 0.9763043468997085 and parameters: {'d': 64, 'd_hidden_factor': 2.5997781706103087, 'n_layers': 5, 'hidden_dropout': 0.3625343814017603, 'residual_dropout': 0.2766662702095061, 'learning_rate': 0.0003568746976457221, 'batch_size': 128, 'epochs': 55}. Best is trial 30 with value: 0.9838129911342357.\n",
      "[I 2025-11-27 10:09:59,321] Trial 33 finished with value: 0.9762458263241932 and parameters: {'d': 64, 'd_hidden_factor': 3.067987841254255, 'n_layers': 3, 'hidden_dropout': 0.46199387937869896, 'residual_dropout': 0.3689391963444134, 'learning_rate': 0.00026618865829499956, 'batch_size': 128, 'epochs': 103}. Best is trial 30 with value: 0.9838129911342357.\n",
      "[I 2025-11-27 10:10:29,353] Trial 34 finished with value: 0.9769907672219181 and parameters: {'d': 64, 'd_hidden_factor': 3.604765404191198, 'n_layers': 5, 'hidden_dropout': 0.3589606463823524, 'residual_dropout': 0.155976697272324, 'learning_rate': 0.00015875707852181905, 'batch_size': 128, 'epochs': 80}. Best is trial 30 with value: 0.9838129911342357.\n",
      "[I 2025-11-27 10:11:27,673] Trial 35 finished with value: 0.9755585170064067 and parameters: {'d': 256, 'd_hidden_factor': 2.0507433228487115, 'n_layers': 4, 'hidden_dropout': 0.26068584703754205, 'residual_dropout': 0.36537736234299767, 'learning_rate': 0.0009866644532975663, 'batch_size': 32, 'epochs': 65}. Best is trial 30 with value: 0.9838129911342357.\n",
      "[I 2025-11-27 10:11:51,754] Trial 36 finished with value: 0.9604999841475349 and parameters: {'d': 128, 'd_hidden_factor': 3.1951960499505745, 'n_layers': 5, 'hidden_dropout': 0.21004251574118313, 'residual_dropout': 0.3023643199934979, 'learning_rate': 2.288910455222199e-05, 'batch_size': 64, 'epochs': 31}. Best is trial 30 with value: 0.9838129911342357.\n",
      "[I 2025-11-27 10:12:11,385] Trial 37 finished with value: 0.9792698023720797 and parameters: {'d': 64, 'd_hidden_factor': 2.819634061394364, 'n_layers': 3, 'hidden_dropout': 0.38143521740654557, 'residual_dropout': 0.43388898621202177, 'learning_rate': 0.0014132863312410384, 'batch_size': 128, 'epochs': 96}. Best is trial 30 with value: 0.9838129911342357.\n",
      "[I 2025-11-27 10:14:16,859] Trial 38 finished with value: 0.985314720867003 and parameters: {'d': 256, 'd_hidden_factor': 2.3692840774683015, 'n_layers': 6, 'hidden_dropout': 0.3284770462087821, 'residual_dropout': 0.2556897797211803, 'learning_rate': 9.716444547420922e-05, 'batch_size': 32, 'epochs': 107}. Best is trial 38 with value: 0.985314720867003.\n",
      "[I 2025-11-27 10:15:09,184] Trial 39 finished with value: 0.9783815281815297 and parameters: {'d': 128, 'd_hidden_factor': 2.3900884990534386, 'n_layers': 6, 'hidden_dropout': 0.3121443136311757, 'residual_dropout': 0.24754282261647909, 'learning_rate': 0.00034825907790008353, 'batch_size': 64, 'epochs': 128}. Best is trial 38 with value: 0.985314720867003.\n",
      "[I 2025-11-27 10:15:22,317] Trial 40 finished with value: 0.9760730073703032 and parameters: {'d': 512, 'd_hidden_factor': 1.4939082438600118, 'n_layers': 2, 'hidden_dropout': 0.33499981848446453, 'residual_dropout': 0.3354633620161916, 'learning_rate': 8.877984702178372e-05, 'batch_size': 256, 'epochs': 92}. Best is trial 38 with value: 0.985314720867003.\n",
      "[I 2025-11-27 10:18:19,902] Trial 41 finished with value: 0.9806220077643598 and parameters: {'d': 256, 'd_hidden_factor': 2.169272611233207, 'n_layers': 5, 'hidden_dropout': 0.2901382904665285, 'residual_dropout': 0.2904591323773049, 'learning_rate': 3.6573905383823696e-05, 'batch_size': 32, 'epochs': 112}. Best is trial 38 with value: 0.985314720867003.\n",
      "[I 2025-11-27 10:19:58,840] Trial 42 finished with value: 0.9807511382413416 and parameters: {'d': 256, 'd_hidden_factor': 2.637352974731051, 'n_layers': 6, 'hidden_dropout': 0.27853837526239045, 'residual_dropout': 0.21526616264803286, 'learning_rate': 0.00022527086114963556, 'batch_size': 32, 'epochs': 104}. Best is trial 38 with value: 0.985314720867003.\n",
      "[I 2025-11-27 10:24:35,638] Trial 43 finished with value: 0.9814518473407944 and parameters: {'d': 256, 'd_hidden_factor': 3.2289897806790613, 'n_layers': 7, 'hidden_dropout': 0.39286323599510686, 'residual_dropout': 0.18202139573614515, 'learning_rate': 1.8157643132503903e-05, 'batch_size': 32, 'epochs': 117}. Best is trial 38 with value: 0.985314720867003.\n",
      "[I 2025-11-27 10:26:24,079] Trial 44 finished with value: 0.9808046510465436 and parameters: {'d': 256, 'd_hidden_factor': 2.9537301752097194, 'n_layers': 5, 'hidden_dropout': 0.23937931752583724, 'residual_dropout': 0.3191704703268134, 'learning_rate': 9.712873592820865e-05, 'batch_size': 32, 'epochs': 128}. Best is trial 38 with value: 0.985314720867003.\n",
      "[I 2025-11-27 10:27:47,929] Trial 45 finished with value: 0.9738960236413922 and parameters: {'d': 256, 'd_hidden_factor': 2.3948956160633865, 'n_layers': 6, 'hidden_dropout': 0.33457160528029767, 'residual_dropout': 0.35265216304215874, 'learning_rate': 0.00044847388007915497, 'batch_size': 32, 'epochs': 72}. Best is trial 38 with value: 0.985314720867003.\n",
      "[I 2025-11-27 10:30:08,652] Trial 46 finished with value: 0.9800303588765585 and parameters: {'d': 256, 'd_hidden_factor': 3.625452476696257, 'n_layers': 4, 'hidden_dropout': 0.45129817189735427, 'residual_dropout': 0.2554623381960828, 'learning_rate': 2.2522097729948333e-05, 'batch_size': 32, 'epochs': 87}. Best is trial 38 with value: 0.985314720867003.\n",
      "[I 2025-11-27 10:31:47,632] Trial 47 finished with value: 0.9755867731900251 and parameters: {'d': 64, 'd_hidden_factor': 4.110590720301218, 'n_layers': 7, 'hidden_dropout': 0.025172146053080283, 'residual_dropout': 0.06872427552831367, 'learning_rate': 1.3023144033284044e-05, 'batch_size': 64, 'epochs': 99}. Best is trial 38 with value: 0.985314720867003.\n",
      "[I 2025-11-27 10:32:56,367] Trial 48 finished with value: 0.971662706174752 and parameters: {'d': 128, 'd_hidden_factor': 1.9921514776733091, 'n_layers': 4, 'hidden_dropout': 0.3368246243861766, 'residual_dropout': 0.22634599964879393, 'learning_rate': 3.553971092884538e-05, 'batch_size': 32, 'epochs': 51}. Best is trial 38 with value: 0.985314720867003.\n",
      "[I 2025-11-27 10:34:22,818] Trial 49 finished with value: 0.9779111170696295 and parameters: {'d': 256, 'd_hidden_factor': 2.6906573355318026, 'n_layers': 6, 'hidden_dropout': 0.26869302247629523, 'residual_dropout': 0.12698764010354063, 'learning_rate': 0.00017434307148937782, 'batch_size': 32, 'epochs': 87}. Best is trial 38 with value: 0.985314720867003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 6063.92s\n",
      "  Best CV G-Mean: 0.9853\n",
      "  Best parameters:\n",
      "    d: 256\n",
      "    d_hidden_factor: 2.3692840774683015\n",
      "    n_layers: 6\n",
      "    hidden_dropout: 0.3284770462087821\n",
      "    residual_dropout: 0.2556897797211803\n",
      "    learning_rate: 9.716444547420922e-05\n",
      "    batch_size: 32\n",
      "    epochs: 107\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/107: Train Loss = 0.1473, Val Loss = 0.1855\n",
      "    Epoch 20/107: Train Loss = 0.0490, Val Loss = 0.1662\n",
      "    Epoch 30/107: Train Loss = 0.0336, Val Loss = 0.1463\n",
      "    Epoch 40/107: Train Loss = 0.0217, Val Loss = 0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 10:34:32,797] A new study created in memory with name: no-name-49cdb593-a17c-45c9-ba51-e902c6a8b85e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Early stopping at epoch 49\n",
      "✓ Training complete! Time: 9.93s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR mfeat-factors\n",
      "================================================================================\n",
      "Accuracy:        0.9783\n",
      "AUC OVO:         0.9992\n",
      "G-Mean:          0.9780\n",
      "Cross-Entropy:   0.0764\n",
      "================================================================================\n",
      "✓ Saved results for mfeat-factors\n",
      "\n",
      "✓ Completed mfeat-factors (18/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 19/30: steel-plates-fault\n",
      "################################################################################\n",
      "Loading processed dataset from cache: steel-plates-fault\n",
      "Using device: cuda\n",
      "Dataset: steel-plates-fault\n",
      "  Train: (1358, 27), Test: (583, 27)\n",
      "  Features: 27, Classes: 7\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: steel-plates-fault\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 10:34:47,904] Trial 0 finished with value: 0.2819697622028472 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.2819697622028472.\n",
      "[I 2025-11-27 10:35:18,677] Trial 1 finished with value: 0.7652942150274382 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.7652942150274382.\n",
      "[I 2025-11-27 10:35:55,459] Trial 2 finished with value: 0.7739187315506323 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 2 with value: 0.7739187315506323.\n",
      "[I 2025-11-27 10:39:51,968] Trial 3 finished with value: 0.7723951510027295 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 2 with value: 0.7739187315506323.\n",
      "[I 2025-11-27 10:40:23,207] Trial 4 finished with value: 0.7721004101394118 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 2 with value: 0.7739187315506323.\n",
      "[I 2025-11-27 10:43:11,052] Trial 5 finished with value: 0.6891460395820573 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 2 with value: 0.7739187315506323.\n",
      "[I 2025-11-27 10:45:15,131] Trial 6 finished with value: 0.6816363233993378 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 2 with value: 0.7739187315506323.\n",
      "[I 2025-11-27 10:45:29,189] Trial 7 finished with value: 0.7446879633542829 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 2 with value: 0.7739187315506323.\n",
      "[I 2025-11-27 10:45:35,392] Trial 8 finished with value: 0.7607657399261508 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 2 with value: 0.7739187315506323.\n",
      "[I 2025-11-27 10:45:38,901] Trial 9 finished with value: 0.7804351437433923 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:45:41,871] Trial 10 finished with value: 0.7671025921057755 and parameters: {'d': 256, 'd_hidden_factor': 4.983415693331228, 'n_layers': 1, 'hidden_dropout': 0.44545663057052365, 'residual_dropout': 0.2217318988758852, 'learning_rate': 0.0013249155895711754, 'batch_size': 256, 'epochs': 145}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:46:00,259] Trial 11 finished with value: 0.7619617038118299 and parameters: {'d': 512, 'd_hidden_factor': 4.561570484976926, 'n_layers': 3, 'hidden_dropout': 0.16310974540791695, 'residual_dropout': 0.18362738732213654, 'learning_rate': 0.00012688024392471325, 'batch_size': 256, 'epochs': 157}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:46:34,594] Trial 12 finished with value: 0.7547482913612371 and parameters: {'d': 128, 'd_hidden_factor': 2.507861502703489, 'n_layers': 9, 'hidden_dropout': 0.17091847105211322, 'residual_dropout': 0.11419704643922987, 'learning_rate': 0.0004356378962632358, 'batch_size': 64, 'epochs': 31}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:46:50,452] Trial 13 finished with value: 0.7627592586607271 and parameters: {'d': 256, 'd_hidden_factor': 4.2037764573897505, 'n_layers': 8, 'hidden_dropout': 0.0661156727729458, 'residual_dropout': 0.14792120604505007, 'learning_rate': 0.000738011172565629, 'batch_size': 128, 'epochs': 57}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:46:59,522] Trial 14 finished with value: 0.4595821671485331 and parameters: {'d': 128, 'd_hidden_factor': 2.0489934704481887, 'n_layers': 1, 'hidden_dropout': 0.39735747450550907, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 6.801678770781595e-05, 'batch_size': 256, 'epochs': 121}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:47:16,729] Trial 15 finished with value: 0.7718475370734134 and parameters: {'d': 256, 'd_hidden_factor': 2.708816821246878, 'n_layers': 3, 'hidden_dropout': 0.20515888070779514, 'residual_dropout': 0.2397569208234826, 'learning_rate': 0.00828044546605218, 'batch_size': 64, 'epochs': 169}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:47:37,893] Trial 16 finished with value: 0.23276690368495698 and parameters: {'d': 64, 'd_hidden_factor': 3.577334648741387, 'n_layers': 4, 'hidden_dropout': 0.11046894625567605, 'residual_dropout': 0.4201469348604926, 'learning_rate': 1.0011881142426159e-05, 'batch_size': 256, 'epochs': 138}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:47:59,016] Trial 17 finished with value: 0.7711422698226882 and parameters: {'d': 512, 'd_hidden_factor': 1.8339025678503724, 'n_layers': 8, 'hidden_dropout': 0.22641849467787545, 'residual_dropout': 0.053355412359392534, 'learning_rate': 0.0002682578084204811, 'batch_size': 128, 'epochs': 105}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:48:16,749] Trial 18 finished with value: 0.7599963263915179 and parameters: {'d': 128, 'd_hidden_factor': 4.177733113237734, 'n_layers': 3, 'hidden_dropout': 0.37274536605122993, 'residual_dropout': 0.2741263944983908, 'learning_rate': 0.001370120320492544, 'batch_size': 64, 'epochs': 62}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:48:27,117] Trial 19 finished with value: 0.7708153627064757 and parameters: {'d': 256, 'd_hidden_factor': 3.4176129404706703, 'n_layers': 2, 'hidden_dropout': 0.2712299707869676, 'residual_dropout': 0.39839970561446225, 'learning_rate': 0.00012794499015081993, 'batch_size': 256, 'epochs': 173}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:48:57,627] Trial 20 finished with value: 0.7530502706254962 and parameters: {'d': 128, 'd_hidden_factor': 2.5159022451762993, 'n_layers': 7, 'hidden_dropout': 0.09754008217805937, 'residual_dropout': 0.18986536616420802, 'learning_rate': 0.0006343435725476305, 'batch_size': 64, 'epochs': 114}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:52:21,020] Trial 21 finished with value: 0.7535232014786508 and parameters: {'d': 256, 'd_hidden_factor': 2.9337886679145755, 'n_layers': 9, 'hidden_dropout': 0.2434291786024131, 'residual_dropout': 0.29200208919594917, 'learning_rate': 3.0058905072681507e-05, 'batch_size': 32, 'epochs': 79}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:55:21,155] Trial 22 finished with value: 0.6778401921451781 and parameters: {'d': 256, 'd_hidden_factor': 2.904343127776696, 'n_layers': 10, 'hidden_dropout': 0.3165084123361712, 'residual_dropout': 0.3863277568943377, 'learning_rate': 1.4710919070891296e-05, 'batch_size': 32, 'epochs': 57}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:56:58,289] Trial 23 finished with value: 0.770616717741816 and parameters: {'d': 256, 'd_hidden_factor': 3.949208182237251, 'n_layers': 5, 'hidden_dropout': 0.20301006065053034, 'residual_dropout': 0.46042281013445907, 'learning_rate': 5.801309554568338e-05, 'batch_size': 32, 'epochs': 80}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 10:59:21,937] Trial 24 finished with value: 0.7693040965273451 and parameters: {'d': 256, 'd_hidden_factor': 2.4393803139146883, 'n_layers': 10, 'hidden_dropout': 0.28644851441319075, 'residual_dropout': 0.27797435038947527, 'learning_rate': 3.424643211082078e-05, 'batch_size': 32, 'epochs': 46}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:01:06,049] Trial 25 finished with value: 0.6937239488701111 and parameters: {'d': 256, 'd_hidden_factor': 1.7588180804538915, 'n_layers': 4, 'hidden_dropout': 0.4090078859640838, 'residual_dropout': 0.16015433917838068, 'learning_rate': 1.734653298467576e-05, 'batch_size': 32, 'epochs': 77}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:01:10,464] Trial 26 finished with value: 0.0639174250947753 and parameters: {'d': 64, 'd_hidden_factor': 3.1729523249460776, 'n_layers': 2, 'hidden_dropout': 0.3475560367765505, 'residual_dropout': 0.36393848195459544, 'learning_rate': 0.00020302273601575601, 'batch_size': 256, 'epochs': 45}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:02:12,880] Trial 27 finished with value: 0.7684783241132811 and parameters: {'d': 512, 'd_hidden_factor': 4.653544201998555, 'n_layers': 8, 'hidden_dropout': 0.24356767461981754, 'residual_dropout': 0.3068449759057107, 'learning_rate': 7.960724889009904e-05, 'batch_size': 128, 'epochs': 112}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:02:21,616] Trial 28 finished with value: 0.7630923984930685 and parameters: {'d': 256, 'd_hidden_factor': 2.7174625154202223, 'n_layers': 7, 'hidden_dropout': 0.19161560341509878, 'residual_dropout': 0.22302077531900827, 'learning_rate': 0.002338667587294082, 'batch_size': 256, 'epochs': 132}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:02:33,578] Trial 29 finished with value: 0.22057250765435713 and parameters: {'d': 64, 'd_hidden_factor': 3.70190511379115, 'n_layers': 5, 'hidden_dropout': 0.49234790898426983, 'residual_dropout': 0.43470022514418927, 'learning_rate': 0.00040482177266683484, 'batch_size': 128, 'epochs': 32}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:03:43,812] Trial 30 finished with value: 0.7580440950836357 and parameters: {'d': 128, 'd_hidden_factor': 4.02277987965878, 'n_layers': 7, 'hidden_dropout': 0.12936553289746575, 'residual_dropout': 0.11332195947468018, 'learning_rate': 0.00847033887404098, 'batch_size': 32, 'epochs': 83}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:04:27,226] Trial 31 finished with value: 0.7521111741251999 and parameters: {'d': 256, 'd_hidden_factor': 3.556064212053729, 'n_layers': 9, 'hidden_dropout': 0.3211932692842187, 'residual_dropout': 0.3426618761305476, 'learning_rate': 0.00271140600142245, 'batch_size': 64, 'epochs': 123}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:04:48,574] Trial 32 finished with value: 0.7586631007060491 and parameters: {'d': 256, 'd_hidden_factor': 3.7688558044248746, 'n_layers': 4, 'hidden_dropout': 0.3027960015596411, 'residual_dropout': 0.32555093351694697, 'learning_rate': 0.005035366275032826, 'batch_size': 64, 'epochs': 149}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:05:19,239] Trial 33 finished with value: 0.7652586222151071 and parameters: {'d': 256, 'd_hidden_factor': 3.144941728447762, 'n_layers': 5, 'hidden_dropout': 0.2583097066573604, 'residual_dropout': 0.3660063294909089, 'learning_rate': 0.005590682166302927, 'batch_size': 64, 'epochs': 126}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:05:54,306] Trial 34 finished with value: 0.7510371207934472 and parameters: {'d': 256, 'd_hidden_factor': 4.4124880122714645, 'n_layers': 6, 'hidden_dropout': 0.3355598944314242, 'residual_dropout': 0.4490917697795802, 'learning_rate': 0.0008539033361706574, 'batch_size': 64, 'epochs': 96}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:06:23,802] Trial 35 finished with value: 0.7715283966087745 and parameters: {'d': 128, 'd_hidden_factor': 3.3039571324790593, 'n_layers': 7, 'hidden_dropout': 0.2923293551615265, 'residual_dropout': 0.2513078736886481, 'learning_rate': 0.009912218799508809, 'batch_size': 64, 'epochs': 107}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:06:37,518] Trial 36 finished with value: 0.7605846212767048 and parameters: {'d': 256, 'd_hidden_factor': 2.8260736387345347, 'n_layers': 2, 'hidden_dropout': 0.376756810514871, 'residual_dropout': 0.40273652560670153, 'learning_rate': 0.002139028029198533, 'batch_size': 64, 'epochs': 65}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:07:48,005] Trial 37 finished with value: 0.7596894543705545 and parameters: {'d': 64, 'd_hidden_factor': 2.2248749948992397, 'n_layers': 6, 'hidden_dropout': 0.22708354420246382, 'residual_dropout': 0.3538292706076076, 'learning_rate': 0.003994677223401148, 'batch_size': 32, 'epochs': 94}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:08:17,832] Trial 38 finished with value: 0.76788142464559 and parameters: {'d': 512, 'd_hidden_factor': 3.0891902284393806, 'n_layers': 1, 'hidden_dropout': 0.42479141502120604, 'residual_dropout': 0.30821777843011283, 'learning_rate': 4.217079622994824e-05, 'batch_size': 64, 'epochs': 72}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:08:35,999] Trial 39 finished with value: 0.7731722392248922 and parameters: {'d': 128, 'd_hidden_factor': 3.393487380267861, 'n_layers': 3, 'hidden_dropout': 0.26813450184514653, 'residual_dropout': 0.47065727945563923, 'learning_rate': 0.00016166916502344025, 'batch_size': 256, 'epochs': 139}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:08:52,038] Trial 40 finished with value: 0.7756393347649821 and parameters: {'d': 128, 'd_hidden_factor': 3.4055567955036095, 'n_layers': 3, 'hidden_dropout': 0.26557787560939267, 'residual_dropout': 0.47654255781897226, 'learning_rate': 0.00022781524673684274, 'batch_size': 256, 'epochs': 161}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:09:11,563] Trial 41 finished with value: 0.7733967086300086 and parameters: {'d': 128, 'd_hidden_factor': 3.381732874795365, 'n_layers': 3, 'hidden_dropout': 0.2636780136550979, 'residual_dropout': 0.4596340592524291, 'learning_rate': 0.00016617662050405976, 'batch_size': 256, 'epochs': 164}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:09:28,045] Trial 42 finished with value: 0.7665027348136011 and parameters: {'d': 128, 'd_hidden_factor': 3.5139531010270897, 'n_layers': 3, 'hidden_dropout': 0.2797120467846402, 'residual_dropout': 0.4756024654332913, 'learning_rate': 0.00021020264456117116, 'batch_size': 256, 'epochs': 185}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:09:44,046] Trial 43 finished with value: 0.7625212317217696 and parameters: {'d': 128, 'd_hidden_factor': 3.8600115877907455, 'n_layers': 3, 'hidden_dropout': 0.23458017685337818, 'residual_dropout': 0.49600505342910367, 'learning_rate': 0.00017392790753778707, 'batch_size': 256, 'epochs': 162}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:10:07,040] Trial 44 finished with value: 0.70296978200565 and parameters: {'d': 128, 'd_hidden_factor': 3.2934291638048507, 'n_layers': 4, 'hidden_dropout': 0.26602703931368377, 'residual_dropout': 0.4718254677387281, 'learning_rate': 0.00010050868874283534, 'batch_size': 256, 'epochs': 151}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:10:16,496] Trial 45 finished with value: 0.7755057996165122 and parameters: {'d': 128, 'd_hidden_factor': 4.062952492441166, 'n_layers': 2, 'hidden_dropout': 0.18079085814877544, 'residual_dropout': 0.4312420275768453, 'learning_rate': 0.00032303105016100327, 'batch_size': 256, 'epochs': 141}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:10:25,797] Trial 46 finished with value: 0.7618433694263069 and parameters: {'d': 128, 'd_hidden_factor': 4.173890730533075, 'n_layers': 2, 'hidden_dropout': 0.1459545270077999, 'residual_dropout': 0.4312607176866201, 'learning_rate': 0.0002943094478954095, 'batch_size': 256, 'epochs': 182}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:10:35,922] Trial 47 finished with value: 0.7727784357363883 and parameters: {'d': 128, 'd_hidden_factor': 4.4181267179624575, 'n_layers': 1, 'hidden_dropout': 0.19114508434411015, 'residual_dropout': 0.4128946175127599, 'learning_rate': 0.00026377050134196163, 'batch_size': 256, 'epochs': 155}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:10:43,569] Trial 48 finished with value: 0.7724345634075122 and parameters: {'d': 128, 'd_hidden_factor': 4.884429572818466, 'n_layers': 2, 'hidden_dropout': 0.21053335916538024, 'residual_dropout': 0.44449012368592433, 'learning_rate': 0.0004612455413044817, 'batch_size': 256, 'epochs': 163}. Best is trial 9 with value: 0.7804351437433923.\n",
      "[I 2025-11-27 11:10:50,439] Trial 49 finished with value: 0.7606407641997227 and parameters: {'d': 128, 'd_hidden_factor': 4.041655844046121, 'n_layers': 4, 'hidden_dropout': 0.07868523884428547, 'residual_dropout': 0.4999468213800488, 'learning_rate': 0.0008629447128815287, 'batch_size': 256, 'epochs': 138}. Best is trial 9 with value: 0.7804351437433923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 2177.64s\n",
      "  Best CV G-Mean: 0.7804\n",
      "  Best parameters:\n",
      "    d: 256\n",
      "    d_hidden_factor: 3.9242921433782283\n",
      "    n_layers: 2\n",
      "    hidden_dropout: 0.30034928391679494\n",
      "    residual_dropout: 0.4329322291516323\n",
      "    learning_rate: 0.008924108207819248\n",
      "    batch_size: 256\n",
      "    epochs: 123\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/123: Train Loss = 0.5490, Val Loss = 0.6852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 11:10:50,809] A new study created in memory with name: no-name-a75ae8b0-2ce9-4e99-8216-bcf743eda624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 20/123: Train Loss = 0.4658, Val Loss = 0.6155\n",
      "    Early stopping at epoch 27\n",
      "✓ Training complete! Time: 0.34s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR steel-plates-fault\n",
      "================================================================================\n",
      "Accuracy:        0.7479\n",
      "AUC OVO:         0.9540\n",
      "G-Mean:          0.8028\n",
      "Cross-Entropy:   0.7581\n",
      "================================================================================\n",
      "✓ Saved results for steel-plates-fault\n",
      "\n",
      "✓ Completed steel-plates-fault (19/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 20/30: wdbc\n",
      "################################################################################\n",
      "Loading processed dataset from cache: wdbc\n",
      "Using device: cuda\n",
      "Dataset: wdbc\n",
      "  Train: (398, 30), Test: (171, 30)\n",
      "  Features: 30, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: wdbc\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 11:10:54,746] Trial 0 finished with value: 0.9748143661185684 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.9748143661185684.\n",
      "[I 2025-11-27 11:11:03,799] Trial 1 finished with value: 0.9697906892984761 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 0 with value: 0.9748143661185684.\n",
      "[I 2025-11-27 11:11:14,086] Trial 2 finished with value: 0.9705914859133452 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: 0.9748143661185684.\n",
      "[I 2025-11-27 11:12:21,999] Trial 3 finished with value: 0.9807786352695093 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:12:29,290] Trial 4 finished with value: 0.9766829790512471 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:13:19,547] Trial 5 finished with value: 0.9787582249808363 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:13:56,310] Trial 6 finished with value: 0.9734865036715707 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:14:00,390] Trial 7 finished with value: 0.9766683533601693 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:14:02,451] Trial 8 finished with value: 0.980252059374967 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:14:03,530] Trial 9 finished with value: 0.9691757184852345 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:15:41,231] Trial 10 finished with value: 0.9717298144547091 and parameters: {'d': 256, 'd_hidden_factor': 4.956401873386991, 'n_layers': 10, 'hidden_dropout': 0.10467358725545478, 'residual_dropout': 0.21319384192877996, 'learning_rate': 1.0455868741494775e-05, 'batch_size': 32, 'epochs': 159}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:15:47,794] Trial 11 finished with value: 0.9726544451584178 and parameters: {'d': 512, 'd_hidden_factor': 2.245569478012125, 'n_layers': 10, 'hidden_dropout': 0.010476594631962113, 'residual_dropout': 0.255524419252097, 'learning_rate': 0.0008904221936858838, 'batch_size': 256, 'epochs': 198}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:15:56,312] Trial 12 finished with value: 0.9749254235853053 and parameters: {'d': 256, 'd_hidden_factor': 3.105429421116747, 'n_layers': 8, 'hidden_dropout': 0.008038652206972724, 'residual_dropout': 0.026421789768837745, 'learning_rate': 5.375248322425842e-05, 'batch_size': 256, 'epochs': 198}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:16:18,776] Trial 13 finished with value: 0.9536278394808189 and parameters: {'d': 128, 'd_hidden_factor': 4.393031779314121, 'n_layers': 8, 'hidden_dropout': 0.4009467477691605, 'residual_dropout': 0.4903748330118821, 'learning_rate': 1.0156421711796782e-05, 'batch_size': 128, 'epochs': 160}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:17:17,953] Trial 14 finished with value: 0.9697828983850991 and parameters: {'d': 128, 'd_hidden_factor': 2.3579113600319364, 'n_layers': 8, 'hidden_dropout': 0.09752730303763973, 'residual_dropout': 0.26479210264905184, 'learning_rate': 5.2348743226099426e-05, 'batch_size': 32, 'epochs': 157}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:17:22,204] Trial 15 finished with value: 0.9675622898262264 and parameters: {'d': 256, 'd_hidden_factor': 3.4148239983519093, 'n_layers': 9, 'hidden_dropout': 0.2100144113534665, 'residual_dropout': 0.4107356069462064, 'learning_rate': 0.0007072646067119463, 'batch_size': 256, 'epochs': 66}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:17:25,297] Trial 16 finished with value: 0.9734865036715707 and parameters: {'d': 64, 'd_hidden_factor': 1.7324314271361396, 'n_layers': 1, 'hidden_dropout': 0.10024071832905038, 'residual_dropout': 0.1488236073281246, 'learning_rate': 0.0004544039227900941, 'batch_size': 256, 'epochs': 140}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:17:46,153] Trial 17 finished with value: 0.9577121716911566 and parameters: {'d': 512, 'd_hidden_factor': 2.7071954100982487, 'n_layers': 7, 'hidden_dropout': 0.42361711480884384, 'residual_dropout': 0.37768936735346226, 'learning_rate': 0.00866097213453406, 'batch_size': 32, 'epochs': 182}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:17:49,605] Trial 18 finished with value: 0.9762371983515583 and parameters: {'d': 256, 'd_hidden_factor': 4.328105898153262, 'n_layers': 4, 'hidden_dropout': 0.2264434318636487, 'residual_dropout': 0.3007692106563874, 'learning_rate': 0.0018678233048472989, 'batch_size': 128, 'epochs': 74}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:17:54,852] Trial 19 finished with value: 0.9567237859679691 and parameters: {'d': 128, 'd_hidden_factor': 1.9075349334588585, 'n_layers': 4, 'hidden_dropout': 0.15646996140556554, 'residual_dropout': 0.2009838505480701, 'learning_rate': 2.3906293977172207e-05, 'batch_size': 256, 'epochs': 110}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:18:38,775] Trial 20 finished with value: 0.9660098187949513 and parameters: {'d': 128, 'd_hidden_factor': 3.4430661664311515, 'n_layers': 9, 'hidden_dropout': 0.0638370768713501, 'residual_dropout': 0.45472441589358303, 'learning_rate': 0.0001380239209845302, 'batch_size': 32, 'epochs': 136}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:19:26,760] Trial 21 finished with value: 0.9807786352695093 and parameters: {'d': 128, 'd_hidden_factor': 1.0753689629712153, 'n_layers': 6, 'hidden_dropout': 0.2686556170052365, 'residual_dropout': 0.021968538406766935, 'learning_rate': 3.0058905072681507e-05, 'batch_size': 32, 'epochs': 92}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:20:08,424] Trial 22 finished with value: 0.969448011332972 and parameters: {'d': 128, 'd_hidden_factor': 1.0756737482952552, 'n_layers': 7, 'hidden_dropout': 0.2593825466436156, 'residual_dropout': 0.08016980483256025, 'learning_rate': 7.492292749451343e-05, 'batch_size': 32, 'epochs': 88}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:21:09,851] Trial 23 finished with value: 0.9771410464354524 and parameters: {'d': 128, 'd_hidden_factor': 2.752466810599879, 'n_layers': 7, 'hidden_dropout': 0.17773725189754136, 'residual_dropout': 0.1311594150761049, 'learning_rate': 2.32195943645926e-05, 'batch_size': 32, 'epochs': 111}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:21:29,420] Trial 24 finished with value: 0.9773878135774389 and parameters: {'d': 128, 'd_hidden_factor': 4.247896463561199, 'n_layers': 3, 'hidden_dropout': 0.3630612305644981, 'residual_dropout': 0.020032038741565655, 'learning_rate': 3.261126335283925e-05, 'batch_size': 32, 'epochs': 57}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:22:35,659] Trial 25 finished with value: 0.9773878135774389 and parameters: {'d': 256, 'd_hidden_factor': 1.7588180804538915, 'n_layers': 9, 'hidden_dropout': 0.2418543515857726, 'residual_dropout': 0.3818949608787146, 'learning_rate': 1.462955298097966e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:22:41,473] Trial 26 finished with value: 0.9802520593749667 and parameters: {'d': 64, 'd_hidden_factor': 4.898985458984265, 'n_layers': 5, 'hidden_dropout': 0.352664294603069, 'residual_dropout': 0.2057945828285987, 'learning_rate': 8.822462989648172e-05, 'batch_size': 256, 'epochs': 102}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:22:58,607] Trial 27 finished with value: 0.9767378146921635 and parameters: {'d': 512, 'd_hidden_factor': 1.4340418191255528, 'n_layers': 7, 'hidden_dropout': 0.18583223641687124, 'residual_dropout': 0.29191293149076525, 'learning_rate': 4.495883757557331e-05, 'batch_size': 128, 'epochs': 182}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:23:14,613] Trial 28 finished with value: 0.9637429473975582 and parameters: {'d': 128, 'd_hidden_factor': 3.4020367270327205, 'n_layers': 3, 'hidden_dropout': 0.2665663784623712, 'residual_dropout': 0.09000072147690401, 'learning_rate': 0.0002912234363264636, 'batch_size': 32, 'epochs': 79}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:23:18,213] Trial 29 finished with value: 0.97120226511576 and parameters: {'d': 64, 'd_hidden_factor': 3.8879207189054386, 'n_layers': 5, 'hidden_dropout': 0.49234790898426983, 'residual_dropout': 0.38205356803550294, 'learning_rate': 0.0001917211175537227, 'batch_size': 128, 'epochs': 37}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:23:24,670] Trial 30 finished with value: 0.9665312688652238 and parameters: {'d': 256, 'd_hidden_factor': 2.4785691794250373, 'n_layers': 10, 'hidden_dropout': 0.44077734940510815, 'residual_dropout': 0.18379853523074952, 'learning_rate': 1.760228287835365e-05, 'batch_size': 256, 'epochs': 57}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:23:30,545] Trial 31 finished with value: 0.9678309966067635 and parameters: {'d': 64, 'd_hidden_factor': 4.822503954703341, 'n_layers': 5, 'hidden_dropout': 0.3455644543963491, 'residual_dropout': 0.12139255840821886, 'learning_rate': 7.72512552682514e-05, 'batch_size': 256, 'epochs': 103}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:23:38,481] Trial 32 finished with value: 0.9734865036715707 and parameters: {'d': 64, 'd_hidden_factor': 4.66989458055338, 'n_layers': 6, 'hidden_dropout': 0.2874609289203544, 'residual_dropout': 0.04610301440461352, 'learning_rate': 9.987686318395638e-05, 'batch_size': 256, 'epochs': 120}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:23:44,475] Trial 33 finished with value: 0.9446003683717461 and parameters: {'d': 64, 'd_hidden_factor': 4.078043765093003, 'n_layers': 5, 'hidden_dropout': 0.3855120211585059, 'residual_dropout': 0.2258828651135281, 'learning_rate': 3.880731534000441e-05, 'batch_size': 256, 'epochs': 103}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:24:00,554] Trial 34 finished with value: 0.9746748554470906 and parameters: {'d': 64, 'd_hidden_factor': 3.6700100983445334, 'n_layers': 6, 'hidden_dropout': 0.3352753755225828, 'residual_dropout': 0.18509073348112084, 'learning_rate': 0.00018771823845528126, 'batch_size': 64, 'epochs': 63}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:24:07,660] Trial 35 finished with value: 0.9753674032887659 and parameters: {'d': 128, 'd_hidden_factor': 4.544075261303515, 'n_layers': 4, 'hidden_dropout': 0.13081422197142312, 'residual_dropout': 0.2961335506865247, 'learning_rate': 1.675648784195739e-05, 'batch_size': 256, 'epochs': 139}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:24:17,531] Trial 36 finished with value: 0.969499044961343 and parameters: {'d': 128, 'd_hidden_factor': 2.9704129031054958, 'n_layers': 5, 'hidden_dropout': 0.315386970641091, 'residual_dropout': 0.34545258959090175, 'learning_rate': 0.00042653570622258147, 'batch_size': 64, 'epochs': 48}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:24:36,331] Trial 37 finished with value: 0.9681461084399116 and parameters: {'d': 64, 'd_hidden_factor': 2.0737754964273796, 'n_layers': 6, 'hidden_dropout': 0.21192277473550875, 'residual_dropout': 0.46853003671233556, 'learning_rate': 0.002292202760854042, 'batch_size': 32, 'epochs': 88}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:24:42,285] Trial 38 finished with value: 0.9681012312447648 and parameters: {'d': 128, 'd_hidden_factor': 1.3688455273554667, 'n_layers': 6, 'hidden_dropout': 0.45857541116773587, 'residual_dropout': 0.05704644849976412, 'learning_rate': 6.824042330254397e-05, 'batch_size': 256, 'epochs': 96}. Best is trial 3 with value: 0.9807786352695093.\n",
      "[I 2025-11-27 11:24:47,941] Trial 39 finished with value: 0.9843613884626498 and parameters: {'d': 256, 'd_hidden_factor': 3.679472268120411, 'n_layers': 3, 'hidden_dropout': 0.2890784603364066, 'residual_dropout': 0.4083359142322675, 'learning_rate': 0.0039888567934246826, 'batch_size': 64, 'epochs': 132}. Best is trial 39 with value: 0.9843613884626498.\n",
      "[I 2025-11-27 11:24:50,752] Trial 40 finished with value: 0.9700980102182474 and parameters: {'d': 256, 'd_hidden_factor': 3.595230882279206, 'n_layers': 1, 'hidden_dropout': 0.28923931483994775, 'residual_dropout': 0.4194939346344666, 'learning_rate': 0.0055507071090564256, 'batch_size': 64, 'epochs': 177}. Best is trial 39 with value: 0.9843613884626498.\n",
      "[I 2025-11-27 11:24:55,095] Trial 41 finished with value: 0.9752014313416332 and parameters: {'d': 256, 'd_hidden_factor': 3.207847237801604, 'n_layers': 3, 'hidden_dropout': 0.3200602894645967, 'residual_dropout': 0.45026104176177667, 'learning_rate': 0.004142921573138831, 'batch_size': 64, 'epochs': 148}. Best is trial 39 with value: 0.9843613884626498.\n",
      "[I 2025-11-27 11:24:59,277] Trial 42 finished with value: 0.9673417882714433 and parameters: {'d': 256, 'd_hidden_factor': 2.9104382351029265, 'n_layers': 2, 'hidden_dropout': 0.24276697184680038, 'residual_dropout': 0.3560019471836933, 'learning_rate': 0.0012564763205961651, 'batch_size': 64, 'epochs': 131}. Best is trial 39 with value: 0.9843613884626498.\n",
      "[I 2025-11-27 11:25:03,414] Trial 43 finished with value: 0.9747859129138279 and parameters: {'d': 256, 'd_hidden_factor': 2.552668250990738, 'n_layers': 3, 'hidden_dropout': 0.3659665332325748, 'residual_dropout': 0.0005233439450442745, 'learning_rate': 0.0023959374942989784, 'batch_size': 64, 'epochs': 116}. Best is trial 39 with value: 0.9843613884626498.\n",
      "[I 2025-11-27 11:25:23,928] Trial 44 finished with value: 0.9677003277402226 and parameters: {'d': 512, 'd_hidden_factor': 3.9819520220832185, 'n_layers': 4, 'hidden_dropout': 0.2782278213167679, 'residual_dropout': 0.3191704703268134, 'learning_rate': 0.004835784341932017, 'batch_size': 32, 'epochs': 73}. Best is trial 39 with value: 0.9843613884626498.\n",
      "[I 2025-11-27 11:25:33,142] Trial 45 finished with value: 0.9718531586059627 and parameters: {'d': 256, 'd_hidden_factor': 4.154073439095409, 'n_layers': 8, 'hidden_dropout': 0.32205122563963656, 'residual_dropout': 0.4774394370560169, 'learning_rate': 0.009506487571506019, 'batch_size': 64, 'epochs': 103}. Best is trial 39 with value: 0.9843613884626498.\n",
      "[I 2025-11-27 11:25:38,870] Trial 46 finished with value: 0.9717298144547091 and parameters: {'d': 256, 'd_hidden_factor': 3.2351105048095206, 'n_layers': 2, 'hidden_dropout': 0.38578609038384903, 'residual_dropout': 0.2374481449914729, 'learning_rate': 3.1965059874231254e-05, 'batch_size': 256, 'epochs': 170}. Best is trial 39 with value: 0.9843613884626498.\n",
      "[I 2025-11-27 11:25:51,708] Trial 47 finished with value: 0.9722563903492516 and parameters: {'d': 64, 'd_hidden_factor': 3.735121718737688, 'n_layers': 7, 'hidden_dropout': 0.3010731664765197, 'residual_dropout': 0.26555602868248357, 'learning_rate': 0.006374472455739124, 'batch_size': 32, 'epochs': 94}. Best is trial 39 with value: 0.9843613884626498.\n",
      "[I 2025-11-27 11:25:54,698] Trial 48 finished with value: 0.9667442102157604 and parameters: {'d': 128, 'd_hidden_factor': 4.884429572818466, 'n_layers': 5, 'hidden_dropout': 0.041987255576772076, 'residual_dropout': 0.39598028492761744, 'learning_rate': 0.0026778258970974857, 'batch_size': 128, 'epochs': 77}. Best is trial 39 with value: 0.9843613884626498.\n",
      "[I 2025-11-27 11:25:57,774] Trial 49 finished with value: 0.9696947784749584 and parameters: {'d': 256, 'd_hidden_factor': 4.552081253223655, 'n_layers': 4, 'hidden_dropout': 0.19367369090003692, 'residual_dropout': 0.49952232140697156, 'learning_rate': 0.000873835301560557, 'batch_size': 256, 'epochs': 147}. Best is trial 39 with value: 0.9843613884626498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 906.97s\n",
      "  Best CV G-Mean: 0.9844\n",
      "  Best parameters:\n",
      "    d: 256\n",
      "    d_hidden_factor: 3.679472268120411\n",
      "    n_layers: 3\n",
      "    hidden_dropout: 0.2890784603364066\n",
      "    residual_dropout: 0.4083359142322675\n",
      "    learning_rate: 0.0039888567934246826\n",
      "    batch_size: 64\n",
      "    epochs: 132\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/132: Train Loss = 0.0600, Val Loss = 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 11:25:58,154] A new study created in memory with name: no-name-d4bce46a-7a78-4e34-bcd2-19053ba9c62e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 20/132: Train Loss = 0.0341, Val Loss = 0.0197\n",
      "    Early stopping at epoch 20\n",
      "✓ Training complete! Time: 0.36s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR wdbc\n",
      "================================================================================\n",
      "Accuracy:        0.9591\n",
      "AUC OVO:         0.9896\n",
      "G-Mean:          0.9579\n",
      "Cross-Entropy:   0.1355\n",
      "================================================================================\n",
      "✓ Saved results for wdbc\n",
      "\n",
      "✓ Completed wdbc (20/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 21/30: climate-model-simulation-crashes\n",
      "################################################################################\n",
      "Loading processed dataset from cache: climate-model-simulation-crashes\n",
      "Using device: cuda\n",
      "Dataset: climate-model-simulation-crashes\n",
      "  Train: (378, 18), Test: (162, 18)\n",
      "  Features: 18, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: climate-model-simulation-crashes\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 11:26:02,006] Trial 0 finished with value: 0.7974245415041891 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.7974245415041891.\n",
      "[I 2025-11-27 11:26:11,003] Trial 1 finished with value: 0.6541101102640742 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 0 with value: 0.7974245415041891.\n",
      "[I 2025-11-27 11:26:21,505] Trial 2 finished with value: 0.7848882665640848 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: 0.7974245415041891.\n",
      "[I 2025-11-27 11:27:29,911] Trial 3 finished with value: 0.8025100253134593 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.8025100253134593.\n",
      "[I 2025-11-27 11:27:40,755] Trial 4 finished with value: 0.8289345900311842 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 4 with value: 0.8289345900311842.\n",
      "[I 2025-11-27 11:28:26,735] Trial 5 finished with value: 0.7892834173657075 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 4 with value: 0.8289345900311842.\n",
      "[I 2025-11-27 11:29:02,204] Trial 6 finished with value: 0.8456212951533313 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 6 with value: 0.8456212951533313.\n",
      "[I 2025-11-27 11:29:07,010] Trial 7 finished with value: 0.7703103270543545 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 6 with value: 0.8456212951533313.\n",
      "[I 2025-11-27 11:29:09,124] Trial 8 finished with value: 0.7795718569839253 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 6 with value: 0.8456212951533313.\n",
      "[I 2025-11-27 11:29:09,848] Trial 9 finished with value: 0.7972855348128277 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 6 with value: 0.8456212951533313.\n",
      "[I 2025-11-27 11:30:30,327] Trial 10 finished with value: 0.687263531940393 and parameters: {'d': 64, 'd_hidden_factor': 4.898911825744538, 'n_layers': 9, 'hidden_dropout': 0.45987165508765876, 'residual_dropout': 0.1934998040501344, 'learning_rate': 8.436023359535897e-05, 'batch_size': 32, 'epochs': 161}. Best is trial 6 with value: 0.8456212951533313.\n",
      "[I 2025-11-27 11:30:35,252] Trial 11 finished with value: 0.8153582364223754 and parameters: {'d': 256, 'd_hidden_factor': 2.019839569141026, 'n_layers': 4, 'hidden_dropout': 0.3761275059380934, 'residual_dropout': 0.4961689423400903, 'learning_rate': 0.0009031472349418137, 'batch_size': 128, 'epochs': 131}. Best is trial 6 with value: 0.8456212951533313.\n",
      "[I 2025-11-27 11:30:51,945] Trial 12 finished with value: 0.8022826263140242 and parameters: {'d': 64, 'd_hidden_factor': 2.1444073493643163, 'n_layers': 8, 'hidden_dropout': 0.39666925881190335, 'residual_dropout': 0.24448556576035885, 'learning_rate': 0.0009332839245769886, 'batch_size': 64, 'epochs': 150}. Best is trial 6 with value: 0.8456212951533313.\n",
      "[I 2025-11-27 11:31:25,471] Trial 13 finished with value: 0.8168348227041445 and parameters: {'d': 512, 'd_hidden_factor': 4.403565243743425, 'n_layers': 3, 'hidden_dropout': 0.13735723400868138, 'residual_dropout': 0.39413953355958786, 'learning_rate': 0.00010038584476789021, 'batch_size': 32, 'epochs': 112}. Best is trial 6 with value: 0.8456212951533313.\n",
      "[I 2025-11-27 11:31:45,405] Trial 14 finished with value: 0.6828213498125506 and parameters: {'d': 256, 'd_hidden_factor': 2.2658712619164882, 'n_layers': 8, 'hidden_dropout': 0.3784098617133148, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 0.0004773948829215246, 'batch_size': 32, 'epochs': 151}. Best is trial 6 with value: 0.8456212951533313.\n",
      "[I 2025-11-27 11:31:58,655] Trial 15 finished with value: 0.31675112133504524 and parameters: {'d': 64, 'd_hidden_factor': 3.7911575129310653, 'n_layers': 1, 'hidden_dropout': 0.4183655448533285, 'residual_dropout': 0.2812321272168263, 'learning_rate': 1.201880159180346e-05, 'batch_size': 64, 'epochs': 178}. Best is trial 6 with value: 0.8456212951533313.\n",
      "[I 2025-11-27 11:32:00,285] Trial 16 finished with value: 0.8421688253932688 and parameters: {'d': 256, 'd_hidden_factor': 2.4539209232214865, 'n_layers': 7, 'hidden_dropout': 0.3300451156758476, 'residual_dropout': 0.37496612117779893, 'learning_rate': 0.0021783318760847134, 'batch_size': 256, 'epochs': 110}. Best is trial 6 with value: 0.8456212951533313.\n",
      "[I 2025-11-27 11:32:04,530] Trial 17 finished with value: 0.7141249278864242 and parameters: {'d': 64, 'd_hidden_factor': 1.677403476787704, 'n_layers': 8, 'hidden_dropout': 0.21392208437273827, 'residual_dropout': 0.3982913237566343, 'learning_rate': 8.465710502824902e-05, 'batch_size': 256, 'epochs': 58}. Best is trial 6 with value: 0.8456212951533313.\n",
      "[I 2025-11-27 11:32:06,543] Trial 18 finished with value: 0.8450930811354563 and parameters: {'d': 512, 'd_hidden_factor': 2.5025527782041093, 'n_layers': 4, 'hidden_dropout': 0.34906537462593495, 'residual_dropout': 0.4558020046196922, 'learning_rate': 0.0018640535933673347, 'batch_size': 256, 'epochs': 106}. Best is trial 6 with value: 0.8456212951533313.\n",
      "[I 2025-11-27 11:32:09,717] Trial 19 finished with value: 0.8486556699375916 and parameters: {'d': 512, 'd_hidden_factor': 1.7121943585199537, 'n_layers': 4, 'hidden_dropout': 0.06624576312342867, 'residual_dropout': 0.4689751042264251, 'learning_rate': 0.0005909540058908585, 'batch_size': 256, 'epochs': 72}. Best is trial 19 with value: 0.8486556699375916.\n",
      "[I 2025-11-27 11:32:15,018] Trial 20 finished with value: 0.7997101480631853 and parameters: {'d': 512, 'd_hidden_factor': 1.6395590993312847, 'n_layers': 4, 'hidden_dropout': 0.021097325319195948, 'residual_dropout': 0.46883345362224743, 'learning_rate': 0.00041844972063439877, 'batch_size': 128, 'epochs': 72}. Best is trial 19 with value: 0.8486556699375916.\n",
      "[I 2025-11-27 11:32:18,004] Trial 21 finished with value: 0.8473600885613569 and parameters: {'d': 512, 'd_hidden_factor': 2.5603607222845066, 'n_layers': 3, 'hidden_dropout': 0.07315217129980485, 'residual_dropout': 0.4459788443111897, 'learning_rate': 0.000731932717256626, 'batch_size': 256, 'epochs': 99}. Best is trial 19 with value: 0.8486556699375916.\n",
      "[I 2025-11-27 11:32:22,912] Trial 22 finished with value: 0.8530416001426658 and parameters: {'d': 512, 'd_hidden_factor': 1.8750919086658437, 'n_layers': 3, 'hidden_dropout': 0.0744186097659405, 'residual_dropout': 0.44148815820074955, 'learning_rate': 0.00015884162833086892, 'batch_size': 256, 'epochs': 81}. Best is trial 22 with value: 0.8530416001426658.\n",
      "[I 2025-11-27 11:32:24,740] Trial 23 finished with value: 0.8858393237798653 and parameters: {'d': 512, 'd_hidden_factor': 1.101825874182417, 'n_layers': 3, 'hidden_dropout': 0.06632072424576456, 'residual_dropout': 0.4397253646010145, 'learning_rate': 0.0006862268260582755, 'batch_size': 256, 'epochs': 34}. Best is trial 23 with value: 0.8858393237798653.\n",
      "[I 2025-11-27 11:32:25,592] Trial 24 finished with value: 0.7630645075870219 and parameters: {'d': 512, 'd_hidden_factor': 1.0113878617509044, 'n_layers': 1, 'hidden_dropout': 0.07716679747571731, 'residual_dropout': 0.37317606746212595, 'learning_rate': 0.00030814747534276264, 'batch_size': 256, 'epochs': 31}. Best is trial 23 with value: 0.8858393237798653.\n",
      "[I 2025-11-27 11:32:29,031] Trial 25 finished with value: 0.8937106694592274 and parameters: {'d': 512, 'd_hidden_factor': 1.445023114555651, 'n_layers': 3, 'hidden_dropout': 0.06863452696561956, 'residual_dropout': 0.4171196735446927, 'learning_rate': 0.0001922883998359619, 'batch_size': 256, 'epochs': 59}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:32:31,244] Trial 26 finished with value: 0.8773751756649384 and parameters: {'d': 512, 'd_hidden_factor': 1.3588818562606808, 'n_layers': 2, 'hidden_dropout': 0.1295510011570993, 'residual_dropout': 0.24752711365034197, 'learning_rate': 0.00018979156613901292, 'batch_size': 256, 'epochs': 56}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:32:33,163] Trial 27 finished with value: 0.8686159304007226 and parameters: {'d': 512, 'd_hidden_factor': 1.3325712705220831, 'n_layers': 2, 'hidden_dropout': 0.13071028834656145, 'residual_dropout': 0.24469518499278106, 'learning_rate': 4.495883757557331e-05, 'batch_size': 256, 'epochs': 48}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:32:34,732] Trial 28 finished with value: 0.8170697346258846 and parameters: {'d': 512, 'd_hidden_factor': 1.2827151023168701, 'n_layers': 1, 'hidden_dropout': 0.11639065824859224, 'residual_dropout': 0.19568138557443265, 'learning_rate': 0.0002048602700278542, 'batch_size': 256, 'epochs': 60}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:32:36,733] Trial 29 finished with value: 0.8385422842735168 and parameters: {'d': 512, 'd_hidden_factor': 1.4530579065301805, 'n_layers': 2, 'hidden_dropout': 0.1718418341088766, 'residual_dropout': 0.28227805713496157, 'learning_rate': 5.382626731136662e-05, 'batch_size': 128, 'epochs': 31}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:32:38,897] Trial 30 finished with value: 0.8782103599949002 and parameters: {'d': 512, 'd_hidden_factor': 1.1565350365036793, 'n_layers': 3, 'hidden_dropout': 0.03448691302365884, 'residual_dropout': 0.10814667926287849, 'learning_rate': 0.0002897488534604902, 'batch_size': 256, 'epochs': 48}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:32:40,991] Trial 31 finished with value: 0.893021556608488 and parameters: {'d': 512, 'd_hidden_factor': 1.1543930963338644, 'n_layers': 3, 'hidden_dropout': 0.03644038089873968, 'residual_dropout': 0.11340430266899172, 'learning_rate': 0.00034595887178761047, 'batch_size': 256, 'epochs': 43}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:32:43,310] Trial 32 finished with value: 0.8757772078600885 and parameters: {'d': 512, 'd_hidden_factor': 1.014067432146629, 'n_layers': 5, 'hidden_dropout': 0.03587639838684013, 'residual_dropout': 0.10465543423982368, 'learning_rate': 0.00036347894110829517, 'batch_size': 256, 'epochs': 40}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:32:45,393] Trial 33 finished with value: 0.8826250343268519 and parameters: {'d': 512, 'd_hidden_factor': 1.2209913052015038, 'n_layers': 3, 'hidden_dropout': 0.04535089710109934, 'residual_dropout': 0.05442200236795454, 'learning_rate': 0.00024410664275587366, 'batch_size': 256, 'epochs': 45}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:32:47,398] Trial 34 finished with value: 0.8929088219298726 and parameters: {'d': 512, 'd_hidden_factor': 1.6032515221902437, 'n_layers': 3, 'hidden_dropout': 0.09420969091736833, 'residual_dropout': 0.01425882648309254, 'learning_rate': 0.0011636607177873464, 'batch_size': 256, 'epochs': 37}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:32:49,213] Trial 35 finished with value: 0.7719372030648703 and parameters: {'d': 128, 'd_hidden_factor': 1.8720110016993494, 'n_layers': 5, 'hidden_dropout': 0.100973518771191, 'residual_dropout': 0.014417172052317854, 'learning_rate': 0.0016136734038829786, 'batch_size': 256, 'epochs': 34}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:32:51,149] Trial 36 finished with value: 0.8595577326850833 and parameters: {'d': 512, 'd_hidden_factor': 1.5768363337555946, 'n_layers': 3, 'hidden_dropout': 0.1981415926264816, 'residual_dropout': 0.03663757703528768, 'learning_rate': 0.001224834529252326, 'batch_size': 256, 'epochs': 63}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:32:55,956] Trial 37 finished with value: 0.7991369586328779 and parameters: {'d': 512, 'd_hidden_factor': 1.9178625332291264, 'n_layers': 4, 'hidden_dropout': 0.0026110143735128544, 'residual_dropout': 0.16902141634424273, 'learning_rate': 0.0005122165113395537, 'batch_size': 128, 'epochs': 42}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:32:58,564] Trial 38 finished with value: 0.7041168416544683 and parameters: {'d': 128, 'd_hidden_factor': 2.8732011305500675, 'n_layers': 5, 'hidden_dropout': 0.09981312029860415, 'residual_dropout': 0.12000645630325972, 'learning_rate': 0.0011363728982725055, 'batch_size': 256, 'epochs': 79}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:33:00,066] Trial 39 finished with value: 0.8905725857613274 and parameters: {'d': 512, 'd_hidden_factor': 3.1496097878319476, 'n_layers': 2, 'hidden_dropout': 0.2390330547686615, 'residual_dropout': 0.07255828029100654, 'learning_rate': 0.0027945152605073653, 'batch_size': 256, 'epochs': 53}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:33:03,871] Trial 40 finished with value: 0.7874394928698705 and parameters: {'d': 512, 'd_hidden_factor': 3.15001465551025, 'n_layers': 1, 'hidden_dropout': 0.24123464118196947, 'residual_dropout': 0.04846578444250234, 'learning_rate': 0.0028565535777785754, 'batch_size': 64, 'epochs': 54}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:33:05,396] Trial 41 finished with value: 0.8898477002465839 and parameters: {'d': 512, 'd_hidden_factor': 3.282124183330216, 'n_layers': 2, 'hidden_dropout': 0.053776776606079414, 'residual_dropout': 0.02870932732954328, 'learning_rate': 0.005077026071983291, 'batch_size': 256, 'epochs': 38}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:33:07,139] Trial 42 finished with value: 0.85302598593375 and parameters: {'d': 512, 'd_hidden_factor': 3.4725351067993393, 'n_layers': 2, 'hidden_dropout': 0.16009175057457314, 'residual_dropout': 0.07723309527910138, 'learning_rate': 0.005363611611031477, 'batch_size': 256, 'epochs': 66}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:33:09,055] Trial 43 finished with value: 0.8449722629054934 and parameters: {'d': 512, 'd_hidden_factor': 3.4929209235590424, 'n_layers': 2, 'hidden_dropout': 0.10269773473727029, 'residual_dropout': 0.07686744672466203, 'learning_rate': 0.005713367344616912, 'batch_size': 256, 'epochs': 40}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:33:11,191] Trial 44 finished with value: 0.7637822085117636 and parameters: {'d': 512, 'd_hidden_factor': 3.038797985128814, 'n_layers': 2, 'hidden_dropout': 0.04905216340115376, 'residual_dropout': 0.023018079528941686, 'learning_rate': 0.009379416063476382, 'batch_size': 256, 'epochs': 52}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:33:12,116] Trial 45 finished with value: 0.6963961547206473 and parameters: {'d': 128, 'd_hidden_factor': 4.122989520088826, 'n_layers': 1, 'hidden_dropout': 0.019989041183289202, 'residual_dropout': 0.1415293349321483, 'learning_rate': 0.0033712703268175665, 'batch_size': 256, 'epochs': 88}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:33:22,085] Trial 46 finished with value: 0.5363760065536871 and parameters: {'d': 512, 'd_hidden_factor': 2.820221863547094, 'n_layers': 2, 'hidden_dropout': 0.17829632728706907, 'residual_dropout': 0.05670222240305356, 'learning_rate': 0.0021628854686969014, 'batch_size': 32, 'epochs': 71}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:33:24,466] Trial 47 finished with value: 0.666917280786269 and parameters: {'d': 512, 'd_hidden_factor': 3.289400736570128, 'n_layers': 4, 'hidden_dropout': 0.2656369302974893, 'residual_dropout': 0.09338727229282831, 'learning_rate': 0.0038478976209579425, 'batch_size': 256, 'epochs': 38}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:33:40,604] Trial 48 finished with value: 0.70636395232251 and parameters: {'d': 256, 'd_hidden_factor': 3.184869000449613, 'n_layers': 10, 'hidden_dropout': 0.49799206724062267, 'residual_dropout': 0.0008719532891241274, 'learning_rate': 0.007030935215478902, 'batch_size': 64, 'epochs': 47}. Best is trial 25 with value: 0.8937106694592274.\n",
      "[I 2025-11-27 11:33:45,220] Trial 49 finished with value: 0.8095171027582992 and parameters: {'d': 64, 'd_hidden_factor': 2.6996559999565526, 'n_layers': 3, 'hidden_dropout': 0.23536409382915208, 'residual_dropout': 0.12757754132444732, 'learning_rate': 0.00014161097842332296, 'batch_size': 128, 'epochs': 64}. Best is trial 25 with value: 0.8937106694592274.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 467.07s\n",
      "  Best CV G-Mean: 0.8937\n",
      "  Best parameters:\n",
      "    d: 512\n",
      "    d_hidden_factor: 1.445023114555651\n",
      "    n_layers: 3\n",
      "    hidden_dropout: 0.06863452696561956\n",
      "    residual_dropout: 0.4171196735446927\n",
      "    learning_rate: 0.0001922883998359619\n",
      "    batch_size: 256\n",
      "    epochs: 59\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/59: Train Loss = 0.3087, Val Loss = 0.3669\n",
      "    Epoch 20/59: Train Loss = 0.1437, Val Loss = 0.2657\n",
      "    Epoch 30/59: Train Loss = 0.0722, Val Loss = 0.1589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 11:33:45,589] A new study created in memory with name: no-name-1f7765fd-7597-4eef-8b32-4700b49ff84e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 40/59: Train Loss = 0.0447, Val Loss = 0.1088\n",
      "    Epoch 50/59: Train Loss = 0.0314, Val Loss = 0.0858\n",
      "✓ Training complete! Time: 0.35s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR climate-model-simulation-crashes\n",
      "================================================================================\n",
      "Accuracy:        0.8951\n",
      "AUC OVO:         0.9102\n",
      "G-Mean:          0.8434\n",
      "Cross-Entropy:   0.3137\n",
      "================================================================================\n",
      "✓ Saved results for climate-model-simulation-crashes\n",
      "\n",
      "✓ Completed climate-model-simulation-crashes (21/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 22/30: analcatdata_dmft\n",
      "################################################################################\n",
      "Loading processed dataset from cache: analcatdata_dmft\n",
      "Using device: cuda\n",
      "Dataset: analcatdata_dmft\n",
      "  Train: (462, 7), Test: (199, 7)\n",
      "  Features: 7, Classes: 5\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: analcatdata_dmft\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 11:33:50,348] Trial 0 finished with value: 0.15769268867733985 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:33:55,944] Trial 1 finished with value: 0.12462427641552247 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:34:01,304] Trial 2 finished with value: 0.09401563314565238 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:34:25,947] Trial 3 finished with value: 0.10608193707317708 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:34:34,323] Trial 4 finished with value: 0.08660334366571171 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:34:57,642] Trial 5 finished with value: 0.10898099719206271 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:20,218] Trial 6 finished with value: 0.09999033450442336 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:24,249] Trial 7 finished with value: 0.13753035827527404 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:25,703] Trial 8 finished with value: 0.04908464766342871 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:26,808] Trial 9 finished with value: 0.13801747082023968 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:31,967] Trial 10 finished with value: 0.13538458109535217 and parameters: {'d': 64, 'd_hidden_factor': 4.982751445203364, 'n_layers': 9, 'hidden_dropout': 0.4730853252665121, 'residual_dropout': 0.20864544555392683, 'learning_rate': 0.0006039122933759166, 'batch_size': 128, 'epochs': 161}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:32,849] Trial 11 finished with value: 0.06530463805179873 and parameters: {'d': 256, 'd_hidden_factor': 4.203203101790258, 'n_layers': 2, 'hidden_dropout': 0.4816139361200471, 'residual_dropout': 0.3735745363958049, 'learning_rate': 0.0005433672809100612, 'batch_size': 256, 'epochs': 131}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:34,302] Trial 12 finished with value: 0.0 and parameters: {'d': 64, 'd_hidden_factor': 4.273265051962233, 'n_layers': 1, 'hidden_dropout': 0.4065623125080101, 'residual_dropout': 0.4161581708130512, 'learning_rate': 8.012285241153539e-05, 'batch_size': 128, 'epochs': 31}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:37,801] Trial 13 finished with value: 0.067862593435166 and parameters: {'d': 512, 'd_hidden_factor': 3.989551883143492, 'n_layers': 4, 'hidden_dropout': 0.1282492931447887, 'residual_dropout': 0.2718684815012768, 'learning_rate': 0.0011496835365855387, 'batch_size': 256, 'epochs': 150}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:44,360] Trial 14 finished with value: 0.12202285200829524 and parameters: {'d': 256, 'd_hidden_factor': 4.713297582512494, 'n_layers': 8, 'hidden_dropout': 0.40778884935507287, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 0.008615101704363677, 'batch_size': 128, 'epochs': 178}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:47,017] Trial 15 finished with value: 0.08796429113264395 and parameters: {'d': 64, 'd_hidden_factor': 3.542832421349154, 'n_layers': 3, 'hidden_dropout': 0.08247982261357112, 'residual_dropout': 0.4169939928530237, 'learning_rate': 0.000294731122795604, 'batch_size': 128, 'epochs': 114}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:47,769] Trial 16 finished with value: 0.0 and parameters: {'d': 256, 'd_hidden_factor': 2.43977699174793, 'n_layers': 1, 'hidden_dropout': 0.40478571195356405, 'residual_dropout': 0.23760248619629204, 'learning_rate': 1.001781929603626e-05, 'batch_size': 256, 'epochs': 59}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:49,672] Trial 17 finished with value: 0.04419083490181383 and parameters: {'d': 64, 'd_hidden_factor': 4.426874031416949, 'n_layers': 8, 'hidden_dropout': 0.20775013439864004, 'residual_dropout': 0.37689676549846945, 'learning_rate': 0.001135532537894405, 'batch_size': 256, 'epochs': 32}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:55,939] Trial 18 finished with value: 0.08296053540023506 and parameters: {'d': 512, 'd_hidden_factor': 3.7948293395342327, 'n_layers': 4, 'hidden_dropout': 0.49381875884984056, 'residual_dropout': 0.4480268323281261, 'learning_rate': 7.991185089019366e-05, 'batch_size': 128, 'epochs': 117}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:35:57,047] Trial 19 finished with value: 0.11670826546143784 and parameters: {'d': 256, 'd_hidden_factor': 1.9247082136744789, 'n_layers': 3, 'hidden_dropout': 0.3613334514949725, 'residual_dropout': 0.16885219213971683, 'learning_rate': 0.0003892007987137343, 'batch_size': 256, 'epochs': 146}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:36:00,348] Trial 20 finished with value: 0.09479796843771507 and parameters: {'d': 64, 'd_hidden_factor': 3.417654942627662, 'n_layers': 7, 'hidden_dropout': 0.4396260303879493, 'residual_dropout': 0.2854948959224487, 'learning_rate': 0.001837478397831817, 'batch_size': 128, 'epochs': 72}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:36:04,073] Trial 21 finished with value: 0.11731164487850947 and parameters: {'d': 512, 'd_hidden_factor': 1.1309697554135671, 'n_layers': 2, 'hidden_dropout': 0.14718886159734326, 'residual_dropout': 0.35138653571637163, 'learning_rate': 0.008851973608213706, 'batch_size': 64, 'epochs': 95}. Best is trial 0 with value: 0.15769268867733985.\n",
      "[I 2025-11-27 11:36:07,800] Trial 22 finished with value: 0.17408208553264698 and parameters: {'d': 512, 'd_hidden_factor': 1.5323902987820166, 'n_layers': 2, 'hidden_dropout': 0.19105875212159706, 'residual_dropout': 0.3215206698912427, 'learning_rate': 0.00396282212739446, 'batch_size': 64, 'epochs': 57}. Best is trial 22 with value: 0.17408208553264698.\n",
      "[I 2025-11-27 11:36:12,662] Trial 23 finished with value: 0.14956639057217483 and parameters: {'d': 512, 'd_hidden_factor': 1.6403960994118048, 'n_layers': 3, 'hidden_dropout': 0.21387064336018313, 'residual_dropout': 0.3865328322266878, 'learning_rate': 0.0028709034578655573, 'batch_size': 64, 'epochs': 48}. Best is trial 22 with value: 0.17408208553264698.\n",
      "[I 2025-11-27 11:36:17,717] Trial 24 finished with value: 0.13189927879339874 and parameters: {'d': 512, 'd_hidden_factor': 1.7476037757364216, 'n_layers': 3, 'hidden_dropout': 0.2212833355000224, 'residual_dropout': 0.2299252259221244, 'learning_rate': 0.0036096827302446164, 'batch_size': 64, 'epochs': 46}. Best is trial 22 with value: 0.17408208553264698.\n",
      "[I 2025-11-27 11:36:24,704] Trial 25 finished with value: 0.1057577171651957 and parameters: {'d': 512, 'd_hidden_factor': 1.7530043919111473, 'n_layers': 5, 'hidden_dropout': 0.08448187852014288, 'residual_dropout': 0.38073538335581825, 'learning_rate': 0.0007556559503516784, 'batch_size': 64, 'epochs': 50}. Best is trial 22 with value: 0.17408208553264698.\n",
      "[I 2025-11-27 11:36:30,670] Trial 26 finished with value: 0.11351438998412489 and parameters: {'d': 512, 'd_hidden_factor': 2.2197458650952546, 'n_layers': 3, 'hidden_dropout': 0.17538300326715872, 'residual_dropout': 0.3090403401879681, 'learning_rate': 0.0021213452056736133, 'batch_size': 64, 'epochs': 62}. Best is trial 22 with value: 0.17408208553264698.\n",
      "[I 2025-11-27 11:36:35,856] Trial 27 finished with value: 0.19520258883760583 and parameters: {'d': 512, 'd_hidden_factor': 1.4497135806113484, 'n_layers': 4, 'hidden_dropout': 0.1063100195064367, 'residual_dropout': 0.276134088348072, 'learning_rate': 0.0002268858964148915, 'batch_size': 64, 'epochs': 43}. Best is trial 27 with value: 0.19520258883760583.\n",
      "[I 2025-11-27 11:36:41,854] Trial 28 finished with value: 0.15236877459704437 and parameters: {'d': 512, 'd_hidden_factor': 1.4216534620170906, 'n_layers': 5, 'hidden_dropout': 0.09592506400985255, 'residual_dropout': 0.1691583439305592, 'learning_rate': 0.00020656447796710753, 'batch_size': 64, 'epochs': 42}. Best is trial 27 with value: 0.19520258883760583.\n",
      "[I 2025-11-27 11:36:48,418] Trial 29 finished with value: 0.18594951881919583 and parameters: {'d': 512, 'd_hidden_factor': 3.0509204565718555, 'n_layers': 4, 'hidden_dropout': 0.030253967155624062, 'residual_dropout': 0.26091902335765804, 'learning_rate': 0.0001853496805446354, 'batch_size': 64, 'epochs': 74}. Best is trial 27 with value: 0.19520258883760583.\n",
      "[I 2025-11-27 11:36:54,449] Trial 30 finished with value: 0.13672806994477246 and parameters: {'d': 512, 'd_hidden_factor': 2.5750808160144083, 'n_layers': 4, 'hidden_dropout': 0.013581541362315847, 'residual_dropout': 0.20899909803806238, 'learning_rate': 0.00013251175690523863, 'batch_size': 64, 'epochs': 77}. Best is trial 27 with value: 0.19520258883760583.\n",
      "[I 2025-11-27 11:37:02,640] Trial 31 finished with value: 0.19972112279751592 and parameters: {'d': 512, 'd_hidden_factor': 3.0889111449605084, 'n_layers': 5, 'hidden_dropout': 0.031557588911752636, 'residual_dropout': 0.26056222359775966, 'learning_rate': 0.00032417156728348445, 'batch_size': 64, 'epochs': 64}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:37:09,276] Trial 32 finished with value: 0.11676186870063703 and parameters: {'d': 512, 'd_hidden_factor': 3.107698432880259, 'n_layers': 4, 'hidden_dropout': 0.04018421650905876, 'residual_dropout': 0.2582804628614498, 'learning_rate': 5.6564950209342703e-05, 'batch_size': 64, 'epochs': 63}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:37:19,710] Trial 33 finished with value: 0.1349484329321367 and parameters: {'d': 512, 'd_hidden_factor': 2.864040485973511, 'n_layers': 7, 'hidden_dropout': 0.046424172428813595, 'residual_dropout': 0.2920119166906208, 'learning_rate': 0.00021982154658841503, 'batch_size': 64, 'epochs': 56}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:37:26,931] Trial 34 finished with value: 0.15129144532725708 and parameters: {'d': 512, 'd_hidden_factor': 2.181052521059451, 'n_layers': 5, 'hidden_dropout': 0.11318134732110456, 'residual_dropout': 0.13282463845981918, 'learning_rate': 0.0004007389482129326, 'batch_size': 64, 'epochs': 82}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:37:33,409] Trial 35 finished with value: 0.10974664551338909 and parameters: {'d': 512, 'd_hidden_factor': 2.6414614587951846, 'n_layers': 4, 'hidden_dropout': 0.05581799246455546, 'residual_dropout': 0.20259004235166694, 'learning_rate': 4.1720180866296455e-05, 'batch_size': 64, 'epochs': 66}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:37:40,469] Trial 36 finished with value: 0.06614332374717583 and parameters: {'d': 128, 'd_hidden_factor': 3.2339465211202496, 'n_layers': 7, 'hidden_dropout': 0.06405781143687378, 'residual_dropout': 0.3188988019160792, 'learning_rate': 0.00014054266437547072, 'batch_size': 64, 'epochs': 37}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:37:45,876] Trial 37 finished with value: 0.19443997547392436 and parameters: {'d': 512, 'd_hidden_factor': 2.990448732588074, 'n_layers': 1, 'hidden_dropout': 0.02658495827968922, 'residual_dropout': 0.2601682947471932, 'learning_rate': 0.0009087816123795112, 'batch_size': 32, 'epochs': 74}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:38:06,184] Trial 38 finished with value: 0.10390861681119279 and parameters: {'d': 512, 'd_hidden_factor': 2.9371273367234036, 'n_layers': 5, 'hidden_dropout': 0.03324618588654183, 'residual_dropout': 0.2533192078064859, 'learning_rate': 0.0009352757563511179, 'batch_size': 32, 'epochs': 109}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:38:16,203] Trial 39 finished with value: 0.17974996943348465 and parameters: {'d': 128, 'd_hidden_factor': 3.548870190517208, 'n_layers': 6, 'hidden_dropout': 0.023143964587891697, 'residual_dropout': 0.13642050993290933, 'learning_rate': 0.00027892122872303683, 'batch_size': 32, 'epochs': 88}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:38:20,865] Trial 40 finished with value: 0.1059385653415976 and parameters: {'d': 512, 'd_hidden_factor': 2.4748782340443896, 'n_layers': 1, 'hidden_dropout': 0.0046632657637512565, 'residual_dropout': 0.2790187962780076, 'learning_rate': 0.0004535815403398194, 'batch_size': 32, 'epochs': 105}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:38:30,866] Trial 41 finished with value: 0.11930375751403048 and parameters: {'d': 128, 'd_hidden_factor': 3.535998797143421, 'n_layers': 6, 'hidden_dropout': 0.02833714183479489, 'residual_dropout': 0.09654099518409642, 'learning_rate': 0.0002931694869366231, 'batch_size': 32, 'epochs': 86}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:38:41,700] Trial 42 finished with value: 0.10664745817652022 and parameters: {'d': 128, 'd_hidden_factor': 3.1667294885766646, 'n_layers': 6, 'hidden_dropout': 0.07317372909929293, 'residual_dropout': 0.13939125683819917, 'learning_rate': 0.0001622908446717813, 'batch_size': 32, 'epochs': 73}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:38:54,393] Trial 43 finished with value: 0.11014549645288137 and parameters: {'d': 128, 'd_hidden_factor': 2.8874187487753256, 'n_layers': 7, 'hidden_dropout': 0.10279192877651307, 'residual_dropout': 0.1875217934624553, 'learning_rate': 0.0002399682751329312, 'batch_size': 32, 'epochs': 79}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:39:05,896] Trial 44 finished with value: 0.11450307300083888 and parameters: {'d': 128, 'd_hidden_factor': 3.7037821588919204, 'n_layers': 6, 'hidden_dropout': 0.12857355098632167, 'residual_dropout': 0.22696800500771494, 'learning_rate': 9.163900915395847e-05, 'batch_size': 32, 'epochs': 90}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:39:14,202] Trial 45 finished with value: 0.14015605545154744 and parameters: {'d': 128, 'd_hidden_factor': 2.7600048677304208, 'n_layers': 5, 'hidden_dropout': 0.020715756207370248, 'residual_dropout': 0.05524541668320959, 'learning_rate': 0.0006898627202328125, 'batch_size': 32, 'epochs': 72}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:39:51,381] Trial 46 finished with value: 0.16822169965794814 and parameters: {'d': 512, 'd_hidden_factor': 3.3807987374238997, 'n_layers': 10, 'hidden_dropout': 0.05862783236676126, 'residual_dropout': 0.34610002799260864, 'learning_rate': 0.0003281639301873612, 'batch_size': 32, 'epochs': 99}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:40:26,398] Trial 47 finished with value: 0.13703216465491946 and parameters: {'d': 512, 'd_hidden_factor': 4.110590720301218, 'n_layers': 8, 'hidden_dropout': 0.00479683798134585, 'residual_dropout': 0.26327457937428317, 'learning_rate': 0.0004959185749722545, 'batch_size': 32, 'epochs': 53}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:40:38,844] Trial 48 finished with value: 0.0854204264980518 and parameters: {'d': 128, 'd_hidden_factor': 3.072009081605374, 'n_layers': 6, 'hidden_dropout': 0.03800580987697117, 'residual_dropout': 0.2980049673004495, 'learning_rate': 0.00011141590438877149, 'batch_size': 32, 'epochs': 68}. Best is trial 31 with value: 0.19972112279751592.\n",
      "[I 2025-11-27 11:40:46,213] Trial 49 finished with value: 0.2006434487810112 and parameters: {'d': 512, 'd_hidden_factor': 3.5625424706553064, 'n_layers': 4, 'hidden_dropout': 0.11666435986352208, 'residual_dropout': 0.23164147899615622, 'learning_rate': 0.00018288138471389106, 'batch_size': 64, 'epochs': 86}. Best is trial 49 with value: 0.2006434487810112.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 420.63s\n",
      "  Best CV G-Mean: 0.2006\n",
      "  Best parameters:\n",
      "    d: 512\n",
      "    d_hidden_factor: 3.5625424706553064\n",
      "    n_layers: 4\n",
      "    hidden_dropout: 0.11666435986352208\n",
      "    residual_dropout: 0.23164147899615622\n",
      "    learning_rate: 0.00018288138471389106\n",
      "    batch_size: 64\n",
      "    epochs: 86\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/86: Train Loss = 1.4190, Val Loss = 1.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 11:40:46,993] A new study created in memory with name: no-name-6242da9b-6b25-4fb4-9514-5f45fc884bab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Early stopping at epoch 16\n",
      "✓ Training complete! Time: 0.75s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR analcatdata_dmft\n",
      "================================================================================\n",
      "Accuracy:        0.2312\n",
      "AUC OVO:         0.5561\n",
      "G-Mean:          0.2270\n",
      "Cross-Entropy:   1.7538\n",
      "================================================================================\n",
      "✓ Saved results for analcatdata_dmft\n",
      "\n",
      "✓ Completed analcatdata_dmft (22/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 23/30: ilpd\n",
      "################################################################################\n",
      "Loading processed dataset from cache: ilpd\n",
      "Using device: cuda\n",
      "Dataset: ilpd\n",
      "  Train: (408, 11), Test: (175, 11)\n",
      "  Features: 11, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: ilpd\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 11:40:50,676] Trial 0 finished with value: 0.5438684519231419 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.5438684519231419.\n",
      "[I 2025-11-27 11:40:57,823] Trial 1 finished with value: 0.4570219981551048 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 0 with value: 0.5438684519231419.\n",
      "[I 2025-11-27 11:41:05,911] Trial 2 finished with value: 0.4807621203707889 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: 0.5438684519231419.\n",
      "[I 2025-11-27 11:41:56,228] Trial 3 finished with value: 0.5208202105780819 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 0 with value: 0.5438684519231419.\n",
      "[I 2025-11-27 11:42:03,225] Trial 4 finished with value: 0.4243044908820573 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 0 with value: 0.5438684519231419.\n",
      "[I 2025-11-27 11:42:45,502] Trial 5 finished with value: 0.4846809247414212 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 0 with value: 0.5438684519231419.\n",
      "[I 2025-11-27 11:43:15,910] Trial 6 finished with value: 0.4977203084313069 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 0 with value: 0.5438684519231419.\n",
      "[I 2025-11-27 11:43:20,124] Trial 7 finished with value: 0.5411817398508101 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 0 with value: 0.5438684519231419.\n",
      "[I 2025-11-27 11:43:21,555] Trial 8 finished with value: 0.5776450740305442 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 8 with value: 0.5776450740305442.\n",
      "[I 2025-11-27 11:43:22,942] Trial 9 finished with value: 0.5111313834746127 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 8 with value: 0.5776450740305442.\n",
      "[I 2025-11-27 11:43:33,642] Trial 10 finished with value: 0.5770414701209091 and parameters: {'d': 512, 'd_hidden_factor': 4.97088426861444, 'n_layers': 9, 'hidden_dropout': 0.004030571702010294, 'residual_dropout': 0.19485930498507747, 'learning_rate': 0.0006550956088886104, 'batch_size': 256, 'epochs': 196}. Best is trial 8 with value: 0.5776450740305442.\n",
      "[I 2025-11-27 11:43:46,071] Trial 11 finished with value: 0.5089465297588008 and parameters: {'d': 512, 'd_hidden_factor': 4.994248805807082, 'n_layers': 9, 'hidden_dropout': 0.010469431921434912, 'residual_dropout': 0.1906752818537771, 'learning_rate': 0.0009031472349418137, 'batch_size': 256, 'epochs': 198}. Best is trial 8 with value: 0.5776450740305442.\n",
      "[I 2025-11-27 11:43:57,209] Trial 12 finished with value: 0.5828598641632038 and parameters: {'d': 512, 'd_hidden_factor': 4.8961709895626155, 'n_layers': 8, 'hidden_dropout': 0.008038652206972724, 'residual_dropout': 0.004006859886477587, 'learning_rate': 0.0007635432584603426, 'batch_size': 256, 'epochs': 200}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:44:11,753] Trial 13 finished with value: 0.4893273517962382 and parameters: {'d': 512, 'd_hidden_factor': 4.393721142753614, 'n_layers': 8, 'hidden_dropout': 0.11074965551116456, 'residual_dropout': 0.03936207928860028, 'learning_rate': 0.0075743760851161935, 'batch_size': 256, 'epochs': 159}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:44:16,606] Trial 14 finished with value: 0.577016994537004 and parameters: {'d': 128, 'd_hidden_factor': 2.0489934704481887, 'n_layers': 8, 'hidden_dropout': 0.08607796944377914, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 6.669007789675228e-05, 'batch_size': 256, 'epochs': 171}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:44:28,873] Trial 15 finished with value: 0.5019494697441556 and parameters: {'d': 512, 'd_hidden_factor': 4.441163399558476, 'n_layers': 7, 'hidden_dropout': 0.07166648817949585, 'residual_dropout': 0.12383255926597689, 'learning_rate': 0.0021615797171048137, 'batch_size': 128, 'epochs': 165}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:44:30,759] Trial 16 finished with value: 0.49632071509132436 and parameters: {'d': 128, 'd_hidden_factor': 3.5080275297486154, 'n_layers': 4, 'hidden_dropout': 0.15312345549450412, 'residual_dropout': 0.2563297389073373, 'learning_rate': 0.000636532898686829, 'batch_size': 256, 'epochs': 142}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:44:34,319] Trial 17 finished with value: 0.4924767130338125 and parameters: {'d': 64, 'd_hidden_factor': 4.426874031416949, 'n_layers': 7, 'hidden_dropout': 0.0502907543578177, 'residual_dropout': 0.4099737252089405, 'learning_rate': 1.1016598219611525e-05, 'batch_size': 256, 'epochs': 181}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:44:36,272] Trial 18 finished with value: 0.5764205457568508 and parameters: {'d': 128, 'd_hidden_factor': 2.47895619924915, 'n_layers': 10, 'hidden_dropout': 0.4365385960326071, 'residual_dropout': 0.25435551009274787, 'learning_rate': 0.003525883505793857, 'batch_size': 256, 'epochs': 148}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:44:38,976] Trial 19 finished with value: 0.5655117205335364 and parameters: {'d': 512, 'd_hidden_factor': 1.8388473225725999, 'n_layers': 3, 'hidden_dropout': 0.15646996140556554, 'residual_dropout': 0.4921796978160566, 'learning_rate': 0.00039298596305228754, 'batch_size': 128, 'epochs': 185}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:44:41,550] Trial 20 finished with value: 0.5126568640670366 and parameters: {'d': 128, 'd_hidden_factor': 3.3195027074479047, 'n_layers': 8, 'hidden_dropout': 0.20917712536281455, 'residual_dropout': 0.10426691307577787, 'learning_rate': 0.0011369536677875195, 'batch_size': 256, 'epochs': 145}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:44:51,655] Trial 21 finished with value: 0.5548299673983793 and parameters: {'d': 512, 'd_hidden_factor': 4.742627915155533, 'n_layers': 9, 'hidden_dropout': 0.008432250931794933, 'residual_dropout': 0.21329767270212308, 'learning_rate': 0.0005365249274990325, 'batch_size': 256, 'epochs': 199}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:45:03,655] Trial 22 finished with value: 0.5415540259078269 and parameters: {'d': 512, 'd_hidden_factor': 4.898227192466686, 'n_layers': 7, 'hidden_dropout': 0.02581823392969991, 'residual_dropout': 0.16951827171277967, 'learning_rate': 0.0018704013687670243, 'batch_size': 256, 'epochs': 185}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:45:13,100] Trial 23 finished with value: 0.5059783445148306 and parameters: {'d': 512, 'd_hidden_factor': 4.106627243311441, 'n_layers': 9, 'hidden_dropout': 0.10796776799958202, 'residual_dropout': 0.0510628139669928, 'learning_rate': 0.00017240170766028191, 'batch_size': 256, 'epochs': 199}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:45:22,657] Trial 24 finished with value: 0.5737944262578625 and parameters: {'d': 512, 'd_hidden_factor': 4.684847789973596, 'n_layers': 8, 'hidden_dropout': 0.049628365568243044, 'residual_dropout': 0.37958219789911474, 'learning_rate': 0.0009128101857698403, 'batch_size': 256, 'epochs': 176}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:45:36,110] Trial 25 finished with value: 0.5393816577089211 and parameters: {'d': 512, 'd_hidden_factor': 4.1851531091968175, 'n_layers': 7, 'hidden_dropout': 0.04473255067461518, 'residual_dropout': 0.281586303681576, 'learning_rate': 0.004819935969705077, 'batch_size': 256, 'epochs': 189}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:45:42,010] Trial 26 finished with value: 0.5215492621438462 and parameters: {'d': 256, 'd_hidden_factor': 4.675934794677958, 'n_layers': 9, 'hidden_dropout': 0.12141008110488964, 'residual_dropout': 0.21964169275257464, 'learning_rate': 8.822462989648172e-05, 'batch_size': 256, 'epochs': 159}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:45:47,265] Trial 27 finished with value: 0.4471665823030218 and parameters: {'d': 64, 'd_hidden_factor': 3.608313847766137, 'n_layers': 10, 'hidden_dropout': 0.0128681645473985, 'residual_dropout': 0.013002810573465699, 'learning_rate': 0.00045343077043170113, 'batch_size': 128, 'epochs': 166}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:46:16,346] Trial 28 finished with value: 0.38794581346428647 and parameters: {'d': 512, 'd_hidden_factor': 4.2364241237184865, 'n_layers': 5, 'hidden_dropout': 0.06737064720653721, 'residual_dropout': 0.13718941141673768, 'learning_rate': 0.005843606444678368, 'batch_size': 32, 'epochs': 192}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:46:17,522] Trial 29 finished with value: 0.49269991785287165 and parameters: {'d': 64, 'd_hidden_factor': 3.8680321609137103, 'n_layers': 1, 'hidden_dropout': 0.49234790898426983, 'residual_dropout': 0.0865106313854855, 'learning_rate': 0.001962910016772426, 'batch_size': 128, 'epochs': 37}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:46:19,847] Trial 30 finished with value: 0.5640612663316371 and parameters: {'d': 128, 'd_hidden_factor': 4.607640883766086, 'n_layers': 4, 'hidden_dropout': 0.0009765327106295357, 'residual_dropout': 0.4512658223433867, 'learning_rate': 0.0002897488534604902, 'batch_size': 256, 'epochs': 175}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:46:27,035] Trial 31 finished with value: 0.5238447504050094 and parameters: {'d': 128, 'd_hidden_factor': 1.986849047018148, 'n_layers': 8, 'hidden_dropout': 0.06956084911078943, 'residual_dropout': 0.01280306221200754, 'learning_rate': 5.478852915088853e-05, 'batch_size': 256, 'epochs': 172}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:46:32,985] Trial 32 finished with value: 0.5275155106211242 and parameters: {'d': 128, 'd_hidden_factor': 2.5456974778500143, 'n_layers': 8, 'hidden_dropout': 0.10122232122077537, 'residual_dropout': 0.05300417703605537, 'learning_rate': 5.6564950209342703e-05, 'batch_size': 256, 'epochs': 200}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:46:35,818] Trial 33 finished with value: 0.45765757895301806 and parameters: {'d': 128, 'd_hidden_factor': 1.6034825549778833, 'n_layers': 6, 'hidden_dropout': 0.03849214150731235, 'residual_dropout': 0.006598733601860224, 'learning_rate': 0.00022658179449399393, 'batch_size': 256, 'epochs': 186}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:46:45,757] Trial 34 finished with value: 0.42922758885239787 and parameters: {'d': 128, 'd_hidden_factor': 2.9831467121623354, 'n_layers': 9, 'hidden_dropout': 0.07629596113018705, 'residual_dropout': 0.36048635057419154, 'learning_rate': 0.0006798673830674356, 'batch_size': 64, 'epochs': 54}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:46:49,881] Trial 35 finished with value: 0.5729807470305219 and parameters: {'d': 128, 'd_hidden_factor': 3.276095442199144, 'n_layers': 7, 'hidden_dropout': 0.20444943742694688, 'residual_dropout': 0.07859348455009328, 'learning_rate': 0.00013335847252562448, 'batch_size': 256, 'epochs': 154}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:46:59,930] Trial 36 finished with value: 0.42924962815466666 and parameters: {'d': 256, 'd_hidden_factor': 1.0104526113171488, 'n_layers': 10, 'hidden_dropout': 0.376756810514871, 'residual_dropout': 0.29848770087449555, 'learning_rate': 0.0013045736811384554, 'batch_size': 64, 'epochs': 131}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:47:31,049] Trial 37 finished with value: 0.4352781080469266 and parameters: {'d': 128, 'd_hidden_factor': 2.763016377126414, 'n_layers': 6, 'hidden_dropout': 0.0012317053526543515, 'residual_dropout': 0.1587239763925914, 'learning_rate': 2.8257665786832757e-05, 'batch_size': 32, 'epochs': 111}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:47:34,821] Trial 38 finished with value: 0.508669608068006 and parameters: {'d': 512, 'd_hidden_factor': 2.2653823192177045, 'n_layers': 5, 'hidden_dropout': 0.13484695763104082, 'residual_dropout': 0.03955206337997948, 'learning_rate': 0.00032551090932331764, 'batch_size': 256, 'epochs': 171}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:47:57,826] Trial 39 finished with value: 0.42343388071009735 and parameters: {'d': 128, 'd_hidden_factor': 3.855421599893769, 'n_layers': 6, 'hidden_dropout': 0.0864079699909388, 'residual_dropout': 0.1189499696278758, 'learning_rate': 6.343289306201652e-05, 'batch_size': 32, 'epochs': 191}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:48:38,329] Trial 40 finished with value: 0.5541228106079674 and parameters: {'d': 256, 'd_hidden_factor': 1.313235069300796, 'n_layers': 8, 'hidden_dropout': 0.03599939868387678, 'residual_dropout': 0.4676538191100664, 'learning_rate': 1.4804425073747498e-05, 'batch_size': 64, 'epochs': 179}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:48:40,533] Trial 41 finished with value: 0.5457307007286586 and parameters: {'d': 128, 'd_hidden_factor': 2.424116682317014, 'n_layers': 10, 'hidden_dropout': 0.39508352692777804, 'residual_dropout': 0.2556042354006794, 'learning_rate': 0.0033875626716770076, 'batch_size': 256, 'epochs': 150}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:48:43,144] Trial 42 finished with value: 0.5717927349854157 and parameters: {'d': 128, 'd_hidden_factor': 2.0923702373383963, 'n_layers': 9, 'hidden_dropout': 0.45456841551280425, 'residual_dropout': 0.32456788275260395, 'learning_rate': 0.0025100065786392693, 'batch_size': 256, 'epochs': 165}. Best is trial 12 with value: 0.5828598641632038.\n",
      "[I 2025-11-27 11:48:45,324] Trial 43 finished with value: 0.5853853348002827 and parameters: {'d': 128, 'd_hidden_factor': 2.7143130342335984, 'n_layers': 10, 'hidden_dropout': 0.44435819668937837, 'residual_dropout': 0.36486421532738844, 'learning_rate': 0.005059123639270438, 'batch_size': 256, 'epochs': 137}. Best is trial 43 with value: 0.5853853348002827.\n",
      "[I 2025-11-27 11:48:48,262] Trial 44 finished with value: 0.5673301575067446 and parameters: {'d': 128, 'd_hidden_factor': 2.7912610564081253, 'n_layers': 9, 'hidden_dropout': 0.2649906181216591, 'residual_dropout': 0.38127577989348765, 'learning_rate': 0.009379416063476382, 'batch_size': 256, 'epochs': 135}. Best is trial 43 with value: 0.5853853348002827.\n",
      "[I 2025-11-27 11:48:51,310] Trial 45 finished with value: 0.5644795225574344 and parameters: {'d': 64, 'd_hidden_factor': 3.1885587117295504, 'n_layers': 10, 'hidden_dropout': 0.1777199454022762, 'residual_dropout': 0.415212848495427, 'learning_rate': 0.00501678868746666, 'batch_size': 256, 'epochs': 116}. Best is trial 43 with value: 0.5853853348002827.\n",
      "[I 2025-11-27 11:48:58,967] Trial 46 finished with value: 0.6141855445543094 and parameters: {'d': 512, 'd_hidden_factor': 1.795851333002123, 'n_layers': 8, 'hidden_dropout': 0.3510491642133454, 'residual_dropout': 0.2280213953889534, 'learning_rate': 0.002883879979938879, 'batch_size': 256, 'epochs': 193}. Best is trial 46 with value: 0.6141855445543094.\n",
      "[I 2025-11-27 11:49:06,100] Trial 47 finished with value: 0.5876829322722719 and parameters: {'d': 512, 'd_hidden_factor': 1.5527022378373563, 'n_layers': 9, 'hidden_dropout': 0.3208781033821724, 'residual_dropout': 0.2242952588483553, 'learning_rate': 0.0073369831942902, 'batch_size': 256, 'epochs': 74}. Best is trial 46 with value: 0.6141855445543094.\n",
      "[I 2025-11-27 11:49:11,554] Trial 48 finished with value: 0.5722812180570509 and parameters: {'d': 512, 'd_hidden_factor': 1.6394453888164, 'n_layers': 7, 'hidden_dropout': 0.3368246243861766, 'residual_dropout': 0.2343559676514833, 'learning_rate': 0.007219922932971542, 'batch_size': 256, 'epochs': 74}. Best is trial 46 with value: 0.6141855445543094.\n",
      "[I 2025-11-27 11:49:19,767] Trial 49 finished with value: 0.5323033606573303 and parameters: {'d': 512, 'd_hidden_factor': 1.3613667294693443, 'n_layers': 9, 'hidden_dropout': 0.2897792231827742, 'residual_dropout': 0.18947933889126384, 'learning_rate': 0.004311163836057601, 'batch_size': 128, 'epochs': 55}. Best is trial 46 with value: 0.6141855445543094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 512.77s\n",
      "  Best CV G-Mean: 0.6142\n",
      "  Best parameters:\n",
      "    d: 512\n",
      "    d_hidden_factor: 1.795851333002123\n",
      "    n_layers: 8\n",
      "    hidden_dropout: 0.3510491642133454\n",
      "    residual_dropout: 0.2280213953889534\n",
      "    learning_rate: 0.002883879979938879\n",
      "    batch_size: 256\n",
      "    epochs: 193\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/193: Train Loss = 0.5241, Val Loss = 1.3635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 11:49:20,055] A new study created in memory with name: no-name-f1f95078-bdc7-4fb2-8e46-3b354ccb2e93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Early stopping at epoch 16\n",
      "✓ Training complete! Time: 0.27s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR ilpd\n",
      "================================================================================\n",
      "Accuracy:        0.6800\n",
      "AUC OVO:         0.8005\n",
      "G-Mean:          0.7018\n",
      "Cross-Entropy:   0.5278\n",
      "================================================================================\n",
      "✓ Saved results for ilpd\n",
      "\n",
      "✓ Completed ilpd (23/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 24/30: cmc\n",
      "################################################################################\n",
      "Loading processed dataset from cache: cmc\n",
      "Using device: cuda\n",
      "Dataset: cmc\n",
      "  Train: (1031, 9), Test: (442, 9)\n",
      "  Features: 9, Classes: 3\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: cmc\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 11:49:31,768] Trial 0 finished with value: 0.5540176875081935 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.5540176875081935.\n",
      "[I 2025-11-27 11:49:49,184] Trial 1 finished with value: 0.551519852542982 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 0 with value: 0.5540176875081935.\n",
      "[I 2025-11-27 11:50:07,857] Trial 2 finished with value: 0.5402436753447036 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: 0.5540176875081935.\n",
      "[I 2025-11-27 11:51:41,563] Trial 3 finished with value: 0.5367824132099381 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 0 with value: 0.5540176875081935.\n",
      "[I 2025-11-27 11:52:03,549] Trial 4 finished with value: 0.5486479621063434 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 0 with value: 0.5540176875081935.\n",
      "[I 2025-11-27 11:53:24,957] Trial 5 finished with value: 0.5427016724405002 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 0 with value: 0.5540176875081935.\n",
      "[I 2025-11-27 11:54:30,393] Trial 6 finished with value: 0.5410447081782609 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 0 with value: 0.5540176875081935.\n",
      "[I 2025-11-27 11:54:39,406] Trial 7 finished with value: 0.560745611031228 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 7 with value: 0.560745611031228.\n",
      "[I 2025-11-27 11:54:44,402] Trial 8 finished with value: 0.5605900929094393 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 7 with value: 0.560745611031228.\n",
      "[I 2025-11-27 11:54:47,090] Trial 9 finished with value: 0.5533642449823679 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 7 with value: 0.560745611031228.\n",
      "[I 2025-11-27 11:54:52,628] Trial 10 finished with value: 0.525112082773225 and parameters: {'d': 512, 'd_hidden_factor': 4.869886258753025, 'n_layers': 1, 'hidden_dropout': 0.10467358725545478, 'residual_dropout': 0.20327186961400082, 'learning_rate': 0.001484521852630656, 'batch_size': 128, 'epochs': 161}. Best is trial 7 with value: 0.560745611031228.\n",
      "[I 2025-11-27 11:55:03,156] Trial 11 finished with value: 0.5641080690656581 and parameters: {'d': 512, 'd_hidden_factor': 1.393822117101131, 'n_layers': 8, 'hidden_dropout': 0.0070454647817293735, 'residual_dropout': 0.49603173000665035, 'learning_rate': 0.00888036766804695, 'batch_size': 256, 'epochs': 198}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:55:11,992] Trial 12 finished with value: 0.47804446846292825 and parameters: {'d': 512, 'd_hidden_factor': 1.0658503514830249, 'n_layers': 9, 'hidden_dropout': 0.008038652206972724, 'residual_dropout': 0.2588052346456238, 'learning_rate': 0.0016179440919177456, 'batch_size': 256, 'epochs': 198}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:55:25,380] Trial 13 finished with value: 0.5265925348907744 and parameters: {'d': 512, 'd_hidden_factor': 1.7897617711971638, 'n_layers': 8, 'hidden_dropout': 0.1282492931447887, 'residual_dropout': 0.39413953355958786, 'learning_rate': 0.003278104381018684, 'batch_size': 256, 'epochs': 151}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:55:38,853] Trial 14 finished with value: 0.5191530495668581 and parameters: {'d': 512, 'd_hidden_factor': 1.771180029697678, 'n_layers': 3, 'hidden_dropout': 0.10577088952846844, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 0.0098013840231289, 'batch_size': 64, 'epochs': 161}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:55:48,445] Trial 15 finished with value: 0.5004045925540387 and parameters: {'d': 512, 'd_hidden_factor': 1.6509259250621737, 'n_layers': 8, 'hidden_dropout': 0.1671785283298504, 'residual_dropout': 0.23414926391329935, 'learning_rate': 0.0006178590691416533, 'batch_size': 256, 'epochs': 142}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:56:20,505] Trial 16 finished with value: 0.534959524473697 and parameters: {'d': 512, 'd_hidden_factor': 2.2281766868677337, 'n_layers': 8, 'hidden_dropout': 0.06672247854475262, 'residual_dropout': 0.3864469996498301, 'learning_rate': 0.0006960164587986635, 'batch_size': 64, 'epochs': 173}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:56:24,810] Trial 17 finished with value: 0.5152054411613307 and parameters: {'d': 512, 'd_hidden_factor': 1.4037840337818108, 'n_layers': 1, 'hidden_dropout': 0.19615136858073126, 'residual_dropout': 0.14837473819610625, 'learning_rate': 5.941072156885347e-05, 'batch_size': 128, 'epochs': 64}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:56:40,871] Trial 18 finished with value: 0.5337926503328204 and parameters: {'d': 512, 'd_hidden_factor': 2.387817421476856, 'n_layers': 3, 'hidden_dropout': 0.04581635808289565, 'residual_dropout': 0.4528136005496688, 'learning_rate': 0.0006248578598342765, 'batch_size': 64, 'epochs': 105}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:56:57,783] Trial 19 finished with value: 0.39215012898118284 and parameters: {'d': 64, 'd_hidden_factor': 1.3913190147578705, 'n_layers': 7, 'hidden_dropout': 0.4009886606683126, 'residual_dropout': 0.2942856933354856, 'learning_rate': 1.0094165165701898e-05, 'batch_size': 256, 'epochs': 132}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:57:45,363] Trial 20 finished with value: 0.5213857130313838 and parameters: {'d': 512, 'd_hidden_factor': 1.9800352322484882, 'n_layers': 10, 'hidden_dropout': 0.1460078519099227, 'residual_dropout': 0.3248579789120458, 'learning_rate': 0.003922968241286064, 'batch_size': 64, 'epochs': 79}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:57:49,187] Trial 21 finished with value: 0.560258215629431 and parameters: {'d': 128, 'd_hidden_factor': 3.327267904609774, 'n_layers': 4, 'hidden_dropout': 0.00564246948064855, 'residual_dropout': 0.4844951065962404, 'learning_rate': 0.005370529319844121, 'batch_size': 256, 'epochs': 199}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:57:55,070] Trial 22 finished with value: 0.5498814425379968 and parameters: {'d': 128, 'd_hidden_factor': 4.277930675430194, 'n_layers': 7, 'hidden_dropout': 0.058301646223967885, 'residual_dropout': 0.3920483221252671, 'learning_rate': 0.0060080747227556994, 'batch_size': 256, 'epochs': 181}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:58:01,020] Trial 23 finished with value: 0.5367383554747146 and parameters: {'d': 128, 'd_hidden_factor': 2.6186655166533708, 'n_layers': 7, 'hidden_dropout': 0.044721698336653695, 'residual_dropout': 0.4659392097544896, 'learning_rate': 0.0021300698901821906, 'batch_size': 256, 'epochs': 187}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:58:27,420] Trial 24 finished with value: 0.5177353185036869 and parameters: {'d': 512, 'd_hidden_factor': 3.3355874852975886, 'n_layers': 9, 'hidden_dropout': 0.08666441812204588, 'residual_dropout': 0.3695231853365965, 'learning_rate': 0.006731721504791833, 'batch_size': 256, 'epochs': 170}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:58:32,656] Trial 25 finished with value: 0.5534253248975329 and parameters: {'d': 128, 'd_hidden_factor': 1.445023114555651, 'n_layers': 5, 'hidden_dropout': 0.21414415918446733, 'residual_dropout': 0.49835037577775376, 'learning_rate': 0.0009196994723595075, 'batch_size': 256, 'epochs': 109}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:58:39,844] Trial 26 finished with value: 0.5539959984311424 and parameters: {'d': 64, 'd_hidden_factor': 4.898985458984265, 'n_layers': 4, 'hidden_dropout': 0.16672105608351398, 'residual_dropout': 0.43983987107001415, 'learning_rate': 0.002603030811924946, 'batch_size': 128, 'epochs': 187}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:59:00,493] Trial 27 finished with value: 0.5397192279506211 and parameters: {'d': 256, 'd_hidden_factor': 4.365792612056518, 'n_layers': 2, 'hidden_dropout': 0.016688001380539833, 'residual_dropout': 0.2772025146287224, 'learning_rate': 0.004775641111629979, 'batch_size': 32, 'epochs': 148}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:59:20,833] Trial 28 finished with value: 0.5367883942596589 and parameters: {'d': 512, 'd_hidden_factor': 2.5733773943920335, 'n_layers': 9, 'hidden_dropout': 0.12117501097437011, 'residual_dropout': 0.4158466692834832, 'learning_rate': 0.007695211352471625, 'batch_size': 256, 'epochs': 88}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:59:31,651] Trial 29 finished with value: 0.5353968593511953 and parameters: {'d': 64, 'd_hidden_factor': 3.6680391211655365, 'n_layers': 5, 'hidden_dropout': 0.49234790898426983, 'residual_dropout': 0.34230942202369763, 'learning_rate': 0.00034966984894653567, 'batch_size': 128, 'epochs': 37}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 11:59:58,049] Trial 30 finished with value: 0.5531146792588106 and parameters: {'d': 128, 'd_hidden_factor': 1.9851053329393573, 'n_layers': 7, 'hidden_dropout': 0.4365255285115474, 'residual_dropout': 0.3641495880552426, 'learning_rate': 0.0003396010126803056, 'batch_size': 64, 'epochs': 57}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:00:01,540] Trial 31 finished with value: 0.5425003121840042 and parameters: {'d': 128, 'd_hidden_factor': 3.3034948821523478, 'n_layers': 4, 'hidden_dropout': 0.0023747242199536056, 'residual_dropout': 0.4779389651884601, 'learning_rate': 0.005401808396464392, 'batch_size': 256, 'epochs': 197}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:00:04,322] Trial 32 finished with value: 0.5353938518205805 and parameters: {'d': 128, 'd_hidden_factor': 3.15441485809352, 'n_layers': 3, 'hidden_dropout': 0.028566573079911874, 'residual_dropout': 0.46824072890139046, 'learning_rate': 0.002431099224153593, 'batch_size': 256, 'epochs': 197}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:00:06,801] Trial 33 finished with value: 0.5407412085416384 and parameters: {'d': 128, 'd_hidden_factor': 2.864040485973511, 'n_layers': 2, 'hidden_dropout': 0.08195966077789636, 'residual_dropout': 0.42667508802935594, 'learning_rate': 0.0011089678914436595, 'batch_size': 256, 'epochs': 180}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:00:11,471] Trial 34 finished with value: 0.5442617818169999 and parameters: {'d': 128, 'd_hidden_factor': 3.482922845490388, 'n_layers': 5, 'hidden_dropout': 0.00010538830989883455, 'residual_dropout': 0.48087204331154704, 'learning_rate': 0.004532097239165488, 'batch_size': 256, 'epochs': 189}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:00:24,875] Trial 35 finished with value: 0.5538631043672848 and parameters: {'d': 128, 'd_hidden_factor': 3.987193788150548, 'n_layers': 4, 'hidden_dropout': 0.04433057958658092, 'residual_dropout': 0.4176701402092539, 'learning_rate': 0.00986848117377414, 'batch_size': 64, 'epochs': 169}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:00:30,760] Trial 36 finished with value: 0.5411723168685779 and parameters: {'d': 256, 'd_hidden_factor': 3.0786917587635028, 'n_layers': 6, 'hidden_dropout': 0.07720658790888639, 'residual_dropout': 0.4974131464870657, 'learning_rate': 0.0036133662006831825, 'batch_size': 256, 'epochs': 76}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:00:56,127] Trial 37 finished with value: 0.5639724959247918 and parameters: {'d': 128, 'd_hidden_factor': 2.898188655063103, 'n_layers': 3, 'hidden_dropout': 0.24867533477088785, 'residual_dropout': 0.45440144172644004, 'learning_rate': 0.001567023951520014, 'batch_size': 32, 'epochs': 119}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:01:12,160] Trial 38 finished with value: 0.5421083254300735 and parameters: {'d': 512, 'd_hidden_factor': 1.2106518812883171, 'n_layers': 1, 'hidden_dropout': 0.23800155660510894, 'residual_dropout': 0.45158534144918694, 'learning_rate': 0.0016452775446645013, 'batch_size': 32, 'epochs': 118}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:01:31,227] Trial 39 finished with value: 0.5379185079720487 and parameters: {'d': 128, 'd_hidden_factor': 2.8413183685745658, 'n_layers': 2, 'hidden_dropout': 0.35444250996869764, 'residual_dropout': 0.15680738693334226, 'learning_rate': 0.00016166916502344025, 'batch_size': 32, 'epochs': 98}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:02:12,248] Trial 40 finished with value: 0.5371644744109825 and parameters: {'d': 256, 'd_hidden_factor': 1.5463787115907746, 'n_layers': 6, 'hidden_dropout': 0.2714443045117627, 'residual_dropout': 0.40548911805929944, 'learning_rate': 0.0028565535777785754, 'batch_size': 32, 'epochs': 137}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:02:37,535] Trial 41 finished with value: 0.5361410368128103 and parameters: {'d': 128, 'd_hidden_factor': 3.68474109830124, 'n_layers': 3, 'hidden_dropout': 0.23301607391053683, 'residual_dropout': 0.45026104176177667, 'learning_rate': 0.006410686878811158, 'batch_size': 32, 'epochs': 189}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:03:09,912] Trial 42 finished with value: 0.5586822697354787 and parameters: {'d': 128, 'd_hidden_factor': 4.184991137625425, 'n_layers': 4, 'hidden_dropout': 0.3383543776269125, 'residual_dropout': 0.4812066663056582, 'learning_rate': 0.002079509125029989, 'batch_size': 32, 'epochs': 199}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:03:20,288] Trial 43 finished with value: 0.5574198203757522 and parameters: {'d': 128, 'd_hidden_factor': 3.5391504731293972, 'n_layers': 3, 'hidden_dropout': 0.2975922480271585, 'residual_dropout': 0.4366272275966422, 'learning_rate': 0.00459847336939919, 'batch_size': 64, 'epochs': 46}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:03:22,340] Trial 44 finished with value: 0.5367601886738267 and parameters: {'d': 128, 'd_hidden_factor': 3.215719842948048, 'n_layers': 2, 'hidden_dropout': 0.031515821242452786, 'residual_dropout': 0.3744980477514707, 'learning_rate': 0.00111642036878926, 'batch_size': 256, 'epochs': 159}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:03:57,534] Trial 45 finished with value: 0.5482198051841551 and parameters: {'d': 512, 'd_hidden_factor': 1.1791118887698733, 'n_layers': 4, 'hidden_dropout': 0.1910156938752389, 'residual_dropout': 0.46115910705426105, 'learning_rate': 0.003139467982509678, 'batch_size': 32, 'epochs': 89}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:04:07,941] Trial 46 finished with value: 0.5370497816378494 and parameters: {'d': 64, 'd_hidden_factor': 2.392229656234666, 'n_layers': 3, 'hidden_dropout': 0.10295654012930044, 'residual_dropout': 0.2280213953889534, 'learning_rate': 0.007645923268806444, 'batch_size': 64, 'epochs': 180}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:04:19,726] Trial 47 finished with value: 0.524825380211396 and parameters: {'d': 512, 'd_hidden_factor': 1.9632325061695062, 'n_layers': 5, 'hidden_dropout': 0.15473867839284922, 'residual_dropout': 0.3186934240564875, 'learning_rate': 0.0019042358930049079, 'batch_size': 128, 'epochs': 71}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:04:21,271] Trial 48 finished with value: 0.5365320663524085 and parameters: {'d': 128, 'd_hidden_factor': 3.02126111649583, 'n_layers': 1, 'hidden_dropout': 0.06063657090827616, 'residual_dropout': 0.35825196932554915, 'learning_rate': 0.003793592950899028, 'batch_size': 256, 'epochs': 110}. Best is trial 11 with value: 0.5641080690656581.\n",
      "[I 2025-11-27 12:04:44,654] Trial 49 finished with value: 0.5410670582842186 and parameters: {'d': 512, 'd_hidden_factor': 4.5148293452011075, 'n_layers': 6, 'hidden_dropout': 0.0152561826700304, 'residual_dropout': 0.49996190878232943, 'learning_rate': 0.009804707009558706, 'batch_size': 256, 'epochs': 174}. Best is trial 11 with value: 0.5641080690656581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 924.60s\n",
      "  Best CV G-Mean: 0.5641\n",
      "  Best parameters:\n",
      "    d: 512\n",
      "    d_hidden_factor: 1.393822117101131\n",
      "    n_layers: 8\n",
      "    hidden_dropout: 0.0070454647817293735\n",
      "    residual_dropout: 0.49603173000665035\n",
      "    learning_rate: 0.00888036766804695\n",
      "    batch_size: 256\n",
      "    epochs: 198\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/198: Train Loss = 0.8636, Val Loss = 0.9030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 12:04:45,575] A new study created in memory with name: no-name-dde7da60-63cf-47c2-aa5e-08db55617cc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 20/198: Train Loss = 0.8611, Val Loss = 0.9522\n",
      "    Early stopping at epoch 25\n",
      "✓ Training complete! Time: 0.90s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR cmc\n",
      "================================================================================\n",
      "Accuracy:        0.5385\n",
      "AUC OVO:         0.7192\n",
      "G-Mean:          0.5284\n",
      "Cross-Entropy:   0.9841\n",
      "================================================================================\n",
      "✓ Saved results for cmc\n",
      "\n",
      "✓ Completed cmc (24/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 25/30: cylinder-bands\n",
      "################################################################################\n",
      "Loading processed dataset from cache: cylinder-bands\n",
      "Using device: cuda\n",
      "Dataset: cylinder-bands\n",
      "  Train: (378, 119), Test: (162, 119)\n",
      "  Features: 119, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: cylinder-bands\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 12:04:49,193] Trial 0 finished with value: 0.6899513459810391 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.6899513459810391.\n",
      "[I 2025-11-27 12:04:55,238] Trial 1 finished with value: 0.7728282911648879 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.7728282911648879.\n",
      "[I 2025-11-27 12:05:03,325] Trial 2 finished with value: 0.7392800598765724 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 1 with value: 0.7728282911648879.\n",
      "[I 2025-11-27 12:05:53,345] Trial 3 finished with value: 0.7517289319060854 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 1 with value: 0.7728282911648879.\n",
      "[I 2025-11-27 12:06:00,376] Trial 4 finished with value: 0.757099460845948 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 1 with value: 0.7728282911648879.\n",
      "[I 2025-11-27 12:06:36,823] Trial 5 finished with value: 0.7157356852631054 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 1 with value: 0.7728282911648879.\n",
      "[I 2025-11-27 12:07:09,083] Trial 6 finished with value: 0.7436119653435437 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 1 with value: 0.7728282911648879.\n",
      "[I 2025-11-27 12:07:12,862] Trial 7 finished with value: 0.725915305392468 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 1 with value: 0.7728282911648879.\n",
      "[I 2025-11-27 12:07:14,194] Trial 8 finished with value: 0.7464416757129781 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 1 with value: 0.7728282911648879.\n",
      "[I 2025-11-27 12:07:15,135] Trial 9 finished with value: 0.7517255175048085 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 1 with value: 0.7728282911648879.\n",
      "[I 2025-11-27 12:07:28,867] Trial 10 finished with value: 0.7733074094814466 and parameters: {'d': 512, 'd_hidden_factor': 4.964654933814086, 'n_layers': 9, 'hidden_dropout': 0.45066137904209647, 'residual_dropout': 0.22563768345335203, 'learning_rate': 0.0010035610984542277, 'batch_size': 128, 'epochs': 161}. Best is trial 10 with value: 0.7733074094814466.\n",
      "[I 2025-11-27 12:07:40,763] Trial 11 finished with value: 0.7925886987720848 and parameters: {'d': 512, 'd_hidden_factor': 4.993958781648477, 'n_layers': 9, 'hidden_dropout': 0.45487620030030335, 'residual_dropout': 0.1906752818537771, 'learning_rate': 0.0009031472349418137, 'batch_size': 128, 'epochs': 171}. Best is trial 11 with value: 0.7925886987720848.\n",
      "[I 2025-11-27 12:07:52,994] Trial 12 finished with value: 0.7455054620767518 and parameters: {'d': 512, 'd_hidden_factor': 4.951919553040987, 'n_layers': 10, 'hidden_dropout': 0.4987175153536779, 'residual_dropout': 0.188916471547488, 'learning_rate': 0.0008629604188668137, 'batch_size': 128, 'epochs': 177}. Best is trial 11 with value: 0.7925886987720848.\n",
      "[I 2025-11-27 12:08:04,680] Trial 13 finished with value: 0.7863347281117047 and parameters: {'d': 512, 'd_hidden_factor': 4.8817604808111845, 'n_layers': 8, 'hidden_dropout': 0.40897952652222425, 'residual_dropout': 0.2151930443307654, 'learning_rate': 0.0007384168872280235, 'batch_size': 128, 'epochs': 152}. Best is trial 11 with value: 0.7925886987720848.\n",
      "[I 2025-11-27 12:08:20,951] Trial 14 finished with value: 0.7972450296992954 and parameters: {'d': 512, 'd_hidden_factor': 4.348287911600313, 'n_layers': 8, 'hidden_dropout': 0.40027920419014784, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 7.285108457447034e-05, 'batch_size': 128, 'epochs': 152}. Best is trial 14 with value: 0.7972450296992954.\n",
      "[I 2025-11-27 12:08:36,344] Trial 15 finished with value: 0.7945297631349699 and parameters: {'d': 512, 'd_hidden_factor': 4.359615939322498, 'n_layers': 8, 'hidden_dropout': 0.4048920902439122, 'residual_dropout': 0.023829386218252563, 'learning_rate': 6.833803821633542e-05, 'batch_size': 128, 'epochs': 146}. Best is trial 14 with value: 0.7972450296992954.\n",
      "[I 2025-11-27 12:09:09,509] Trial 16 finished with value: 0.7404882291043222 and parameters: {'d': 512, 'd_hidden_factor': 4.330864977227533, 'n_layers': 8, 'hidden_dropout': 0.38094962107450325, 'residual_dropout': 0.035162100805171716, 'learning_rate': 1.0004964666069479e-05, 'batch_size': 128, 'epochs': 141}. Best is trial 14 with value: 0.7972450296992954.\n",
      "[I 2025-11-27 12:09:21,550] Trial 17 finished with value: 0.7888273040725012 and parameters: {'d': 512, 'd_hidden_factor': 4.293297384902982, 'n_layers': 8, 'hidden_dropout': 0.12492113872937427, 'residual_dropout': 0.01758283612045591, 'learning_rate': 6.745419764340012e-05, 'batch_size': 128, 'epochs': 195}. Best is trial 14 with value: 0.7972450296992954.\n",
      "[I 2025-11-27 12:09:36,396] Trial 18 finished with value: 0.7758605588538854 and parameters: {'d': 512, 'd_hidden_factor': 4.315599630022925, 'n_layers': 7, 'hidden_dropout': 0.4226382203250074, 'residual_dropout': 0.11111388020677801, 'learning_rate': 5.197107858716717e-05, 'batch_size': 128, 'epochs': 138}. Best is trial 14 with value: 0.7972450296992954.\n",
      "[I 2025-11-27 12:09:40,371] Trial 19 finished with value: 0.7077227973086674 and parameters: {'d': 64, 'd_hidden_factor': 2.4203523509970757, 'n_layers': 4, 'hidden_dropout': 0.36713489751566775, 'residual_dropout': 0.08003279660316663, 'learning_rate': 0.00011445909263667076, 'batch_size': 256, 'epochs': 110}. Best is trial 14 with value: 0.7972450296992954.\n",
      "[I 2025-11-27 12:09:59,731] Trial 20 finished with value: 0.7579177573701671 and parameters: {'d': 512, 'd_hidden_factor': 3.471078014535214, 'n_layers': 7, 'hidden_dropout': 0.20435013036294924, 'residual_dropout': 0.022534357225195784, 'learning_rate': 1.1465344738688203e-05, 'batch_size': 128, 'epochs': 183}. Best is trial 14 with value: 0.7972450296992954.\n",
      "[I 2025-11-27 12:10:11,014] Trial 21 finished with value: 0.7823675526241923 and parameters: {'d': 512, 'd_hidden_factor': 4.558326327042703, 'n_layers': 9, 'hidden_dropout': 0.4463163893388423, 'residual_dropout': 0.1288594275692115, 'learning_rate': 0.0003381731195839259, 'batch_size': 128, 'epochs': 162}. Best is trial 14 with value: 0.7972450296992954.\n",
      "[I 2025-11-27 12:10:31,355] Trial 22 finished with value: 0.8065122475678248 and parameters: {'d': 512, 'd_hidden_factor': 4.560107548527225, 'n_layers': 9, 'hidden_dropout': 0.4597693182168862, 'residual_dropout': 0.0033274404135525426, 'learning_rate': 4.596810624149129e-05, 'batch_size': 128, 'epochs': 174}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:10:51,967] Trial 23 finished with value: 0.7519521929950701 and parameters: {'d': 512, 'd_hidden_factor': 4.074139708557597, 'n_layers': 10, 'hidden_dropout': 0.3980834658918617, 'residual_dropout': 0.06255810459114024, 'learning_rate': 3.396962503151182e-05, 'batch_size': 128, 'epochs': 143}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:11:08,499] Trial 24 finished with value: 0.7877512819311008 and parameters: {'d': 512, 'd_hidden_factor': 4.534884939875605, 'n_layers': 7, 'hidden_dropout': 0.3630612305644981, 'residual_dropout': 0.0047987751471233, 'learning_rate': 5.00589880250937e-05, 'batch_size': 128, 'epochs': 154}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:11:24,990] Trial 25 finished with value: 0.7928284689249017 and parameters: {'d': 512, 'd_hidden_factor': 4.576114285833383, 'n_layers': 8, 'hidden_dropout': 0.4692059285334769, 'residual_dropout': 0.06524751754119353, 'learning_rate': 9.481661536131907e-05, 'batch_size': 128, 'epochs': 184}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:11:46,253] Trial 26 finished with value: 0.7548398706045057 and parameters: {'d': 512, 'd_hidden_factor': 3.6464991114935597, 'n_layers': 9, 'hidden_dropout': 0.33374943696492254, 'residual_dropout': 0.11659735293655892, 'learning_rate': 2.025651097091268e-05, 'batch_size': 128, 'epochs': 117}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:11:49,382] Trial 27 finished with value: 0.7272464688497468 and parameters: {'d': 64, 'd_hidden_factor': 4.0540527670431015, 'n_layers': 1, 'hidden_dropout': 0.41943134338801874, 'residual_dropout': 0.004413264920120125, 'learning_rate': 0.00016705137854971383, 'batch_size': 256, 'epochs': 165}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:12:07,998] Trial 28 finished with value: 0.7692605156471359 and parameters: {'d': 256, 'd_hidden_factor': 4.6137104028973175, 'n_layers': 7, 'hidden_dropout': 0.42536960354014164, 'residual_dropout': 0.2802185579333718, 'learning_rate': 0.00035187382422154756, 'batch_size': 32, 'epochs': 132}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:12:17,348] Trial 29 finished with value: 0.7346787377835633 and parameters: {'d': 64, 'd_hidden_factor': 3.7147590420565795, 'n_layers': 9, 'hidden_dropout': 0.49682662581257975, 'residual_dropout': 0.047879453888595935, 'learning_rate': 0.0002268700793369689, 'batch_size': 128, 'epochs': 187}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:12:31,460] Trial 30 finished with value: 0.7856108738897183 and parameters: {'d': 512, 'd_hidden_factor': 4.181599244054671, 'n_layers': 8, 'hidden_dropout': 0.04832695252429192, 'residual_dropout': 0.09853336062339504, 'learning_rate': 4.2292561229259796e-05, 'batch_size': 128, 'epochs': 152}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:12:46,476] Trial 31 finished with value: 0.7970676131160382 and parameters: {'d': 512, 'd_hidden_factor': 4.454800115528094, 'n_layers': 8, 'hidden_dropout': 0.46582503306377593, 'residual_dropout': 0.06169343197010944, 'learning_rate': 8.992915133929416e-05, 'batch_size': 128, 'epochs': 175}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:13:04,210] Trial 32 finished with value: 0.7811622159833969 and parameters: {'d': 512, 'd_hidden_factor': 3.9646433123926856, 'n_layers': 10, 'hidden_dropout': 0.470414377724054, 'residual_dropout': 0.0513532454730365, 'learning_rate': 8.161376987045603e-05, 'batch_size': 128, 'epochs': 147}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:13:30,408] Trial 33 finished with value: 0.7459976504818175 and parameters: {'d': 512, 'd_hidden_factor': 4.718429833479952, 'n_layers': 7, 'hidden_dropout': 0.39041043796200137, 'residual_dropout': 0.1522637619006772, 'learning_rate': 1.7565525175472306e-05, 'batch_size': 128, 'epochs': 174}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:13:40,829] Trial 34 finished with value: 0.7830795472732344 and parameters: {'d': 128, 'd_hidden_factor': 4.4158110786949765, 'n_layers': 5, 'hidden_dropout': 0.47117559263380976, 'residual_dropout': 0.0012450069919643576, 'learning_rate': 0.00015875707852181905, 'batch_size': 64, 'epochs': 54}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:13:52,313] Trial 35 finished with value: 0.7805489793510578 and parameters: {'d': 512, 'd_hidden_factor': 3.198709305827998, 'n_layers': 8, 'hidden_dropout': 0.34014549693717044, 'residual_dropout': 0.033171955973005506, 'learning_rate': 6.425787327572066e-05, 'batch_size': 128, 'epochs': 168}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:14:20,553] Trial 36 finished with value: 0.7400594918330036 and parameters: {'d': 256, 'd_hidden_factor': 4.740827876466644, 'n_layers': 9, 'hidden_dropout': 0.44027579492955166, 'residual_dropout': 0.09095449968111285, 'learning_rate': 2.8881216250724694e-05, 'batch_size': 64, 'epochs': 190}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:14:54,833] Trial 37 finished with value: 0.7868365990008506 and parameters: {'d': 128, 'd_hidden_factor': 2.7726966246232987, 'n_layers': 10, 'hidden_dropout': 0.28116106933868973, 'residual_dropout': 0.1609249921671185, 'learning_rate': 0.00012062926208934713, 'batch_size': 32, 'epochs': 159}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:15:00,891] Trial 38 finished with value: 0.789125287292582 and parameters: {'d': 512, 'd_hidden_factor': 3.770049673813523, 'n_layers': 5, 'hidden_dropout': 0.2474044593696838, 'residual_dropout': 0.044489704611635886, 'learning_rate': 0.00041811677906800066, 'batch_size': 128, 'epochs': 132}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:16:07,489] Trial 39 finished with value: 0.7533167407837772 and parameters: {'d': 512, 'd_hidden_factor': 3.393487380267861, 'n_layers': 6, 'hidden_dropout': 0.3914995163558847, 'residual_dropout': 0.3875606768790699, 'learning_rate': 1.5947522283483563e-05, 'batch_size': 32, 'epochs': 178}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:16:17,650] Trial 40 finished with value: 0.5352574696830137 and parameters: {'d': 64, 'd_hidden_factor': 1.6695115986010567, 'n_layers': 7, 'hidden_dropout': 0.477165977566695, 'residual_dropout': 0.13393865689702497, 'learning_rate': 3.635864590322838e-05, 'batch_size': 64, 'epochs': 37}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:16:32,417] Trial 41 finished with value: 0.7858860328857553 and parameters: {'d': 512, 'd_hidden_factor': 4.521491862066893, 'n_layers': 8, 'hidden_dropout': 0.46791857850051916, 'residual_dropout': 0.06601402112565578, 'learning_rate': 9.621375550587082e-05, 'batch_size': 128, 'epochs': 186}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:16:47,646] Trial 42 finished with value: 0.7904287588755563 and parameters: {'d': 512, 'd_hidden_factor': 4.202786891397546, 'n_layers': 8, 'hidden_dropout': 0.4351989544275533, 'residual_dropout': 0.07294099624302802, 'learning_rate': 7.177205055412304e-05, 'batch_size': 128, 'epochs': 197}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:17:02,202] Trial 43 finished with value: 0.7754453573927079 and parameters: {'d': 512, 'd_hidden_factor': 4.746346143055909, 'n_layers': 9, 'hidden_dropout': 0.4965343705420302, 'residual_dropout': 0.03388823427207093, 'learning_rate': 0.00023451700908495567, 'batch_size': 128, 'epochs': 179}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:17:09,969] Trial 44 finished with value: 0.7929540629080778 and parameters: {'d': 256, 'd_hidden_factor': 4.396886835903434, 'n_layers': 8, 'hidden_dropout': 0.45484211370476996, 'residual_dropout': 0.09378039655850448, 'learning_rate': 0.00013304401526282103, 'batch_size': 128, 'epochs': 170}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:17:15,704] Trial 45 finished with value: 0.7752580033224855 and parameters: {'d': 256, 'd_hidden_factor': 3.8273358824469748, 'n_layers': 9, 'hidden_dropout': 0.4042794569030936, 'residual_dropout': 0.09580301924489507, 'learning_rate': 0.0001566969713916379, 'batch_size': 256, 'epochs': 168}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:17:19,788] Trial 46 finished with value: 0.7422237572108146 and parameters: {'d': 256, 'd_hidden_factor': 4.145822464220734, 'n_layers': 7, 'hidden_dropout': 0.37039216467438246, 'residual_dropout': 0.02169203683736232, 'learning_rate': 0.0005423310583097133, 'batch_size': 128, 'epochs': 156}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:17:29,323] Trial 47 finished with value: 0.7672774276410769 and parameters: {'d': 256, 'd_hidden_factor': 4.437937852618274, 'n_layers': 6, 'hidden_dropout': 0.32066556461194895, 'residual_dropout': 0.2734281251894827, 'learning_rate': 5.270235175436946e-05, 'batch_size': 128, 'epochs': 107}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:17:41,423] Trial 48 finished with value: 0.7321123686108453 and parameters: {'d': 256, 'd_hidden_factor': 4.8198385036512015, 'n_layers': 10, 'hidden_dropout': 0.45227119760993467, 'residual_dropout': 0.0007669733897159685, 'learning_rate': 2.7638781799687866e-05, 'batch_size': 128, 'epochs': 73}. Best is trial 22 with value: 0.8065122475678248.\n",
      "[I 2025-11-27 12:17:45,119] Trial 49 finished with value: 0.7524904445268483 and parameters: {'d': 128, 'd_hidden_factor': 3.573775607840928, 'n_layers': 8, 'hidden_dropout': 0.41118306378550534, 'residual_dropout': 0.04779250383034476, 'learning_rate': 0.0022163007656047563, 'batch_size': 128, 'epochs': 173}. Best is trial 22 with value: 0.8065122475678248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 779.54s\n",
      "  Best CV G-Mean: 0.8065\n",
      "  Best parameters:\n",
      "    d: 512\n",
      "    d_hidden_factor: 4.560107548527225\n",
      "    n_layers: 9\n",
      "    hidden_dropout: 0.4597693182168862\n",
      "    residual_dropout: 0.0033274404135525426\n",
      "    learning_rate: 4.596810624149129e-05\n",
      "    batch_size: 128\n",
      "    epochs: 174\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/174: Train Loss = 0.4801, Val Loss = 0.5887\n",
      "    Epoch 20/174: Train Loss = 0.2690, Val Loss = 0.5812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 12:17:46,720] A new study created in memory with name: no-name-7d2c4e91-b576-44da-984b-de2fc85999f6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 30/174: Train Loss = 0.1445, Val Loss = 0.6926\n",
      "    Early stopping at epoch 30\n",
      "✓ Training complete! Time: 1.58s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR cylinder-bands\n",
      "================================================================================\n",
      "Accuracy:        0.7407\n",
      "AUC OVO:         0.8267\n",
      "G-Mean:          0.7495\n",
      "Cross-Entropy:   0.6391\n",
      "================================================================================\n",
      "✓ Saved results for cylinder-bands\n",
      "\n",
      "✓ Completed cylinder-bands (25/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 26/30: eucalyptus\n",
      "################################################################################\n",
      "Loading processed dataset from cache: eucalyptus\n",
      "Using device: cuda\n",
      "Dataset: eucalyptus\n",
      "  Train: (515, 91), Test: (221, 91)\n",
      "  Features: 91, Classes: 5\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: eucalyptus\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 12:17:52,201] Trial 0 finished with value: 0.5580026445839533 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.5580026445839533.\n",
      "[I 2025-11-27 12:18:01,106] Trial 1 finished with value: 0.5982383152600741 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.5982383152600741.\n",
      "[I 2025-11-27 12:18:13,316] Trial 2 finished with value: 0.63080529408474 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 2 with value: 0.63080529408474.\n",
      "[I 2025-11-27 12:19:40,463] Trial 3 finished with value: 0.5752246075811854 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 2 with value: 0.63080529408474.\n",
      "[I 2025-11-27 12:19:51,191] Trial 4 finished with value: 0.6084295740598121 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 2 with value: 0.63080529408474.\n",
      "[I 2025-11-27 12:20:54,394] Trial 5 finished with value: 0.6236070995638671 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 2 with value: 0.63080529408474.\n",
      "[I 2025-11-27 12:21:43,499] Trial 6 finished with value: 0.6313564693054966 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 6 with value: 0.6313564693054966.\n",
      "[I 2025-11-27 12:21:48,050] Trial 7 finished with value: 0.5837527231347861 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 6 with value: 0.6313564693054966.\n",
      "[I 2025-11-27 12:21:50,255] Trial 8 finished with value: 0.5336429294042063 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 6 with value: 0.6313564693054966.\n",
      "[I 2025-11-27 12:21:51,430] Trial 9 finished with value: 0.5893792409266949 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 6 with value: 0.6313564693054966.\n",
      "[I 2025-11-27 12:23:32,188] Trial 10 finished with value: 0.6448257242570025 and parameters: {'d': 64, 'd_hidden_factor': 4.898911825744538, 'n_layers': 9, 'hidden_dropout': 0.45987165508765876, 'residual_dropout': 0.1934998040501344, 'learning_rate': 8.436023359535897e-05, 'batch_size': 32, 'epochs': 161}. Best is trial 10 with value: 0.6448257242570025.\n",
      "[I 2025-11-27 12:25:38,998] Trial 11 finished with value: 0.6433277034049831 and parameters: {'d': 64, 'd_hidden_factor': 4.900233843769276, 'n_layers': 10, 'hidden_dropout': 0.4592439856823443, 'residual_dropout': 0.1906752818537771, 'learning_rate': 6.31141034044364e-05, 'batch_size': 32, 'epochs': 165}. Best is trial 10 with value: 0.6448257242570025.\n",
      "[I 2025-11-27 12:28:14,298] Trial 12 finished with value: 0.6411533166804454 and parameters: {'d': 64, 'd_hidden_factor': 4.9519747962440235, 'n_layers': 10, 'hidden_dropout': 0.49819677218299285, 'residual_dropout': 0.188916471547488, 'learning_rate': 5.375248322425842e-05, 'batch_size': 32, 'epochs': 177}. Best is trial 10 with value: 0.6448257242570025.\n",
      "[I 2025-11-27 12:30:19,488] Trial 13 finished with value: 0.5213756184313162 and parameters: {'d': 64, 'd_hidden_factor': 4.8817604808111845, 'n_layers': 8, 'hidden_dropout': 0.40068056585205547, 'residual_dropout': 0.03936207928860028, 'learning_rate': 1.0303018478476725e-05, 'batch_size': 32, 'epochs': 152}. Best is trial 10 with value: 0.6448257242570025.\n",
      "[I 2025-11-27 12:30:28,431] Trial 14 finished with value: 0.6450576779193329 and parameters: {'d': 64, 'd_hidden_factor': 4.419338336744398, 'n_layers': 8, 'hidden_dropout': 0.4126210899498219, 'residual_dropout': 0.2088941880434914, 'learning_rate': 0.00081716357677053, 'batch_size': 128, 'epochs': 154}. Best is trial 14 with value: 0.6450576779193329.\n",
      "[I 2025-11-27 12:30:44,158] Trial 15 finished with value: 0.5588708071582256 and parameters: {'d': 512, 'd_hidden_factor': 4.362878474657654, 'n_layers': 8, 'hidden_dropout': 0.40766446614142565, 'residual_dropout': 0.25660482069646195, 'learning_rate': 0.0006084762365211715, 'batch_size': 128, 'epochs': 143}. Best is trial 14 with value: 0.6450576779193329.\n",
      "[I 2025-11-27 12:30:53,604] Trial 16 finished with value: 0.6459043335774141 and parameters: {'d': 64, 'd_hidden_factor': 4.297236074427075, 'n_layers': 8, 'hidden_dropout': 0.40531505510922355, 'residual_dropout': 0.11699048409978212, 'learning_rate': 0.000849473804254325, 'batch_size': 128, 'epochs': 189}. Best is trial 16 with value: 0.6459043335774141.\n",
      "[I 2025-11-27 12:31:02,907] Trial 17 finished with value: 0.648396407933204 and parameters: {'d': 64, 'd_hidden_factor': 4.284910021917601, 'n_layers': 8, 'hidden_dropout': 0.39546429855759824, 'residual_dropout': 0.08716207205949834, 'learning_rate': 0.0007347470464487651, 'batch_size': 128, 'epochs': 199}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:31:07,899] Trial 18 finished with value: 0.5992723215988737 and parameters: {'d': 64, 'd_hidden_factor': 4.399773744831056, 'n_layers': 7, 'hidden_dropout': 0.19136925073820754, 'residual_dropout': 0.10304489197752292, 'learning_rate': 0.0012946166415800668, 'batch_size': 128, 'epochs': 197}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:31:16,708] Trial 19 finished with value: 0.6327966014982803 and parameters: {'d': 512, 'd_hidden_factor': 2.4203523509970757, 'n_layers': 9, 'hidden_dropout': 0.1229345622888072, 'residual_dropout': 0.023594759597001552, 'learning_rate': 0.00048070258396239906, 'batch_size': 128, 'epochs': 179}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:31:20,782] Trial 20 finished with value: 0.6250584843941999 and parameters: {'d': 64, 'd_hidden_factor': 4.1988999883305045, 'n_layers': 4, 'hidden_dropout': 0.3728978084374289, 'residual_dropout': 0.11045470718441273, 'learning_rate': 0.0014030765810116687, 'batch_size': 128, 'epochs': 184}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:31:30,136] Trial 21 finished with value: 0.6437360733693697 and parameters: {'d': 64, 'd_hidden_factor': 3.5377818717500986, 'n_layers': 8, 'hidden_dropout': 0.42352560641315234, 'residual_dropout': 0.1414179404156399, 'learning_rate': 0.00077697473073223, 'batch_size': 128, 'epochs': 140}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:31:43,862] Trial 22 finished with value: 0.6339355513333496 and parameters: {'d': 64, 'd_hidden_factor': 4.4645924242235, 'n_layers': 7, 'hidden_dropout': 0.3555521418911559, 'residual_dropout': 0.25912688191427236, 'learning_rate': 0.00034944299478443874, 'batch_size': 128, 'epochs': 199}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:31:53,301] Trial 23 finished with value: 0.6378488185417954 and parameters: {'d': 64, 'd_hidden_factor': 4.1111995758122815, 'n_layers': 9, 'hidden_dropout': 0.43748516361565815, 'residual_dropout': 0.06161599184872156, 'learning_rate': 0.0009742222477178916, 'batch_size': 128, 'epochs': 170}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:31:59,074] Trial 24 finished with value: 0.6117614093273395 and parameters: {'d': 64, 'd_hidden_factor': 4.534884939875605, 'n_layers': 7, 'hidden_dropout': 0.3695245495683774, 'residual_dropout': 0.14516323349196195, 'learning_rate': 0.0022884750921105704, 'batch_size': 128, 'epochs': 184}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:32:16,112] Trial 25 finished with value: 0.6138044016954163 and parameters: {'d': 64, 'd_hidden_factor': 3.723594277618163, 'n_layers': 8, 'hidden_dropout': 0.3369305906630831, 'residual_dropout': 0.013353091806528467, 'learning_rate': 0.00020132435876468364, 'batch_size': 128, 'epochs': 153}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:32:25,620] Trial 26 finished with value: 0.5898615597057983 and parameters: {'d': 64, 'd_hidden_factor': 4.623186773849521, 'n_layers': 9, 'hidden_dropout': 0.39589151252152094, 'residual_dropout': 0.23297846912449743, 'learning_rate': 0.00047548328391278116, 'batch_size': 256, 'epochs': 191}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:32:38,242] Trial 27 finished with value: 0.6234309749427335 and parameters: {'d': 512, 'd_hidden_factor': 3.3740188401874343, 'n_layers': 7, 'hidden_dropout': 0.4536561376460103, 'residual_dropout': 0.07925484533567573, 'learning_rate': 0.0021404614436731414, 'batch_size': 128, 'epochs': 167}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:32:44,290] Trial 28 finished with value: 0.625696776440275 and parameters: {'d': 256, 'd_hidden_factor': 4.048767900761327, 'n_layers': 8, 'hidden_dropout': 0.3876674884370568, 'residual_dropout': 0.11698004961978858, 'learning_rate': 0.0007357370114757248, 'batch_size': 128, 'epochs': 136}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:32:50,677] Trial 29 finished with value: 0.5844733262954033 and parameters: {'d': 64, 'd_hidden_factor': 4.014730441786302, 'n_layers': 1, 'hidden_dropout': 0.48634011200935917, 'residual_dropout': 0.2304813782369819, 'learning_rate': 0.0002145518613771317, 'batch_size': 128, 'epochs': 111}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:32:59,649] Trial 30 finished with value: 0.6209430611092883 and parameters: {'d': 64, 'd_hidden_factor': 4.612804194247109, 'n_layers': 5, 'hidden_dropout': 0.22005157832395558, 'residual_dropout': 0.17199466950399694, 'learning_rate': 0.0003396010126803056, 'batch_size': 128, 'epochs': 153}. Best is trial 17 with value: 0.648396407933204.\n",
      "[I 2025-11-27 12:34:23,794] Trial 31 finished with value: 0.6764676094421634 and parameters: {'d': 64, 'd_hidden_factor': 4.721827878307432, 'n_layers': 9, 'hidden_dropout': 0.46751066172174116, 'residual_dropout': 0.20297535460076244, 'learning_rate': 0.00010919182475514198, 'batch_size': 32, 'epochs': 161}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:35:01,878] Trial 32 finished with value: 0.649275715168313 and parameters: {'d': 64, 'd_hidden_factor': 4.271303213440863, 'n_layers': 9, 'hidden_dropout': 0.4785673306205521, 'residual_dropout': 0.21219195649443853, 'learning_rate': 0.00011791789778570151, 'batch_size': 128, 'epochs': 188}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:35:18,714] Trial 33 finished with value: 0.6287949351759888 and parameters: {'d': 64, 'd_hidden_factor': 3.7743618283699547, 'n_layers': 9, 'hidden_dropout': 0.48484490648220796, 'residual_dropout': 0.12832476632280826, 'learning_rate': 0.0001318015909075569, 'batch_size': 256, 'epochs': 189}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:36:27,546] Trial 34 finished with value: 0.648459260457704 and parameters: {'d': 128, 'd_hidden_factor': 4.214984739045994, 'n_layers': 10, 'hidden_dropout': 0.4356159256727179, 'residual_dropout': 0.2772821235062695, 'learning_rate': 4.337083187456906e-05, 'batch_size': 64, 'epochs': 174}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:36:53,176] Trial 35 finished with value: 0.504755689397961 and parameters: {'d': 128, 'd_hidden_factor': 4.673196569040061, 'n_layers': 10, 'hidden_dropout': 0.44519773171651594, 'residual_dropout': 0.2838957670331046, 'learning_rate': 3.221296540985991e-05, 'batch_size': 64, 'epochs': 50}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:38:21,035] Trial 36 finished with value: 0.5024333393955318 and parameters: {'d': 128, 'd_hidden_factor': 3.458794331302818, 'n_layers': 10, 'hidden_dropout': 0.4731093090616949, 'residual_dropout': 0.37698938661778003, 'learning_rate': 1.3818491227077265e-05, 'batch_size': 64, 'epochs': 175}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:38:54,870] Trial 37 finished with value: 0.6533089737934124 and parameters: {'d': 128, 'd_hidden_factor': 2.7726966246232987, 'n_layers': 9, 'hidden_dropout': 0.4267779555995303, 'residual_dropout': 0.2877688977423963, 'learning_rate': 0.00011790204877596032, 'batch_size': 64, 'epochs': 174}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:39:29,263] Trial 38 finished with value: 0.6516437875753847 and parameters: {'d': 128, 'd_hidden_factor': 2.8349901690620563, 'n_layers': 9, 'hidden_dropout': 0.43308233198754315, 'residual_dropout': 0.2926029380765998, 'learning_rate': 0.00012666916070053067, 'batch_size': 64, 'epochs': 161}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:40:03,735] Trial 39 finished with value: 0.6349400114931891 and parameters: {'d': 128, 'd_hidden_factor': 2.8705531960143404, 'n_layers': 9, 'hidden_dropout': 0.2807525290124952, 'residual_dropout': 0.30732404384284906, 'learning_rate': 8.804450821112058e-05, 'batch_size': 64, 'epochs': 132}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:40:39,364] Trial 40 finished with value: 0.6454332714944777 and parameters: {'d': 128, 'd_hidden_factor': 1.9824278968993363, 'n_layers': 9, 'hidden_dropout': 0.333725216159587, 'residual_dropout': 0.3711100095630916, 'learning_rate': 0.00013500701802451125, 'batch_size': 64, 'epochs': 115}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:41:51,487] Trial 41 finished with value: 0.6614004273721982 and parameters: {'d': 128, 'd_hidden_factor': 3.1327334124238773, 'n_layers': 10, 'hidden_dropout': 0.43203331879118373, 'residual_dropout': 0.3013305666347432, 'learning_rate': 4.5639505120697244e-05, 'batch_size': 64, 'epochs': 159}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:42:47,143] Trial 42 finished with value: 0.6512456898235478 and parameters: {'d': 128, 'd_hidden_factor': 3.0908555338690618, 'n_layers': 10, 'hidden_dropout': 0.49670818132243155, 'residual_dropout': 0.3118448524156996, 'learning_rate': 7.917662366980952e-05, 'batch_size': 64, 'epochs': 145}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:43:58,663] Trial 43 finished with value: 0.5188635390014052 and parameters: {'d': 128, 'd_hidden_factor': 3.1456828004496833, 'n_layers': 10, 'hidden_dropout': 0.49591892025161904, 'residual_dropout': 0.31342282799405197, 'learning_rate': 2.0385688368169556e-05, 'batch_size': 64, 'epochs': 144}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:44:53,766] Trial 44 finished with value: 0.6732776955802663 and parameters: {'d': 128, 'd_hidden_factor': 2.5557445258241795, 'n_layers': 10, 'hidden_dropout': 0.43146199123096546, 'residual_dropout': 0.35358640259949176, 'learning_rate': 7.860508720549239e-05, 'batch_size': 64, 'epochs': 163}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:45:44,825] Trial 45 finished with value: 0.6069356158019191 and parameters: {'d': 128, 'd_hidden_factor': 2.5778359270931785, 'n_layers': 10, 'hidden_dropout': 0.03050178676502252, 'residual_dropout': 0.36296738031640774, 'learning_rate': 3.98035937348138e-05, 'batch_size': 64, 'epochs': 162}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:46:39,706] Trial 46 finished with value: 0.6468233391977448 and parameters: {'d': 128, 'd_hidden_factor': 1.9451734361228792, 'n_layers': 9, 'hidden_dropout': 0.4296199312228446, 'residual_dropout': 0.41071697205933544, 'learning_rate': 6.186309086049831e-05, 'batch_size': 64, 'epochs': 124}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:47:13,443] Trial 47 finished with value: 0.6273755764532194 and parameters: {'d': 128, 'd_hidden_factor': 2.7420304031346636, 'n_layers': 10, 'hidden_dropout': 0.4602165042174516, 'residual_dropout': 0.336845098393053, 'learning_rate': 0.00016409097433544147, 'batch_size': 64, 'epochs': 160}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:47:47,898] Trial 48 finished with value: 0.5618708490713058 and parameters: {'d': 128, 'd_hidden_factor': 2.2182404365723816, 'n_layers': 9, 'hidden_dropout': 0.30810595994557005, 'residual_dropout': 0.28410126537295616, 'learning_rate': 0.0002545597647758087, 'batch_size': 32, 'epochs': 73}. Best is trial 31 with value: 0.6764676094421634.\n",
      "[I 2025-11-27 12:48:23,841] Trial 49 finished with value: 0.6503456282739954 and parameters: {'d': 256, 'd_hidden_factor': 1.4955618444186862, 'n_layers': 10, 'hidden_dropout': 0.3777054839276479, 'residual_dropout': 0.40032658051554887, 'learning_rate': 8.893005688745637e-05, 'batch_size': 64, 'epochs': 158}. Best is trial 31 with value: 0.6764676094421634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 1837.12s\n",
      "  Best CV G-Mean: 0.6765\n",
      "  Best parameters:\n",
      "    d: 64\n",
      "    d_hidden_factor: 4.721827878307432\n",
      "    n_layers: 9\n",
      "    hidden_dropout: 0.46751066172174116\n",
      "    residual_dropout: 0.20297535460076244\n",
      "    learning_rate: 0.00010919182475514198\n",
      "    batch_size: 32\n",
      "    epochs: 161\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/161: Train Loss = 1.2516, Val Loss = 1.2946\n",
      "    Epoch 20/161: Train Loss = 1.0379, Val Loss = 1.0562\n",
      "    Epoch 30/161: Train Loss = 0.8843, Val Loss = 0.9632\n",
      "    Epoch 40/161: Train Loss = 0.7694, Val Loss = 0.9087\n",
      "    Epoch 50/161: Train Loss = 0.6927, Val Loss = 0.8868\n",
      "    Epoch 60/161: Train Loss = 0.6728, Val Loss = 0.8659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 12:48:30,248] A new study created in memory with name: no-name-dfb0154c-be4c-4cec-9f50-9ead6574004b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 70/161: Train Loss = 0.6373, Val Loss = 0.8764\n",
      "    Early stopping at epoch 72\n",
      "✓ Training complete! Time: 6.39s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR eucalyptus\n",
      "================================================================================\n",
      "Accuracy:        0.6290\n",
      "AUC OVO:         0.9010\n",
      "G-Mean:          0.5759\n",
      "Cross-Entropy:   0.8226\n",
      "================================================================================\n",
      "✓ Saved results for eucalyptus\n",
      "\n",
      "✓ Completed eucalyptus (26/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 27/30: pc3\n",
      "################################################################################\n",
      "Loading processed dataset from cache: pc3\n",
      "Using device: cuda\n",
      "Dataset: pc3\n",
      "  Train: (1094, 37), Test: (469, 37)\n",
      "  Features: 37, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: pc3\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 12:48:42,003] Trial 0 finished with value: 0.3860075897048444 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.3860075897048444.\n",
      "[I 2025-11-27 12:49:01,679] Trial 1 finished with value: 0.5287413205642593 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.5287413205642593.\n",
      "[I 2025-11-27 12:49:25,485] Trial 2 finished with value: 0.5414278628798688 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 2 with value: 0.5414278628798688.\n",
      "[I 2025-11-27 12:52:34,080] Trial 3 finished with value: 0.5184789653036839 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 2 with value: 0.5414278628798688.\n",
      "[I 2025-11-27 12:52:59,496] Trial 4 finished with value: 0.5038666474471923 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 2 with value: 0.5414278628798688.\n",
      "[I 2025-11-27 12:55:01,471] Trial 5 finished with value: 0.43468636053682663 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 2 with value: 0.5414278628798688.\n",
      "[I 2025-11-27 12:56:22,932] Trial 6 finished with value: 0.4912541971913167 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 2 with value: 0.5414278628798688.\n",
      "[I 2025-11-27 12:56:34,653] Trial 7 finished with value: 0.4680638167161292 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 2 with value: 0.5414278628798688.\n",
      "[I 2025-11-27 12:56:38,737] Trial 8 finished with value: 0.5653105586523175 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 12:56:41,549] Trial 9 finished with value: 0.5164896368254484 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 12:57:13,796] Trial 10 finished with value: 0.5216751632502413 and parameters: {'d': 512, 'd_hidden_factor': 4.97088426861444, 'n_layers': 9, 'hidden_dropout': 0.004030571702010294, 'residual_dropout': 0.19485930498507747, 'learning_rate': 0.0006550956088886104, 'batch_size': 256, 'epochs': 196}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 12:57:29,724] Trial 11 finished with value: 0.5287673080446776 and parameters: {'d': 128, 'd_hidden_factor': 2.463181657022648, 'n_layers': 8, 'hidden_dropout': 0.009167267872244343, 'residual_dropout': 0.17494421422567685, 'learning_rate': 0.00010277907736606542, 'batch_size': 256, 'epochs': 198}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 12:57:46,007] Trial 12 finished with value: 0.5084851314654733 and parameters: {'d': 128, 'd_hidden_factor': 1.990247787249071, 'n_layers': 4, 'hidden_dropout': 0.12706008704455735, 'residual_dropout': 0.00928825823765117, 'learning_rate': 0.0004124616854879802, 'batch_size': 64, 'epochs': 155}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 12:58:12,598] Trial 13 finished with value: 0.5433435695468299 and parameters: {'d': 128, 'd_hidden_factor': 3.0764677394426387, 'n_layers': 8, 'hidden_dropout': 0.1282492931447887, 'residual_dropout': 0.12961378391424722, 'learning_rate': 0.00010038584476789021, 'batch_size': 128, 'epochs': 160}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 12:58:43,444] Trial 14 finished with value: 0.5196454785990664 and parameters: {'d': 128, 'd_hidden_factor': 4.661252296572769, 'n_layers': 8, 'hidden_dropout': 0.0866536635119308, 'residual_dropout': 0.10562599961542316, 'learning_rate': 5.234874322609952e-05, 'batch_size': 128, 'epochs': 166}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 12:59:52,454] Trial 15 finished with value: 0.4948892850902329 and parameters: {'d': 128, 'd_hidden_factor': 3.416053370223368, 'n_layers': 8, 'hidden_dropout': 0.07275048158747356, 'residual_dropout': 0.24785037728462722, 'learning_rate': 1.201880159180346e-05, 'batch_size': 128, 'epochs': 168}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 12:59:57,227] Trial 16 finished with value: 0.4860676068603601 and parameters: {'d': 128, 'd_hidden_factor': 4.299953214329586, 'n_layers': 7, 'hidden_dropout': 0.06655925283485266, 'residual_dropout': 0.2445047234664179, 'learning_rate': 0.0011801142500613441, 'batch_size': 256, 'epochs': 142}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 13:00:38,196] Trial 17 finished with value: 0.2736844206104981 and parameters: {'d': 512, 'd_hidden_factor': 3.2215041744466855, 'n_layers': 10, 'hidden_dropout': 0.17954077474325586, 'residual_dropout': 0.04474968457938301, 'learning_rate': 0.007570283433433403, 'batch_size': 128, 'epochs': 181}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 13:01:02,227] Trial 18 finished with value: 0.47909587385932884 and parameters: {'d': 64, 'd_hidden_factor': 1.8747705522934435, 'n_layers': 7, 'hidden_dropout': 0.1258903870892035, 'residual_dropout': 0.1280469573580945, 'learning_rate': 6.560121276948156e-05, 'batch_size': 256, 'epochs': 145}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 13:01:10,010] Trial 19 finished with value: 0.5444132800047867 and parameters: {'d': 128, 'd_hidden_factor': 2.640640607857845, 'n_layers': 3, 'hidden_dropout': 0.04959856858235974, 'residual_dropout': 0.4921796978160566, 'learning_rate': 0.0007229526953330044, 'batch_size': 128, 'epochs': 180}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 13:01:13,374] Trial 20 finished with value: 0.5324774296469297 and parameters: {'d': 128, 'd_hidden_factor': 2.666098952271214, 'n_layers': 1, 'hidden_dropout': 0.4202138733708044, 'residual_dropout': 0.4910019379934049, 'learning_rate': 0.0029562515600007845, 'batch_size': 128, 'epochs': 183}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 13:01:19,639] Trial 21 finished with value: 0.5264375350239605 and parameters: {'d': 128, 'd_hidden_factor': 3.4699829916201956, 'n_layers': 3, 'hidden_dropout': 0.04461143544045284, 'residual_dropout': 0.41770780240639255, 'learning_rate': 0.0007128630250068124, 'batch_size': 128, 'epochs': 179}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 13:01:25,252] Trial 22 finished with value: 0.5427687380645316 and parameters: {'d': 128, 'd_hidden_factor': 2.912898891242838, 'n_layers': 4, 'hidden_dropout': 0.11744578030673701, 'residual_dropout': 0.3900569581573197, 'learning_rate': 0.0016759398248302013, 'batch_size': 128, 'epochs': 199}. Best is trial 8 with value: 0.5653105586523175.\n",
      "[I 2025-11-27 13:01:47,851] Trial 23 finished with value: 0.5751465813951461 and parameters: {'d': 128, 'd_hidden_factor': 2.3825459201848944, 'n_layers': 7, 'hidden_dropout': 0.03511100874398029, 'residual_dropout': 0.4615619588457673, 'learning_rate': 0.0001745908033856583, 'batch_size': 128, 'epochs': 163}. Best is trial 23 with value: 0.5751465813951461.\n",
      "[I 2025-11-27 13:01:58,162] Trial 24 finished with value: 0.5534533831677059 and parameters: {'d': 128, 'd_hidden_factor': 1.7458793199749376, 'n_layers': 7, 'hidden_dropout': 0.025432116789916467, 'residual_dropout': 0.4638963174617964, 'learning_rate': 0.0003811689972647376, 'batch_size': 256, 'epochs': 181}. Best is trial 23 with value: 0.5751465813951461.\n",
      "[I 2025-11-27 13:02:11,952] Trial 25 finished with value: 0.5256803102531338 and parameters: {'d': 128, 'd_hidden_factor': 1.7588180804538915, 'n_layers': 7, 'hidden_dropout': 0.013690289438714753, 'residual_dropout': 0.4535033733776426, 'learning_rate': 0.000210066775387393, 'batch_size': 256, 'epochs': 151}. Best is trial 23 with value: 0.5751465813951461.\n",
      "[I 2025-11-27 13:02:34,473] Trial 26 finished with value: 0.5281708924307381 and parameters: {'d': 64, 'd_hidden_factor': 1.481479275607388, 'n_layers': 9, 'hidden_dropout': 0.21617142944610496, 'residual_dropout': 0.3864272664757997, 'learning_rate': 0.0003491133641750966, 'batch_size': 256, 'epochs': 135}. Best is trial 23 with value: 0.5751465813951461.\n",
      "[I 2025-11-27 13:02:40,950] Trial 27 finished with value: 0.5483529747791943 and parameters: {'d': 256, 'd_hidden_factor': 2.2942840369774986, 'n_layers': 7, 'hidden_dropout': 0.03901815420734813, 'residual_dropout': 0.46111393939144224, 'learning_rate': 0.005098886279401942, 'batch_size': 256, 'epochs': 111}. Best is trial 23 with value: 0.5751465813951461.\n",
      "[I 2025-11-27 13:02:48,003] Trial 28 finished with value: 0.5227302026331957 and parameters: {'d': 512, 'd_hidden_factor': 1.5470238419036881, 'n_layers': 5, 'hidden_dropout': 0.10511385121317102, 'residual_dropout': 0.3867768863229287, 'learning_rate': 0.0004834537242995863, 'batch_size': 256, 'epochs': 169}. Best is trial 23 with value: 0.5751465813951461.\n",
      "[I 2025-11-27 13:03:15,522] Trial 29 finished with value: 0.4232724441026382 and parameters: {'d': 64, 'd_hidden_factor': 1.1709021802338988, 'n_layers': 6, 'hidden_dropout': 0.49234790898426983, 'residual_dropout': 0.28299234158457354, 'learning_rate': 0.00018683667138743798, 'batch_size': 256, 'epochs': 189}. Best is trial 23 with value: 0.5751465813951461.\n",
      "[I 2025-11-27 13:06:07,800] Trial 30 finished with value: 0.5198470082385249 and parameters: {'d': 128, 'd_hidden_factor': 2.13071262411956, 'n_layers': 9, 'hidden_dropout': 0.0009765327106295357, 'residual_dropout': 0.45655056641601516, 'learning_rate': 3.861883906691708e-05, 'batch_size': 32, 'epochs': 172}. Best is trial 23 with value: 0.5751465813951461.\n",
      "[I 2025-11-27 13:06:13,333] Trial 31 finished with value: 0.5441597581906288 and parameters: {'d': 256, 'd_hidden_factor': 2.3486156082912295, 'n_layers': 7, 'hidden_dropout': 0.035943069177555485, 'residual_dropout': 0.4707154500610707, 'learning_rate': 0.0023364070392842998, 'batch_size': 256, 'epochs': 117}. Best is trial 23 with value: 0.5751465813951461.\n",
      "[I 2025-11-27 13:06:20,064] Trial 32 finished with value: 0.5901034404758847 and parameters: {'d': 256, 'd_hidden_factor': 1.8103528312101083, 'n_layers': 7, 'hidden_dropout': 0.038609246415486895, 'residual_dropout': 0.42625230198252084, 'learning_rate': 0.004732405706482846, 'batch_size': 256, 'epochs': 104}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:06:24,413] Trial 33 finished with value: 0.5702028636112114 and parameters: {'d': 256, 'd_hidden_factor': 1.8771119046465017, 'n_layers': 5, 'hidden_dropout': 0.07221390665574264, 'residual_dropout': 0.41453698327842103, 'learning_rate': 0.005064191178879904, 'batch_size': 256, 'epochs': 63}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:06:28,749] Trial 34 finished with value: 0.5504184274631081 and parameters: {'d': 256, 'd_hidden_factor': 1.9761584270361534, 'n_layers': 5, 'hidden_dropout': 0.07877263500725078, 'residual_dropout': 0.4047010313487779, 'learning_rate': 0.005511658350683284, 'batch_size': 256, 'epochs': 52}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:06:34,080] Trial 35 finished with value: 0.5346119893682718 and parameters: {'d': 256, 'd_hidden_factor': 2.505259008931496, 'n_layers': 6, 'hidden_dropout': 0.15815414549828433, 'residual_dropout': 0.3622037263483904, 'learning_rate': 0.005363918683183727, 'batch_size': 256, 'epochs': 65}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:06:49,691] Trial 36 finished with value: 0.48449417389157573 and parameters: {'d': 256, 'd_hidden_factor': 2.786560704743629, 'n_layers': 5, 'hidden_dropout': 0.09637429445917436, 'residual_dropout': 0.3656061601654862, 'learning_rate': 0.0016051350343232534, 'batch_size': 64, 'epochs': 30}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:07:30,752] Trial 37 finished with value: 0.504481707487557 and parameters: {'d': 256, 'd_hidden_factor': 3.7780730987030333, 'n_layers': 6, 'hidden_dropout': 0.0577331816090559, 'residual_dropout': 0.4311271009358649, 'learning_rate': 0.0011930047616054713, 'batch_size': 32, 'epochs': 83}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:07:33,921] Trial 38 finished with value: 0.4538050622754669 and parameters: {'d': 256, 'd_hidden_factor': 1.3662326451707036, 'n_layers': 4, 'hidden_dropout': 0.2169919557424511, 'residual_dropout': 0.3078874490213251, 'learning_rate': 0.003994975031891835, 'batch_size': 256, 'epochs': 68}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:07:41,430] Trial 39 finished with value: 0.5510768371225387 and parameters: {'d': 256, 'd_hidden_factor': 4.1274875838116065, 'n_layers': 6, 'hidden_dropout': 0.1592632874589691, 'residual_dropout': 0.42137007215271194, 'learning_rate': 0.009594436906788496, 'batch_size': 256, 'epochs': 107}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:08:14,736] Trial 40 finished with value: 0.5219758555455781 and parameters: {'d': 256, 'd_hidden_factor': 1.6463877357855388, 'n_layers': 5, 'hidden_dropout': 0.030541220835218798, 'residual_dropout': 0.3534607895432378, 'learning_rate': 0.002055756082035642, 'batch_size': 32, 'epochs': 49}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:08:28,216] Trial 41 finished with value: 0.524311468586709 and parameters: {'d': 128, 'd_hidden_factor': 1.747309320994588, 'n_layers': 7, 'hidden_dropout': 0.025285670598785347, 'residual_dropout': 0.474869701950985, 'learning_rate': 0.00025552143557915085, 'batch_size': 256, 'epochs': 190}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:08:43,060] Trial 42 finished with value: 0.4993212053990351 and parameters: {'d': 128, 'd_hidden_factor': 2.1111118602213583, 'n_layers': 8, 'hidden_dropout': 0.06385567093734856, 'residual_dropout': 0.4374410303749011, 'learning_rate': 0.00014881841536969152, 'batch_size': 256, 'epochs': 81}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:08:47,941] Trial 43 finished with value: 0.5586557659610122 and parameters: {'d': 256, 'd_hidden_factor': 1.8585283457712694, 'n_layers': 6, 'hidden_dropout': 0.44435819668937837, 'residual_dropout': 0.4987107010257649, 'learning_rate': 0.0068441492951237465, 'batch_size': 256, 'epochs': 129}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:09:07,393] Trial 44 finished with value: 0.46322591214491526 and parameters: {'d': 256, 'd_hidden_factor': 1.2590887100918178, 'n_layers': 6, 'hidden_dropout': 0.4321607914049669, 'residual_dropout': 0.4981948442789665, 'learning_rate': 0.007216177442990688, 'batch_size': 64, 'epochs': 131}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:09:11,286] Trial 45 finished with value: 0.5312517512946766 and parameters: {'d': 256, 'd_hidden_factor': 2.448895658673772, 'n_layers': 5, 'hidden_dropout': 0.36415370146291803, 'residual_dropout': 0.44335372502223275, 'learning_rate': 0.0029417907262292518, 'batch_size': 256, 'epochs': 99}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:09:16,133] Trial 46 finished with value: 0.4869022375275838 and parameters: {'d': 256, 'd_hidden_factor': 1.9451734361228792, 'n_layers': 6, 'hidden_dropout': 0.445959834414018, 'residual_dropout': 0.4108849417041003, 'learning_rate': 0.004264399985164106, 'batch_size': 256, 'epochs': 75}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:09:24,485] Trial 47 finished with value: 0.5682550718374993 and parameters: {'d': 512, 'd_hidden_factor': 2.240344750704975, 'n_layers': 4, 'hidden_dropout': 0.3562326307318958, 'residual_dropout': 0.47392848043439445, 'learning_rate': 0.006319395683413709, 'batch_size': 256, 'epochs': 123}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:09:51,468] Trial 48 finished with value: 0.4356984754939914 and parameters: {'d': 512, 'd_hidden_factor': 3.2108059928491977, 'n_layers': 4, 'hidden_dropout': 0.3368246243861766, 'residual_dropout': 0.2178079894973726, 'learning_rate': 0.002941484727947316, 'batch_size': 64, 'epochs': 117}. Best is trial 32 with value: 0.5901034404758847.\n",
      "[I 2025-11-27 13:09:56,854] Trial 49 finished with value: 0.5464781336912337 and parameters: {'d': 512, 'd_hidden_factor': 1.0308717912666476, 'n_layers': 3, 'hidden_dropout': 0.26869302247629523, 'residual_dropout': 0.4782079619910419, 'learning_rate': 0.0010735702598753491, 'batch_size': 128, 'epochs': 95}. Best is trial 32 with value: 0.5901034404758847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 1286.61s\n",
      "  Best CV G-Mean: 0.5901\n",
      "  Best parameters:\n",
      "    d: 256\n",
      "    d_hidden_factor: 1.8103528312101083\n",
      "    n_layers: 7\n",
      "    hidden_dropout: 0.038609246415486895\n",
      "    residual_dropout: 0.42625230198252084\n",
      "    learning_rate: 0.004732405706482846\n",
      "    batch_size: 256\n",
      "    epochs: 104\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/104: Train Loss = 0.2218, Val Loss = 0.3786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:09:57,394] A new study created in memory with name: no-name-a9d42d6f-680a-4ab2-804d-4a682be8a3a9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 20/104: Train Loss = 0.1759, Val Loss = 0.3791\n",
      "    Early stopping at epoch 28\n",
      "✓ Training complete! Time: 0.52s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR pc3\n",
      "================================================================================\n",
      "Accuracy:        0.8763\n",
      "AUC OVO:         0.7885\n",
      "G-Mean:          0.5757\n",
      "Cross-Entropy:   0.3551\n",
      "================================================================================\n",
      "✓ Saved results for pc3\n",
      "\n",
      "✓ Completed pc3 (27/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 28/30: dresses-sales\n",
      "################################################################################\n",
      "Loading processed dataset from cache: dresses-sales\n",
      "Using device: cuda\n",
      "Dataset: dresses-sales\n",
      "  Train: (350, 141), Test: (150, 141)\n",
      "  Features: 141, Classes: 2\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: dresses-sales\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:10:00,621] Trial 0 finished with value: 0.5580807666130643 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.5580807666130643.\n",
      "[I 2025-11-27 13:10:04,503] Trial 1 finished with value: 0.5212502010870452 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 0 with value: 0.5580807666130643.\n",
      "[I 2025-11-27 13:10:08,750] Trial 2 finished with value: 0.5605285293218245 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 2 with value: 0.5605285293218245.\n",
      "[I 2025-11-27 13:10:37,040] Trial 3 finished with value: 0.5776283303384995 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.5776283303384995.\n",
      "[I 2025-11-27 13:10:41,376] Trial 4 finished with value: 0.5313084751422998 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 3 with value: 0.5776283303384995.\n",
      "[I 2025-11-27 13:11:01,904] Trial 5 finished with value: 0.5438594038124026 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 3 with value: 0.5776283303384995.\n",
      "[I 2025-11-27 13:11:16,413] Trial 6 finished with value: 0.5016492718388402 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 3 with value: 0.5776283303384995.\n",
      "[I 2025-11-27 13:11:18,558] Trial 7 finished with value: 0.5195839504804041 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 3 with value: 0.5776283303384995.\n",
      "[I 2025-11-27 13:11:19,768] Trial 8 finished with value: 0.5124530594125151 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 3 with value: 0.5776283303384995.\n",
      "[I 2025-11-27 13:11:20,457] Trial 9 finished with value: 0.548293385438425 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 3 with value: 0.5776283303384995.\n",
      "[I 2025-11-27 13:11:47,730] Trial 10 finished with value: 0.5818830206876703 and parameters: {'d': 256, 'd_hidden_factor': 4.956401873386991, 'n_layers': 10, 'hidden_dropout': 0.10467358725545478, 'residual_dropout': 0.21319384192877996, 'learning_rate': 1.0455868741494775e-05, 'batch_size': 32, 'epochs': 159}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:12:13,230] Trial 11 finished with value: 0.5658035620923744 and parameters: {'d': 256, 'd_hidden_factor': 4.978541460939402, 'n_layers': 10, 'hidden_dropout': 0.08723353405849409, 'residual_dropout': 0.22944464268646939, 'learning_rate': 1.0158320577860581e-05, 'batch_size': 32, 'epochs': 171}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:12:31,295] Trial 12 finished with value: 0.5737886928803192 and parameters: {'d': 256, 'd_hidden_factor': 4.700322375404564, 'n_layers': 10, 'hidden_dropout': 0.13399100690564741, 'residual_dropout': 0.22988626022427197, 'learning_rate': 3.551819509547847e-05, 'batch_size': 32, 'epochs': 150}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:13:08,330] Trial 13 finished with value: 0.5479199533083616 and parameters: {'d': 256, 'd_hidden_factor': 2.2848503025755864, 'n_layers': 8, 'hidden_dropout': 0.4009467477691605, 'residual_dropout': 0.15185790768752072, 'learning_rate': 1.0156421711796782e-05, 'batch_size': 32, 'epochs': 153}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:13:17,866] Trial 14 finished with value: 0.5818196862502345 and parameters: {'d': 512, 'd_hidden_factor': 4.344093201411143, 'n_layers': 8, 'hidden_dropout': 0.027339426374092007, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 4.7705452676408725e-05, 'batch_size': 128, 'epochs': 197}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:13:27,335] Trial 15 finished with value: 0.5524499018840099 and parameters: {'d': 512, 'd_hidden_factor': 4.461226410456492, 'n_layers': 8, 'hidden_dropout': 0.0032523367514282094, 'residual_dropout': 0.023829386218252563, 'learning_rate': 7.705055411258324e-05, 'batch_size': 128, 'epochs': 192}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:13:37,102] Trial 16 finished with value: 0.5503445442354228 and parameters: {'d': 512, 'd_hidden_factor': 4.319529342708191, 'n_layers': 8, 'hidden_dropout': 0.060650672880766865, 'residual_dropout': 0.11657721336819934, 'learning_rate': 4.5548299294062825e-05, 'batch_size': 128, 'epochs': 172}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:13:47,270] Trial 17 finished with value: 0.5590790131708462 and parameters: {'d': 512, 'd_hidden_factor': 4.9325176107325435, 'n_layers': 9, 'hidden_dropout': 0.07436726243220565, 'residual_dropout': 0.030592371909318117, 'learning_rate': 0.0006151230699127701, 'batch_size': 128, 'epochs': 180}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:13:58,929] Trial 18 finished with value: 0.5570112195398369 and parameters: {'d': 512, 'd_hidden_factor': 4.409271365671797, 'n_layers': 9, 'hidden_dropout': 0.16145487062402855, 'residual_dropout': 0.00014597398816210036, 'learning_rate': 1.748450684048741e-05, 'batch_size': 128, 'epochs': 146}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:14:01,114] Trial 19 finished with value: 0.56177355595952 and parameters: {'d': 64, 'd_hidden_factor': 4.033922876421632, 'n_layers': 7, 'hidden_dropout': 0.11276430857371285, 'residual_dropout': 0.16885219213971683, 'learning_rate': 0.0006441943583327288, 'batch_size': 256, 'epochs': 162}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:14:09,988] Trial 20 finished with value: 0.5318049505089281 and parameters: {'d': 512, 'd_hidden_factor': 3.4520715743872765, 'n_layers': 9, 'hidden_dropout': 0.04539626203283579, 'residual_dropout': 0.26681459626650667, 'learning_rate': 7.610613900280256e-05, 'batch_size': 128, 'epochs': 136}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:14:36,176] Trial 21 finished with value: 0.5396434741796349 and parameters: {'d': 256, 'd_hidden_factor': 2.8498255560757566, 'n_layers': 10, 'hidden_dropout': 0.2595343076178078, 'residual_dropout': 0.2847539231512697, 'learning_rate': 1.9758232196167383e-05, 'batch_size': 32, 'epochs': 73}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:15:01,233] Trial 22 finished with value: 0.5722520613032441 and parameters: {'d': 256, 'd_hidden_factor': 2.4095586166016743, 'n_layers': 10, 'hidden_dropout': 0.21616643952788558, 'residual_dropout': 0.20253079528790222, 'learning_rate': 1.9031381155634894e-05, 'batch_size': 32, 'epochs': 112}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:15:13,607] Trial 23 finished with value: 0.572364075995943 and parameters: {'d': 256, 'd_hidden_factor': 1.6403960994118048, 'n_layers': 9, 'hidden_dropout': 0.20301006065053034, 'residual_dropout': 0.07270041975494752, 'learning_rate': 6.101182640609616e-05, 'batch_size': 32, 'epochs': 186}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:15:41,570] Trial 24 finished with value: 0.5815667275109973 and parameters: {'d': 256, 'd_hidden_factor': 4.681140687337586, 'n_layers': 8, 'hidden_dropout': 0.40019605975189243, 'residual_dropout': 0.2975509987584088, 'learning_rate': 1.9898564880200705e-05, 'batch_size': 32, 'epochs': 75}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:15:54,586] Trial 25 finished with value: 0.5455781185095796 and parameters: {'d': 256, 'd_hidden_factor': 4.705649245386059, 'n_layers': 7, 'hidden_dropout': 0.4616285618339846, 'residual_dropout': 0.3867622401164135, 'learning_rate': 0.0001445336234875205, 'batch_size': 32, 'epochs': 64}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:16:08,391] Trial 26 finished with value: 0.5660214164496077 and parameters: {'d': 512, 'd_hidden_factor': 4.11565756637991, 'n_layers': 7, 'hidden_dropout': 0.40841001119823916, 'residual_dropout': 0.10457696885643221, 'learning_rate': 1.2831563278612694e-05, 'batch_size': 128, 'epochs': 110}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:16:12,136] Trial 27 finished with value: 0.42307720005601734 and parameters: {'d': 64, 'd_hidden_factor': 4.702975608669291, 'n_layers': 8, 'hidden_dropout': 0.033780496215791045, 'residual_dropout': 0.19535392567306292, 'learning_rate': 4.495883757557331e-05, 'batch_size': 256, 'epochs': 162}. Best is trial 10 with value: 0.5818830206876703.\n",
      "[I 2025-11-27 13:16:20,522] Trial 28 finished with value: 0.5964920752450611 and parameters: {'d': 256, 'd_hidden_factor': 4.258721174942554, 'n_layers': 3, 'hidden_dropout': 0.11685181245264069, 'residual_dropout': 0.3756675585345258, 'learning_rate': 3.1764777951040145e-05, 'batch_size': 32, 'epochs': 137}. Best is trial 28 with value: 0.5964920752450611.\n",
      "[I 2025-11-27 13:16:22,899] Trial 29 finished with value: 0.5693797932528691 and parameters: {'d': 64, 'd_hidden_factor': 3.679748562117274, 'n_layers': 3, 'hidden_dropout': 0.11571054606437726, 'residual_dropout': 0.38240735090702854, 'learning_rate': 0.00029289734886738157, 'batch_size': 128, 'epochs': 137}. Best is trial 28 with value: 0.5964920752450611.\n",
      "[I 2025-11-27 13:16:27,709] Trial 30 finished with value: 0.5639277071578191 and parameters: {'d': 512, 'd_hidden_factor': 4.257799343570584, 'n_layers': 4, 'hidden_dropout': 0.16983419142110104, 'residual_dropout': 0.3840483861320796, 'learning_rate': 0.00010237206344059428, 'batch_size': 128, 'epochs': 175}. Best is trial 28 with value: 0.5964920752450611.\n",
      "[I 2025-11-27 13:16:40,108] Trial 31 finished with value: 0.5791513417235684 and parameters: {'d': 256, 'd_hidden_factor': 4.4784350945006, 'n_layers': 4, 'hidden_dropout': 0.49221723306006654, 'residual_dropout': 0.30640347885802977, 'learning_rate': 2.747016971333415e-05, 'batch_size': 32, 'epochs': 44}. Best is trial 28 with value: 0.5964920752450611.\n",
      "[I 2025-11-27 13:16:55,317] Trial 32 finished with value: 0.600727562672349 and parameters: {'d': 256, 'd_hidden_factor': 4.708421746705769, 'n_layers': 5, 'hidden_dropout': 0.09008699300455848, 'residual_dropout': 0.36284830921241956, 'learning_rate': 1.4797219999249465e-05, 'batch_size': 32, 'epochs': 137}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:17:13,077] Trial 33 finished with value: 0.5673953695131337 and parameters: {'d': 256, 'd_hidden_factor': 4.969807640881928, 'n_layers': 5, 'hidden_dropout': 0.0826642667526785, 'residual_dropout': 0.45789902120666515, 'learning_rate': 1.3963262985559985e-05, 'batch_size': 32, 'epochs': 136}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:17:18,430] Trial 34 finished with value: 0.5695662746634318 and parameters: {'d': 128, 'd_hidden_factor': 3.75459991480957, 'n_layers': 3, 'hidden_dropout': 0.0315695874828516, 'residual_dropout': 0.36155204620483994, 'learning_rate': 4.162743187576565e-05, 'batch_size': 64, 'epochs': 160}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:17:27,699] Trial 35 finished with value: 0.5652412161081319 and parameters: {'d': 256, 'd_hidden_factor': 4.1113687443041265, 'n_layers': 3, 'hidden_dropout': 0.10998784926761059, 'residual_dropout': 0.44281097994664104, 'learning_rate': 2.7859975474637025e-05, 'batch_size': 32, 'epochs': 124}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:17:35,833] Trial 36 finished with value: 0.5187743430134102 and parameters: {'d': 256, 'd_hidden_factor': 4.541171503753926, 'n_layers': 5, 'hidden_dropout': 0.1407557564852966, 'residual_dropout': 0.34595079089488656, 'learning_rate': 0.0005256717233821735, 'batch_size': 32, 'epochs': 143}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:17:39,170] Trial 37 finished with value: 0.5638904174318312 and parameters: {'d': 128, 'd_hidden_factor': 3.4229130232427245, 'n_layers': 1, 'hidden_dropout': 0.09590001778172294, 'residual_dropout': 0.41288142716204623, 'learning_rate': 5.74247017274745e-05, 'batch_size': 64, 'epochs': 119}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:17:55,825] Trial 38 finished with value: 0.5846911810960704 and parameters: {'d': 256, 'd_hidden_factor': 4.223960324860847, 'n_layers': 4, 'hidden_dropout': 0.19252786265896626, 'residual_dropout': 0.47032317383353694, 'learning_rate': 1.4648956489105805e-05, 'batch_size': 32, 'epochs': 131}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:18:18,957] Trial 39 finished with value: 0.5740738419196821 and parameters: {'d': 256, 'd_hidden_factor': 3.1496097878319476, 'n_layers': 5, 'hidden_dropout': 0.22632878610180618, 'residual_dropout': 0.4790520684729288, 'learning_rate': 1.4755948211980576e-05, 'batch_size': 32, 'epochs': 104}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:18:26,056] Trial 40 finished with value: 0.529258228254091 and parameters: {'d': 256, 'd_hidden_factor': 3.9224608190658836, 'n_layers': 4, 'hidden_dropout': 0.188898299869924, 'residual_dropout': 0.4082452085468575, 'learning_rate': 0.00019160075858938924, 'batch_size': 32, 'epochs': 134}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:18:32,190] Trial 41 finished with value: 0.5693086354354198 and parameters: {'d': 256, 'd_hidden_factor': 4.7516840148632316, 'n_layers': 2, 'hidden_dropout': 0.13863340290194376, 'residual_dropout': 0.32768497193546153, 'learning_rate': 2.8608372531523988e-05, 'batch_size': 32, 'epochs': 156}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:18:50,127] Trial 42 finished with value: 0.5762307766960217 and parameters: {'d': 256, 'd_hidden_factor': 4.218518918628523, 'n_layers': 4, 'hidden_dropout': 0.05737773516810585, 'residual_dropout': 0.45057290290030033, 'learning_rate': 1.035260387244783e-05, 'batch_size': 32, 'epochs': 200}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:19:03,300] Trial 43 finished with value: 0.5818184769609042 and parameters: {'d': 256, 'd_hidden_factor': 4.863939301456784, 'n_layers': 6, 'hidden_dropout': 0.17853947714716947, 'residual_dropout': 0.25678946652141954, 'learning_rate': 2.454607754181886e-05, 'batch_size': 32, 'epochs': 129}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:19:07,085] Trial 44 finished with value: 0.48363357186571854 and parameters: {'d': 128, 'd_hidden_factor': 4.578104892894915, 'n_layers': 1, 'hidden_dropout': 0.13909092679731702, 'residual_dropout': 0.36157852241789196, 'learning_rate': 1.3977525198748227e-05, 'batch_size': 64, 'epochs': 143}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:19:09,251] Trial 45 finished with value: 0.5167820376487521 and parameters: {'d': 256, 'd_hidden_factor': 3.8524547069213853, 'n_layers': 3, 'hidden_dropout': 0.03050178676502252, 'residual_dropout': 0.4682768581288467, 'learning_rate': 3.820880388757153e-05, 'batch_size': 256, 'epochs': 117}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:19:16,695] Trial 46 finished with value: 0.584585804798878 and parameters: {'d': 64, 'd_hidden_factor': 4.261486329104828, 'n_layers': 6, 'hidden_dropout': 0.07336815015179624, 'residual_dropout': 0.41877332001932865, 'learning_rate': 0.001784274728966719, 'batch_size': 32, 'epochs': 165}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:19:20,460] Trial 47 finished with value: 0.5323040359326423 and parameters: {'d': 64, 'd_hidden_factor': 4.044267581135125, 'n_layers': 2, 'hidden_dropout': 0.2398123077108874, 'residual_dropout': 0.41765434473511, 'learning_rate': 0.0013173675781514719, 'batch_size': 32, 'epochs': 168}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:19:27,717] Trial 48 finished with value: 0.5303118814164745 and parameters: {'d': 64, 'd_hidden_factor': 3.4868830728075944, 'n_layers': 6, 'hidden_dropout': 0.10230118765781124, 'residual_dropout': 0.3978751579339939, 'learning_rate': 0.0049627977894147, 'batch_size': 32, 'epochs': 150}. Best is trial 32 with value: 0.600727562672349.\n",
      "[I 2025-11-27 13:19:34,148] Trial 49 finished with value: 0.5164383689091467 and parameters: {'d': 64, 'd_hidden_factor': 4.836333242476765, 'n_layers': 5, 'hidden_dropout': 0.06169010449972221, 'residual_dropout': 0.4999542413242321, 'learning_rate': 0.0022163007656047563, 'batch_size': 32, 'epochs': 182}. Best is trial 32 with value: 0.600727562672349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 576.76s\n",
      "  Best CV G-Mean: 0.6007\n",
      "  Best parameters:\n",
      "    d: 256\n",
      "    d_hidden_factor: 4.708421746705769\n",
      "    n_layers: 5\n",
      "    hidden_dropout: 0.09008699300455848\n",
      "    residual_dropout: 0.36284830921241956\n",
      "    learning_rate: 1.4797219999249465e-05\n",
      "    batch_size: 32\n",
      "    epochs: 137\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/137: Train Loss = 0.7267, Val Loss = 0.7867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:19:34,908] A new study created in memory with name: no-name-914d39f2-bdc2-45a4-99ba-10d81e8d5ce4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Early stopping at epoch 16\n",
      "✓ Training complete! Time: 0.74s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR dresses-sales\n",
      "================================================================================\n",
      "Accuracy:        0.5000\n",
      "AUC OVO:         0.5864\n",
      "G-Mean:          0.4480\n",
      "Cross-Entropy:   0.7484\n",
      "================================================================================\n",
      "✓ Saved results for dresses-sales\n",
      "\n",
      "✓ Completed dresses-sales (28/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 29/30: balance-scale\n",
      "################################################################################\n",
      "Loading processed dataset from cache: balance-scale\n",
      "Using device: cuda\n",
      "Dataset: balance-scale\n",
      "  Train: (437, 4), Test: (188, 4)\n",
      "  Features: 4, Classes: 3\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: balance-scale\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:19:40,070] Trial 0 finished with value: 0.06933612743506347 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.06933612743506347.\n",
      "[I 2025-11-27 13:19:51,202] Trial 1 finished with value: 0.7839030731129073 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 1 with value: 0.7839030731129073.\n",
      "[I 2025-11-27 13:20:03,162] Trial 2 finished with value: 0.8038333749976619 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 2 with value: 0.8038333749976619.\n",
      "[I 2025-11-27 13:21:21,621] Trial 3 finished with value: 0.660573885225743 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 2 with value: 0.8038333749976619.\n",
      "[I 2025-11-27 13:21:34,155] Trial 4 finished with value: 0.8176407489178807 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 4 with value: 0.8176407489178807.\n",
      "[I 2025-11-27 13:22:26,406] Trial 5 finished with value: 0.20800838230519042 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 4 with value: 0.8176407489178807.\n",
      "[I 2025-11-27 13:23:06,305] Trial 6 finished with value: 0.06933612743506347 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 4 with value: 0.8176407489178807.\n",
      "[I 2025-11-27 13:23:10,653] Trial 7 finished with value: 0.7275453340278979 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 4 with value: 0.8176407489178807.\n",
      "[I 2025-11-27 13:23:14,020] Trial 8 finished with value: 0.8490324436651877 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 8 with value: 0.8490324436651877.\n",
      "[I 2025-11-27 13:23:16,083] Trial 9 finished with value: 0.9384216863831816 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 9 with value: 0.9384216863831816.\n",
      "[I 2025-11-27 13:23:18,437] Trial 10 finished with value: 0.9021040012595851 and parameters: {'d': 256, 'd_hidden_factor': 4.983415693331228, 'n_layers': 1, 'hidden_dropout': 0.44545663057052365, 'residual_dropout': 0.2217318988758852, 'learning_rate': 0.0013249155895711754, 'batch_size': 256, 'epochs': 145}. Best is trial 9 with value: 0.9384216863831816.\n",
      "[I 2025-11-27 13:23:21,342] Trial 11 finished with value: 0.8966729213224628 and parameters: {'d': 256, 'd_hidden_factor': 4.995957148017045, 'n_layers': 2, 'hidden_dropout': 0.45075942199623825, 'residual_dropout': 0.1906752818537771, 'learning_rate': 0.0009031472349418137, 'batch_size': 256, 'epochs': 144}. Best is trial 9 with value: 0.9384216863831816.\n",
      "[I 2025-11-27 13:23:22,844] Trial 12 finished with value: 0.9509526612367933 and parameters: {'d': 256, 'd_hidden_factor': 4.927212135393402, 'n_layers': 1, 'hidden_dropout': 0.4065623125080101, 'residual_dropout': 0.005739073876571299, 'learning_rate': 0.00852277869190327, 'batch_size': 256, 'epochs': 170}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:23:25,619] Trial 13 finished with value: 0.8833237372738655 and parameters: {'d': 256, 'd_hidden_factor': 4.2953749304454725, 'n_layers': 3, 'hidden_dropout': 0.3797010289299225, 'residual_dropout': 0.03936207928860028, 'learning_rate': 0.00818279418635244, 'batch_size': 256, 'epochs': 185}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:23:28,610] Trial 14 finished with value: 0.9107764340733743 and parameters: {'d': 512, 'd_hidden_factor': 4.3151578543410345, 'n_layers': 1, 'hidden_dropout': 0.12887664122746859, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 0.009896126790630504, 'batch_size': 256, 'epochs': 166}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:23:37,520] Trial 15 finished with value: 0.6555632676885489 and parameters: {'d': 256, 'd_hidden_factor': 4.514855642447511, 'n_layers': 8, 'hidden_dropout': 0.38767425456958965, 'residual_dropout': 0.12363417797950979, 'learning_rate': 0.0007172553028056624, 'batch_size': 128, 'epochs': 165}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:23:42,676] Trial 16 finished with value: 0.5024076347494513 and parameters: {'d': 256, 'd_hidden_factor': 3.8646830427244216, 'n_layers': 3, 'hidden_dropout': 0.21019889974776085, 'residual_dropout': 0.40822190091418015, 'learning_rate': 7.753846669489313e-05, 'batch_size': 256, 'epochs': 118}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:23:44,316] Trial 17 finished with value: 0.8927837037776787 and parameters: {'d': 256, 'd_hidden_factor': 4.510376061550708, 'n_layers': 1, 'hidden_dropout': 0.42361711480884384, 'residual_dropout': 0.28115728502942816, 'learning_rate': 0.0023980107700242908, 'batch_size': 256, 'epochs': 140}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:23:51,681] Trial 18 finished with value: 0.8394533816873944 and parameters: {'d': 512, 'd_hidden_factor': 3.529000401202909, 'n_layers': 3, 'hidden_dropout': 0.09660139463621625, 'residual_dropout': 0.4190886906781923, 'learning_rate': 0.00048546524260555503, 'batch_size': 256, 'epochs': 171}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:23:58,384] Trial 19 finished with value: 0.2027899722180046 and parameters: {'d': 64, 'd_hidden_factor': 2.4203523509970757, 'n_layers': 2, 'hidden_dropout': 0.3078268663868654, 'residual_dropout': 0.2469487996150432, 'learning_rate': 1.0094165165701898e-05, 'batch_size': 128, 'epochs': 110}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:24:04,354] Trial 20 finished with value: 0.9364139625793984 and parameters: {'d': 256, 'd_hidden_factor': 4.079455770593348, 'n_layers': 8, 'hidden_dropout': 0.37200263656111726, 'residual_dropout': 0.10426691307577787, 'learning_rate': 0.00569004979188322, 'batch_size': 256, 'epochs': 156}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:24:09,964] Trial 21 finished with value: 0.8007195385061951 and parameters: {'d': 256, 'd_hidden_factor': 4.080663535389717, 'n_layers': 8, 'hidden_dropout': 0.3654732861466183, 'residual_dropout': 0.07636390132744152, 'learning_rate': 0.005629935667684891, 'batch_size': 256, 'epochs': 158}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:24:16,186] Trial 22 finished with value: 0.9292362258877349 and parameters: {'d': 256, 'd_hidden_factor': 4.737159199376487, 'n_layers': 8, 'hidden_dropout': 0.4161483519771974, 'residual_dropout': 0.0034800293539502666, 'learning_rate': 0.00999542908955948, 'batch_size': 256, 'epochs': 184}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:24:22,781] Trial 23 finished with value: 0.897800582148472 and parameters: {'d': 256, 'd_hidden_factor': 4.081321958665092, 'n_layers': 10, 'hidden_dropout': 0.3376740662621918, 'residual_dropout': 0.12690155806801895, 'learning_rate': 0.0021300698901821906, 'batch_size': 256, 'epochs': 130}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:24:27,716] Trial 24 finished with value: 0.8993586830330067 and parameters: {'d': 256, 'd_hidden_factor': 4.667796935178907, 'n_layers': 7, 'hidden_dropout': 0.49439937204839407, 'residual_dropout': 0.050821203397465355, 'learning_rate': 0.00474980705116593, 'batch_size': 256, 'epochs': 151}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:24:33,581] Trial 25 finished with value: 0.8627736429099334 and parameters: {'d': 256, 'd_hidden_factor': 3.354835918724702, 'n_layers': 9, 'hidden_dropout': 0.23972864884149744, 'residual_dropout': 0.13145296516044855, 'learning_rate': 0.005743987447912788, 'batch_size': 256, 'epochs': 180}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:24:36,594] Trial 26 finished with value: 0.8186182332921564 and parameters: {'d': 256, 'd_hidden_factor': 4.205998481074304, 'n_layers': 4, 'hidden_dropout': 0.4044659816409834, 'residual_dropout': 0.18068053796338554, 'learning_rate': 0.0029094906789148244, 'batch_size': 256, 'epochs': 131}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:24:45,884] Trial 27 finished with value: 0.8793401062799365 and parameters: {'d': 512, 'd_hidden_factor': 3.7468942194197146, 'n_layers': 4, 'hidden_dropout': 0.2830039938258377, 'residual_dropout': 0.09226437938177379, 'learning_rate': 0.0019967075889322423, 'batch_size': 128, 'epochs': 197}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:25:03,628] Trial 28 finished with value: 0.37068091252936836 and parameters: {'d': 64, 'd_hidden_factor': 4.772488728565687, 'n_layers': 7, 'hidden_dropout': 0.46280416869991986, 'residual_dropout': 0.035271397781955524, 'learning_rate': 0.006488443137920289, 'batch_size': 32, 'epochs': 111}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:25:13,090] Trial 29 finished with value: 0.8597253944491682 and parameters: {'d': 64, 'd_hidden_factor': 4.485638279789799, 'n_layers': 2, 'hidden_dropout': 0.3463612036890888, 'residual_dropout': 0.21880698880233712, 'learning_rate': 0.0005035062105262821, 'batch_size': 128, 'epochs': 156}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:25:16,293] Trial 30 finished with value: 0.8342542143807826 and parameters: {'d': 256, 'd_hidden_factor': 3.883785198767445, 'n_layers': 5, 'hidden_dropout': 0.4721889108566607, 'residual_dropout': 0.4513351813326769, 'learning_rate': 0.00391384665738464, 'batch_size': 256, 'epochs': 173}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:25:22,266] Trial 31 finished with value: 0.9204732211011457 and parameters: {'d': 256, 'd_hidden_factor': 4.822503954703341, 'n_layers': 8, 'hidden_dropout': 0.41799197460757803, 'residual_dropout': 0.01319219662624432, 'learning_rate': 0.008424757120214529, 'batch_size': 256, 'epochs': 185}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:25:28,948] Trial 32 finished with value: 0.8043978876662903 and parameters: {'d': 256, 'd_hidden_factor': 4.609156083797936, 'n_layers': 9, 'hidden_dropout': 0.4184812487372633, 'residual_dropout': 0.3827874440839262, 'learning_rate': 0.009678128805920026, 'batch_size': 256, 'epochs': 188}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:25:33,608] Trial 33 finished with value: 0.8734127514385592 and parameters: {'d': 256, 'd_hidden_factor': 4.04181357975264, 'n_layers': 7, 'hidden_dropout': 0.3767389130964383, 'residual_dropout': 0.05836858225012957, 'learning_rate': 0.0014713564076949844, 'batch_size': 256, 'epochs': 54}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:25:46,544] Trial 34 finished with value: 0.8413633112073151 and parameters: {'d': 128, 'd_hidden_factor': 4.4158110786949765, 'n_layers': 9, 'hidden_dropout': 0.3207284414788567, 'residual_dropout': 0.09719584522907013, 'learning_rate': 0.0069278404977938975, 'batch_size': 64, 'epochs': 176}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:25:50,603] Trial 35 finished with value: 0.9006072486695734 and parameters: {'d': 256, 'd_hidden_factor': 2.9056629733375803, 'n_layers': 7, 'hidden_dropout': 0.3997873900698796, 'residual_dropout': 0.018431211261176028, 'learning_rate': 0.00386030503980524, 'batch_size': 256, 'epochs': 163}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:26:02,223] Trial 36 finished with value: 0.8377624911153173 and parameters: {'d': 256, 'd_hidden_factor': 4.763966368006258, 'n_layers': 8, 'hidden_dropout': 0.2685888143707673, 'residual_dropout': 0.3656061601654862, 'learning_rate': 0.00970299298228264, 'batch_size': 64, 'epochs': 137}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:26:17,831] Trial 37 finished with value: 0.7504243858029003 and parameters: {'d': 128, 'd_hidden_factor': 3.5623172767796807, 'n_layers': 1, 'hidden_dropout': 0.3016032143581233, 'residual_dropout': 0.16902141634424273, 'learning_rate': 0.0003124125838509082, 'batch_size': 32, 'epochs': 119}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:26:21,340] Trial 38 finished with value: 0.8009902712704987 and parameters: {'d': 256, 'd_hidden_factor': 3.159587463786745, 'n_layers': 5, 'hidden_dropout': 0.227630101691435, 'residual_dropout': 0.27520882762802545, 'learning_rate': 0.0011363728982725055, 'batch_size': 256, 'epochs': 74}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:26:55,825] Trial 39 finished with value: 0.674684541709583 and parameters: {'d': 256, 'd_hidden_factor': 4.878664529054543, 'n_layers': 10, 'hidden_dropout': 0.33390860209947665, 'residual_dropout': 0.06775787715864379, 'learning_rate': 0.00016166916502344025, 'batch_size': 32, 'epochs': 154}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:27:05,918] Trial 40 finished with value: 0.7658571425126909 and parameters: {'d': 64, 'd_hidden_factor': 1.6463877357855388, 'n_layers': 6, 'hidden_dropout': 0.18818570781656846, 'residual_dropout': 0.4565636743995088, 'learning_rate': 0.0028565535777785754, 'batch_size': 64, 'epochs': 37}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:27:12,051] Trial 41 finished with value: 0.855743571688453 and parameters: {'d': 256, 'd_hidden_factor': 4.7368830683543335, 'n_layers': 8, 'hidden_dropout': 0.4250380756591778, 'residual_dropout': 0.003560842089334583, 'learning_rate': 0.006976649116143261, 'batch_size': 256, 'epochs': 190}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:27:19,161] Trial 42 finished with value: 0.8685915207580004 and parameters: {'d': 256, 'd_hidden_factor': 4.952850903294556, 'n_layers': 9, 'hidden_dropout': 0.4363107515053866, 'residual_dropout': 0.026846278526595203, 'learning_rate': 0.004878451236955823, 'batch_size': 256, 'epochs': 180}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:27:25,174] Trial 43 finished with value: 0.8973670789472348 and parameters: {'d': 256, 'd_hidden_factor': 4.229615795707419, 'n_layers': 8, 'hidden_dropout': 0.35880280219220323, 'residual_dropout': 0.09881093994905452, 'learning_rate': 0.007295013733034868, 'batch_size': 256, 'epochs': 194}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:27:29,293] Trial 44 finished with value: 0.8142385169857957 and parameters: {'d': 128, 'd_hidden_factor': 4.681196759009891, 'n_layers': 7, 'hidden_dropout': 0.47322295745401566, 'residual_dropout': 0.018750757527594638, 'learning_rate': 0.004144811755742193, 'batch_size': 256, 'epochs': 182}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:27:30,692] Trial 45 finished with value: 0.8981209723212837 and parameters: {'d': 256, 'd_hidden_factor': 4.452050808989424, 'n_layers': 1, 'hidden_dropout': 0.4031679742200383, 'residual_dropout': 0.054312077469048536, 'learning_rate': 0.009832569744660747, 'batch_size': 256, 'epochs': 200}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:27:39,446] Trial 46 finished with value: 0.7080828541188192 and parameters: {'d': 512, 'd_hidden_factor': 3.913731737922458, 'n_layers': 2, 'hidden_dropout': 0.290156201012356, 'residual_dropout': 0.0025659751504102627, 'learning_rate': 4.6564870094735265e-05, 'batch_size': 256, 'epochs': 149}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:27:43,549] Trial 47 finished with value: 0.7313289307607095 and parameters: {'d': 256, 'd_hidden_factor': 4.866466926919405, 'n_layers': 6, 'hidden_dropout': 0.45225133734920797, 'residual_dropout': 0.15206479893545954, 'learning_rate': 0.0018341843179410448, 'batch_size': 256, 'epochs': 101}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:27:50,623] Trial 48 finished with value: 0.8402494388822316 and parameters: {'d': 256, 'd_hidden_factor': 4.295272910834568, 'n_layers': 9, 'hidden_dropout': 0.38487076317276914, 'residual_dropout': 0.03645305809382818, 'learning_rate': 0.0034608292870508934, 'batch_size': 256, 'epochs': 167}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:27:58,551] Trial 49 finished with value: 0.9287541581855437 and parameters: {'d': 256, 'd_hidden_factor': 2.500105193471895, 'n_layers': 8, 'hidden_dropout': 0.324435447165278, 'residual_dropout': 0.3118428665157936, 'learning_rate': 0.007278004746019322, 'batch_size': 128, 'epochs': 188}. Best is trial 12 with value: 0.9509526612367933.\n",
      "[I 2025-11-27 13:27:58,742] A new study created in memory with name: no-name-5c29bfc3-bcae-420a-a851-b3012053ce91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 503.65s\n",
      "  Best CV G-Mean: 0.9510\n",
      "  Best parameters:\n",
      "    d: 256\n",
      "    d_hidden_factor: 4.927212135393402\n",
      "    n_layers: 1\n",
      "    hidden_dropout: 0.4065623125080101\n",
      "    residual_dropout: 0.005739073876571299\n",
      "    learning_rate: 0.00852277869190327\n",
      "    batch_size: 256\n",
      "    epochs: 170\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/170: Train Loss = 0.1501, Val Loss = 0.1845\n",
      "    Epoch 20/170: Train Loss = 0.1287, Val Loss = 0.1317\n",
      "    Epoch 30/170: Train Loss = 0.1083, Val Loss = 0.1438\n",
      "    Epoch 40/170: Train Loss = 0.0693, Val Loss = 0.0704\n",
      "    Epoch 50/170: Train Loss = 0.0497, Val Loss = 0.0647\n",
      "    Epoch 60/170: Train Loss = 0.0350, Val Loss = 0.0288\n",
      "    Epoch 70/170: Train Loss = 0.0541, Val Loss = 0.0397\n",
      "    Early stopping at epoch 73\n",
      "✓ Training complete! Time: 0.17s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR balance-scale\n",
      "================================================================================\n",
      "Accuracy:        0.9787\n",
      "AUC OVO:         0.9968\n",
      "G-Mean:          0.9659\n",
      "Cross-Entropy:   0.0707\n",
      "================================================================================\n",
      "✓ Saved results for balance-scale\n",
      "\n",
      "✓ Completed balance-scale (29/30)\n",
      "\n",
      "################################################################################\n",
      "DATASET 30/30: analcatdata_authorship\n",
      "################################################################################\n",
      "Loading processed dataset from cache: analcatdata_authorship\n",
      "Using device: cuda\n",
      "Dataset: analcatdata_authorship\n",
      "  Train: (588, 70), Test: (253, 70)\n",
      "  Features: 70, Classes: 4\n",
      "✓ Data loaded to cuda\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT: analcatdata_authorship\n",
      "================================================================================\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "  Trials: 50, CV Folds: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:28:05,605] Trial 0 finished with value: 0.9975753094846148 and parameters: {'d': 64, 'd_hidden_factor': 3.8778758791422523, 'n_layers': 5, 'hidden_dropout': 0.49038209919230774, 'residual_dropout': 0.34241486929243165, 'learning_rate': 0.00027720158198153483, 'batch_size': 128, 'epochs': 40}. Best is trial 0 with value: 0.9975753094846148.\n",
      "[I 2025-11-27 13:28:25,676] Trial 1 finished with value: 0.9954235137479704 and parameters: {'d': 128, 'd_hidden_factor': 3.1262054953673535, 'n_layers': 6, 'hidden_dropout': 0.31720047927566053, 'residual_dropout': 0.4247158970388948, 'learning_rate': 0.0014906166728108333, 'batch_size': 64, 'epochs': 69}. Best is trial 0 with value: 0.9975753094846148.\n",
      "[I 2025-11-27 13:28:42,319] Trial 2 finished with value: 0.9966358590056631 and parameters: {'d': 128, 'd_hidden_factor': 2.723451053318575, 'n_layers': 5, 'hidden_dropout': 0.212915145147914, 'residual_dropout': 0.15613061148623264, 'learning_rate': 0.0001901314327577386, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: 0.9975753094846148.\n",
      "[I 2025-11-27 13:30:30,280] Trial 3 finished with value: 0.9987876547423074 and parameters: {'d': 256, 'd_hidden_factor': 2.9321370570508174, 'n_layers': 10, 'hidden_dropout': 0.25974255962990467, 'residual_dropout': 0.30644726288148383, 'learning_rate': 2.300837769659881e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.9987876547423074.\n",
      "[I 2025-11-27 13:30:41,733] Trial 4 finished with value: 0.9975289562751156 and parameters: {'d': 256, 'd_hidden_factor': 3.677255131849089, 'n_layers': 6, 'hidden_dropout': 0.31245175104779993, 'residual_dropout': 0.3373445254939124, 'learning_rate': 0.0033653273331619546, 'batch_size': 64, 'epochs': 127}. Best is trial 3 with value: 0.9987876547423074.\n",
      "[I 2025-11-27 13:31:52,125] Trial 5 finished with value: 0.9966358590056631 and parameters: {'d': 128, 'd_hidden_factor': 1.0645168267800673, 'n_layers': 6, 'hidden_dropout': 0.27839259619714435, 'residual_dropout': 0.07947982207236137, 'learning_rate': 2.8788003404415943e-05, 'batch_size': 32, 'epochs': 96}. Best is trial 3 with value: 0.9987876547423074.\n",
      "[I 2025-11-27 13:32:47,357] Trial 6 finished with value: 0.9987876547423074 and parameters: {'d': 64, 'd_hidden_factor': 2.21907229364439, 'n_layers': 4, 'hidden_dropout': 0.3524794152256811, 'residual_dropout': 0.4976792410170087, 'learning_rate': 0.00011688118260712675, 'batch_size': 32, 'epochs': 98}. Best is trial 3 with value: 0.9987876547423074.\n",
      "[I 2025-11-27 13:32:53,533] Trial 7 finished with value: 0.9976825127402666 and parameters: {'d': 512, 'd_hidden_factor': 1.4236339402272553, 'n_layers': 2, 'hidden_dropout': 0.16099030323415403, 'residual_dropout': 0.33078216833312185, 'learning_rate': 0.0034635277837420115, 'batch_size': 64, 'epochs': 90}. Best is trial 3 with value: 0.9987876547423074.\n",
      "[I 2025-11-27 13:32:58,070] Trial 8 finished with value: 0.9966358590056631 and parameters: {'d': 128, 'd_hidden_factor': 3.314205872435332, 'n_layers': 6, 'hidden_dropout': 0.001344032287160346, 'residual_dropout': 0.49417270964141, 'learning_rate': 0.005200256038614929, 'batch_size': 256, 'epochs': 198}. Best is trial 3 with value: 0.9987876547423074.\n",
      "[I 2025-11-27 13:32:59,372] Trial 9 finished with value: 0.9955544974021061 and parameters: {'d': 256, 'd_hidden_factor': 3.9242921433782283, 'n_layers': 2, 'hidden_dropout': 0.30034928391679494, 'residual_dropout': 0.4329322291516323, 'learning_rate': 0.008924108207819248, 'batch_size': 256, 'epochs': 123}. Best is trial 3 with value: 0.9987876547423074.\n",
      "[I 2025-11-27 13:36:58,423] Trial 10 finished with value: 0.9987876547423074 and parameters: {'d': 256, 'd_hidden_factor': 4.956401873386991, 'n_layers': 10, 'hidden_dropout': 0.10467358725545478, 'residual_dropout': 0.21319384192877996, 'learning_rate': 1.0455868741494775e-05, 'batch_size': 32, 'epochs': 159}. Best is trial 3 with value: 0.9987876547423074.\n",
      "[I 2025-11-27 13:38:30,807] Trial 11 finished with value: 0.9966358590056631 and parameters: {'d': 64, 'd_hidden_factor': 2.245569478012125, 'n_layers': 10, 'hidden_dropout': 0.41854941856004296, 'residual_dropout': 0.25334866386981963, 'learning_rate': 6.247315310775088e-05, 'batch_size': 32, 'epochs': 82}. Best is trial 3 with value: 0.9987876547423074.\n",
      "[I 2025-11-27 13:40:50,829] Trial 12 finished with value: 1.0 and parameters: {'d': 64, 'd_hidden_factor': 2.1444073493643163, 'n_layers': 8, 'hidden_dropout': 0.39773290288811947, 'residual_dropout': 0.02489923440104569, 'learning_rate': 6.731743934331164e-05, 'batch_size': 32, 'epochs': 146}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 13:43:44,696] Trial 13 finished with value: 0.9987876547423074 and parameters: {'d': 512, 'd_hidden_factor': 1.939462840625696, 'n_layers': 8, 'hidden_dropout': 0.4086800319020516, 'residual_dropout': 0.03936207928860028, 'learning_rate': 2.6413923478124092e-05, 'batch_size': 32, 'epochs': 152}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 13:44:18,240] Trial 14 finished with value: 0.9987876547423074 and parameters: {'d': 64, 'd_hidden_factor': 2.708106594508166, 'n_layers': 8, 'hidden_dropout': 0.19422144848526812, 'residual_dropout': 7.392621242233166e-05, 'learning_rate': 0.0008620843368387178, 'batch_size': 128, 'epochs': 152}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 13:47:37,091] Trial 15 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 1.9135004984878676, 'n_layers': 8, 'hidden_dropout': 0.4783280861731555, 'residual_dropout': 0.13454392637516355, 'learning_rate': 1.201880159180346e-05, 'batch_size': 32, 'epochs': 178}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 13:51:01,710] Trial 16 finished with value: 0.9987876547423074 and parameters: {'d': 256, 'd_hidden_factor': 1.6714184423355427, 'n_layers': 8, 'hidden_dropout': 0.49850152831888883, 'residual_dropout': 0.12270717832100393, 'learning_rate': 1.000466454417654e-05, 'batch_size': 32, 'epochs': 198}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 13:53:41,835] Trial 17 finished with value: 0.9953771605384713 and parameters: {'d': 64, 'd_hidden_factor': 2.2793670547625937, 'n_layers': 8, 'hidden_dropout': 0.42361711480884384, 'residual_dropout': 0.14837473819610625, 'learning_rate': 6.392563877777424e-05, 'batch_size': 32, 'epochs': 173}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 13:53:55,790] Trial 18 finished with value: 0.9966358590056631 and parameters: {'d': 512, 'd_hidden_factor': 1.3793267990810607, 'n_layers': 9, 'hidden_dropout': 0.3848562067794023, 'residual_dropout': 0.0830152053608702, 'learning_rate': 0.0006026117646786481, 'batch_size': 256, 'epochs': 176}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 13:54:29,850] Trial 19 finished with value: 0.9987876547423074 and parameters: {'d': 256, 'd_hidden_factor': 1.911422868996933, 'n_layers': 7, 'hidden_dropout': 0.45944819200898274, 'residual_dropout': 0.02359475959700144, 'learning_rate': 6.137060929056808e-05, 'batch_size': 128, 'epochs': 134}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 13:56:17,302] Trial 20 finished with value: 0.9966358590056631 and parameters: {'d': 64, 'd_hidden_factor': 1.0424819686077187, 'n_layers': 4, 'hidden_dropout': 0.35603529817763413, 'residual_dropout': 0.20337885226333327, 'learning_rate': 1.899577839045927e-05, 'batch_size': 32, 'epochs': 177}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 13:58:56,519] Trial 21 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 2.68729613445603, 'n_layers': 9, 'hidden_dropout': 0.2462143677214657, 'residual_dropout': 0.27938812683379166, 'learning_rate': 3.0058905072681507e-05, 'batch_size': 32, 'epochs': 140}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:00:54,304] Trial 22 finished with value: 0.9968064755284463 and parameters: {'d': 256, 'd_hidden_factor': 2.5276665993070377, 'n_layers': 9, 'hidden_dropout': 0.11987041251244654, 'residual_dropout': 0.26960100283635835, 'learning_rate': 0.00010367650420317449, 'batch_size': 32, 'epochs': 139}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:03:42,552] Trial 23 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 1.9660560004167185, 'n_layers': 9, 'hidden_dropout': 0.45041960924620883, 'residual_dropout': 0.19844360581718556, 'learning_rate': 3.849152967990944e-05, 'batch_size': 32, 'epochs': 164}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:05:36,411] Trial 24 finished with value: 0.9966358590056631 and parameters: {'d': 256, 'd_hidden_factor': 3.40438580805432, 'n_layers': 7, 'hidden_dropout': 0.3630612305644981, 'residual_dropout': 0.07966520355767685, 'learning_rate': 1.2478823491097956e-05, 'batch_size': 32, 'epochs': 113}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:07:36,693] Trial 25 finished with value: 0.9987876547423074 and parameters: {'d': 256, 'd_hidden_factor': 2.4040147354024937, 'n_layers': 7, 'hidden_dropout': 0.22042014479874553, 'residual_dropout': 0.11555452806527024, 'learning_rate': 4.593767505885525e-05, 'batch_size': 32, 'epochs': 143}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:09:35,365] Trial 26 finished with value: 1.0 and parameters: {'d': 64, 'd_hidden_factor': 1.8119730049457412, 'n_layers': 9, 'hidden_dropout': 0.4580280444269041, 'residual_dropout': 0.05072073314008592, 'learning_rate': 0.00014509047764415742, 'batch_size': 32, 'epochs': 117}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:09:50,559] Trial 27 finished with value: 0.9966358590056631 and parameters: {'d': 512, 'd_hidden_factor': 4.365792612056518, 'n_layers': 1, 'hidden_dropout': 0.1611455153356719, 'residual_dropout': 0.1715137917966384, 'learning_rate': 1.8739182785947295e-05, 'batch_size': 256, 'epochs': 188}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:11:47,576] Trial 28 finished with value: 0.9987876547423074 and parameters: {'d': 256, 'd_hidden_factor': 1.5470238419036881, 'n_layers': 7, 'hidden_dropout': 0.23765810651813674, 'residual_dropout': 0.29077499271755863, 'learning_rate': 9.210275475834798e-05, 'batch_size': 32, 'epochs': 165}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:12:18,901] Trial 29 finished with value: 0.9791329259641902 and parameters: {'d': 64, 'd_hidden_factor': 2.947608940858636, 'n_layers': 9, 'hidden_dropout': 0.4945028583246654, 'residual_dropout': 0.3696808401510094, 'learning_rate': 3.919271493465258e-05, 'batch_size': 128, 'epochs': 110}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:12:57,385] Trial 30 finished with value: 0.9978482042633556 and parameters: {'d': 64, 'd_hidden_factor': 2.6798990583070306, 'n_layers': 8, 'hidden_dropout': 0.050321681117725614, 'residual_dropout': 0.2266223983843108, 'learning_rate': 0.0002897488534604902, 'batch_size': 128, 'epochs': 147}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:15:46,663] Trial 31 finished with value: 0.9987876547423074 and parameters: {'d': 256, 'd_hidden_factor': 2.0587919505866163, 'n_layers': 9, 'hidden_dropout': 0.45334966390651943, 'residual_dropout': 0.17914997794800475, 'learning_rate': 3.818751661496731e-05, 'batch_size': 32, 'epochs': 165}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:19:40,787] Trial 32 finished with value: 0.9966358590056631 and parameters: {'d': 256, 'd_hidden_factor': 2.072605808557358, 'n_layers': 10, 'hidden_dropout': 0.4505094856017161, 'residual_dropout': 0.12195099975808629, 'learning_rate': 1.4797219999249465e-05, 'batch_size': 32, 'epochs': 187}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:22:31,319] Trial 33 finished with value: 0.9966358590056631 and parameters: {'d': 256, 'd_hidden_factor': 2.4978700419155175, 'n_layers': 9, 'hidden_dropout': 0.4001819510931033, 'residual_dropout': 0.23416966597748173, 'learning_rate': 3.191851637212088e-05, 'batch_size': 32, 'epochs': 160}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:22:57,419] Trial 34 finished with value: 1.0 and parameters: {'d': 128, 'd_hidden_factor': 1.7151188210600148, 'n_layers': 8, 'hidden_dropout': 0.3362759678906159, 'residual_dropout': 0.19355383082805705, 'learning_rate': 0.0002266040297155077, 'batch_size': 64, 'epochs': 54}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:25:56,261] Trial 35 finished with value: 0.9954235137479704 and parameters: {'d': 256, 'd_hidden_factor': 2.9449983063779377, 'n_layers': 10, 'hidden_dropout': 0.4390120864196515, 'residual_dropout': 0.14533045452387963, 'learning_rate': 1.874319649114879e-05, 'batch_size': 32, 'epochs': 133}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:26:27,871] Trial 36 finished with value: 0.9987876547423074 and parameters: {'d': 256, 'd_hidden_factor': 1.239900530648829, 'n_layers': 5, 'hidden_dropout': 0.27939942107568144, 'residual_dropout': 0.3656061601654862, 'learning_rate': 0.0005046054174899076, 'batch_size': 64, 'epochs': 185}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:29:02,213] Trial 37 finished with value: 0.9966358590056631 and parameters: {'d': 128, 'd_hidden_factor': 3.220088127095715, 'n_layers': 7, 'hidden_dropout': 0.4775989821842703, 'residual_dropout': 0.29889544147298275, 'learning_rate': 5.640319415448846e-05, 'batch_size': 32, 'epochs': 170}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:31:57,557] Trial 38 finished with value: 1.0 and parameters: {'d': 256, 'd_hidden_factor': 2.083350504905407, 'n_layers': 9, 'hidden_dropout': 0.37587588985375997, 'residual_dropout': 0.25751203931945327, 'learning_rate': 2.4669749128084154e-05, 'batch_size': 32, 'epochs': 153}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:33:10,472] Trial 39 finished with value: 0.9987876547423074 and parameters: {'d': 256, 'd_hidden_factor': 2.744601428371893, 'n_layers': 6, 'hidden_dropout': 0.3318920813832874, 'residual_dropout': 0.09736457744382052, 'learning_rate': 0.00016166916502344025, 'batch_size': 32, 'epochs': 133}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:33:33,562] Trial 40 finished with value: 0.9966358590056631 and parameters: {'d': 128, 'd_hidden_factor': 3.5467655593907814, 'n_layers': 10, 'hidden_dropout': 0.2714443045117627, 'residual_dropout': 0.0562535368040471, 'learning_rate': 8.877984702178372e-05, 'batch_size': 64, 'epochs': 37}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:35:38,853] Trial 41 finished with value: 0.9953771605384713 and parameters: {'d': 64, 'd_hidden_factor': 1.7311606939576647, 'n_layers': 9, 'hidden_dropout': 0.45618614437483895, 'residual_dropout': 0.04776129520495517, 'learning_rate': 0.00015847993216875687, 'batch_size': 32, 'epochs': 122}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:37:15,871] Trial 42 finished with value: 0.9987876547423074 and parameters: {'d': 64, 'd_hidden_factor': 1.7664088956021278, 'n_layers': 8, 'hidden_dropout': 0.47836370181170396, 'residual_dropout': 0.0023862440187297496, 'learning_rate': 0.0001253533902666984, 'batch_size': 32, 'epochs': 104}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:39:16,819] Trial 43 finished with value: 0.9987876547423074 and parameters: {'d': 64, 'd_hidden_factor': 1.473811758048495, 'n_layers': 9, 'hidden_dropout': 0.4356531642591692, 'residual_dropout': 0.06675535211400349, 'learning_rate': 7.573402045527508e-05, 'batch_size': 32, 'epochs': 119}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:41:42,363] Trial 44 finished with value: 0.9966358590056631 and parameters: {'d': 64, 'd_hidden_factor': 1.8935835747781553, 'n_layers': 10, 'hidden_dropout': 0.39792799763184544, 'residual_dropout': 0.028499187003492063, 'learning_rate': 4.4205065916979145e-05, 'batch_size': 32, 'epochs': 128}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:42:02,413] Trial 45 finished with value: 0.9799746268280259 and parameters: {'d': 64, 'd_hidden_factor': 2.3437203581812747, 'n_layers': 8, 'hidden_dropout': 0.4217186938230467, 'residual_dropout': 0.1042280731374271, 'learning_rate': 2.9460042294118466e-05, 'batch_size': 256, 'epochs': 148}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:45:18,983] Trial 46 finished with value: 0.9987876547423074 and parameters: {'d': 512, 'd_hidden_factor': 2.1837823435633243, 'n_layers': 7, 'hidden_dropout': 0.30132560373392464, 'residual_dropout': 0.16057828469330104, 'learning_rate': 1.4992980701098517e-05, 'batch_size': 32, 'epochs': 160}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:46:24,775] Trial 47 finished with value: 0.9987876547423074 and parameters: {'d': 64, 'd_hidden_factor': 2.595117079048844, 'n_layers': 9, 'hidden_dropout': 0.47935322561533145, 'residual_dropout': 0.13883725616311496, 'learning_rate': 0.0013173675781514719, 'batch_size': 32, 'epochs': 82}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:47:07,296] Trial 48 finished with value: 0.9964330637099383 and parameters: {'d': 256, 'd_hidden_factor': 1.2371642562415122, 'n_layers': 5, 'hidden_dropout': 0.24435625822379664, 'residual_dropout': 0.3167386189938272, 'learning_rate': 0.0004258040622985475, 'batch_size': 32, 'epochs': 141}. Best is trial 12 with value: 1.0.\n",
      "[I 2025-11-27 14:47:57,841] Trial 49 finished with value: 0.9978482042633556 and parameters: {'d': 256, 'd_hidden_factor': 3.0891581245527275, 'n_layers': 8, 'hidden_dropout': 0.1963668183578984, 'residual_dropout': 0.018670365983782744, 'learning_rate': 0.000122841620440663, 'batch_size': 128, 'epochs': 181}. Best is trial 12 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Optimization complete! Time: 4799.10s\n",
      "  Best CV G-Mean: 1.0000\n",
      "  Best parameters:\n",
      "    d: 64\n",
      "    d_hidden_factor: 2.1444073493643163\n",
      "    n_layers: 8\n",
      "    hidden_dropout: 0.39773290288811947\n",
      "    residual_dropout: 0.02489923440104569\n",
      "    learning_rate: 6.731743934331164e-05\n",
      "    batch_size: 32\n",
      "    epochs: 146\n",
      "\n",
      "Training final model...\n",
      "    Epoch 10/146: Train Loss = 0.6102, Val Loss = 0.5120\n",
      "    Epoch 20/146: Train Loss = 0.3209, Val Loss = 0.2760\n",
      "    Epoch 30/146: Train Loss = 0.2039, Val Loss = 0.1956\n",
      "    Epoch 40/146: Train Loss = 0.1517, Val Loss = 0.1337\n",
      "    Epoch 50/146: Train Loss = 0.1163, Val Loss = 0.1005\n",
      "    Epoch 60/146: Train Loss = 0.1006, Val Loss = 0.0773\n",
      "    Epoch 70/146: Train Loss = 0.0760, Val Loss = 0.0619\n",
      "    Epoch 80/146: Train Loss = 0.0682, Val Loss = 0.0495\n",
      "    Epoch 90/146: Train Loss = 0.0671, Val Loss = 0.0433\n",
      "    Epoch 100/146: Train Loss = 0.0353, Val Loss = 0.0347\n",
      "    Epoch 110/146: Train Loss = 0.0521, Val Loss = 0.0296\n",
      "    Epoch 120/146: Train Loss = 0.0317, Val Loss = 0.0279\n",
      "    Epoch 130/146: Train Loss = 0.0298, Val Loss = 0.0226\n",
      "    Epoch 140/146: Train Loss = 0.0313, Val Loss = 0.0195\n",
      "✓ Training complete! Time: 13.06s\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR analcatdata_authorship\n",
      "================================================================================\n",
      "Accuracy:        0.9881\n",
      "AUC OVO:         0.9999\n",
      "G-Mean:          0.9915\n",
      "Cross-Entropy:   0.0453\n",
      "================================================================================\n",
      "✓ Saved results for analcatdata_authorship\n",
      "\n",
      "✓ Completed analcatdata_authorship (30/30)\n",
      "\n",
      "================================================================================\n",
      "SAVING FINAL RESULTS\n",
      "================================================================================\n",
      "\n",
      "✓ Saved metrics CSV: results/resnet/resnet_metrics.csv\n",
      "  Total datasets: 30\n",
      "  Columns: ['dataset', 'model', 'accuracy', 'auc_ovo', 'gmean', 'cross_entropy', 'n_samples_train', 'n_samples_test', 'n_features', 'n_classes']\n",
      "\n",
      "Metrics Summary:\n",
      "        accuracy    auc_ovo      gmean  cross_entropy\n",
      "count  30.000000  30.000000  30.000000      30.000000\n",
      "mean    0.827024   0.891088   0.785000       0.401201\n",
      "std     0.182493   0.126148   0.201549       0.372629\n",
      "min     0.231156   0.556069   0.227015       0.014495\n",
      "25%     0.742520   0.807025   0.669558       0.108775\n",
      "50%     0.884833   0.924514   0.821570       0.326806\n",
      "75%     0.967242   0.996815   0.964126       0.548645\n",
      "max     1.000000   1.000000   1.000000       1.753764\n",
      "\n",
      "================================================================================\n",
      "RESULTS SUMMARY - RESNET\n",
      "================================================================================\n",
      "Total datasets: 30\n",
      "\n",
      "Metrics Statistics:\n",
      "        accuracy    auc_ovo      gmean  cross_entropy\n",
      "count  30.000000  30.000000  30.000000      30.000000\n",
      "mean    0.827024   0.891088   0.785000       0.401201\n",
      "std     0.182493   0.126148   0.201549       0.372629\n",
      "min     0.231156   0.556069   0.227015       0.014495\n",
      "25%     0.742520   0.807025   0.669558       0.108775\n",
      "50%     0.884833   0.924514   0.821570       0.326806\n",
      "75%     0.967242   0.996815   0.964126       0.548645\n",
      "max     1.000000   1.000000   1.000000       1.753764\n",
      "\n",
      "Top 5 datasets by accuracy:\n",
      "                dataset  accuracy  auc_ovo    gmean\n",
      "            MiceProtein  1.000000 1.000000 1.000000\n",
      "banknote-authentication  1.000000 1.000000 1.000000\n",
      "            tic-tac-toe  0.996528 0.999894 0.994987\n",
      "                    car  0.988439 0.999831 0.971309\n",
      " analcatdata_authorship  0.988142 0.999905 0.991464\n",
      "\n",
      "Bottom 5 datasets by accuracy:\n",
      "                         dataset  accuracy  auc_ovo    gmean\n",
      "                analcatdata_dmft  0.231156 0.556069 0.227015\n",
      "                   dresses-sales  0.500000 0.586389 0.447988\n",
      "                             cmc  0.538462 0.719239 0.528419\n",
      "blood-transfusion-service-center  0.604444 0.717349 0.653873\n",
      "                      eucalyptus  0.628959 0.901013 0.575871\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT COMPLETE!\n",
      "================================================================================\n",
      "✓ Total datasets: 30\n",
      "✓ Successful: 30\n",
      "✓ Failed: 0\n",
      "\n",
      "✓ Metrics CSV saved: ./results/resnet/resnet_metrics.csv\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5910571c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
